{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to process Adult Census data, edit/train models, and perform adversarial debiasing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary libraries for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.utils import to_categorical\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.onnx\n",
    "from scipy.io import savemat\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bank():\n",
    "    # Define paths and column names\n",
    "    file_path = '../data/bank/bank-additional-full.csv'\n",
    "    column_names = ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', \n",
    "                    'month', 'day_of_week', 'duration', 'emp.var.rate', 'campaign', 'pdays', 'previous', 'poutcome', 'y']\n",
    "    na_values = ['unknown']\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path, sep=';', na_values=na_values)\n",
    "    \n",
    "    # Drop na values\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Encode categorical features\n",
    "    categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "    for col in categorical_features:\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "    \n",
    "    # Binary transformation for age (1 if age >= 25, else 0)\n",
    "    df['age'] = df['age'].apply(lambda x: 1 if x >= 25 else 0)\n",
    "    \n",
    "    # Convert target variable to binary\n",
    "    df['y'] = df['y'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "    \n",
    "    # Select columns to keep (including the target variable 'y')\n",
    "    df = df[column_names]\n",
    "    \n",
    "    # Split features and labels\n",
    "    X = df.drop('y', axis=1)\n",
    "    y = df['y']\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Extract the protected attribute ('age' for demonstration, adjust as needed)\n",
    "    protected_attribute = X[:, df.columns.get_loc('age')]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test, protected_train, protected_test = train_test_split(\n",
    "        X, to_categorical(y, num_classes=2), protected_attribute, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, protected_train, protected_test\n",
    "\n",
    "# Saves data for use in verification\n",
    "def load_and_save_bank_data():\n",
    "    X_train, X_test, y_train, y_test, _, _ = load_bank()\n",
    "    \n",
    "    # Scaling numerical features with MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Prepare data dictionary to save as .mat file\n",
    "    data_dict = {\n",
    "        'X': X_test, \n",
    "        'y': y_test   \n",
    "    }\n",
    "    \n",
    "    # Save to .mat file for use in MATLAB\n",
    "    savemat(\"./processed_data/bank_data.mat\", data_dict)\n",
    "    print(\"Data saved to bank_data.mat\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Editing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to save the models as onnx files for verification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model as ONNX format\n",
    "def save_model_onnx(model, input_shape, onnx_file_path):\n",
    "    # Create a dummy input tensor with the correct input shape (batch_size, input_shape)\n",
    "    dummy_input = tf.random.normal([1] + list(input_shape))\n",
    "\n",
    "    # Convert the model to ONNX\n",
    "    model_proto, external_tensor_storage = tf2onnx.convert.from_keras(model, \n",
    "                                                                      input_signature=(tf.TensorSpec(shape=[None] + list(input_shape), dtype=tf.float32),),\n",
    "                                                                      opset=13)\n",
    "    \n",
    "    # Save the ONNX model to the specified path\n",
    "    with open(onnx_file_path, \"wb\") as f:\n",
    "        f.write(model_proto.SerializeToString())\n",
    "    \n",
    "    print(f\"Model has been saved in ONNX format at {onnx_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the models so they are able to be used in FairNNV. FairNNV cannot handle sigmoid so shift to softmax and adjust final layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/annemtumlin/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/annemtumlin/.local/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Function to modify a model for multiclass classification\n",
    "def modify_model_for_multiclass(model_path, num_classes):\n",
    "    # with warnings.catch_warnings():\n",
    "    #     warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Create a new input layer with the correct shape\n",
    "    new_input = tf.keras.layers.Input(shape=(16,))\n",
    "    x = new_input\n",
    "\n",
    "    # Transfer the layers except the last one\n",
    "    for layer in model.layers[:-1]:\n",
    "        x = layer(x)\n",
    "\n",
    "    # Create a new output layer\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='softmax', name='new_output')(x)\n",
    "    \n",
    "    # Create a new model\n",
    "    new_model = tf.keras.models.Model(inputs=new_input, outputs=output)\n",
    "    \n",
    "    return new_model\n",
    "\n",
    "# Ensure the save directories exist\n",
    "model_dir = './bank/bank_h5'\n",
    "save_dir = './bank/bank_keras'\n",
    "onnx_save_dir = './bank/bank_onnx'\n",
    "num_classes = 2\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "if not os.path.exists(onnx_save_dir):\n",
    "    os.makedirs(onnx_save_dir)\n",
    "\n",
    "# Modify each model in the directory to remove sigmoid\n",
    "for model_file in os.listdir(model_dir):\n",
    "    if model_file.endswith('.h5'):\n",
    "        model_path = os.path.join(model_dir, model_file)\n",
    "        new_model = modify_model_for_multiclass(model_path, num_classes)\n",
    "        \n",
    "        # Update the model's loss function\n",
    "        new_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Save the modified model\n",
    "        save_path = os.path.join(save_dir, model_file.replace('.h5', '.keras'))\n",
    "        new_model.save(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-train models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to bank_data.mat\n",
      "Loading model BM-7.keras\n",
      "Training model BM-7.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/annemtumlin/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 0.3433 - val_accuracy: 0.8784 - val_loss: 0.3261\n",
      "Epoch 2/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8806 - loss: 0.3161 - val_accuracy: 0.8831 - val_loss: 0.2977\n",
      "Epoch 3/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8929 - loss: 0.2735 - val_accuracy: 0.8872 - val_loss: 0.2645\n",
      "Epoch 4/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8927 - loss: 0.2519 - val_accuracy: 0.8913 - val_loss: 0.2511\n",
      "Epoch 5/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9012 - loss: 0.2335 - val_accuracy: 0.8899 - val_loss: 0.2492\n",
      "Epoch 6/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8999 - loss: 0.2295 - val_accuracy: 0.8899 - val_loss: 0.2496\n",
      "Epoch 7/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9009 - loss: 0.2272 - val_accuracy: 0.8879 - val_loss: 0.2556\n",
      "Epoch 8/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9005 - loss: 0.2262 - val_accuracy: 0.8932 - val_loss: 0.2480\n",
      "Epoch 9/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9017 - loss: 0.2247 - val_accuracy: 0.8891 - val_loss: 0.2425\n",
      "Epoch 10/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8998 - loss: 0.2270 - val_accuracy: 0.8883 - val_loss: 0.2435\n",
      "Epoch 11/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9043 - loss: 0.2158 - val_accuracy: 0.8913 - val_loss: 0.2404\n",
      "Epoch 12/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9006 - loss: 0.2202 - val_accuracy: 0.8913 - val_loss: 0.2386\n",
      "Epoch 13/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9034 - loss: 0.2152 - val_accuracy: 0.8899 - val_loss: 0.2465\n",
      "Epoch 14/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9016 - loss: 0.2158 - val_accuracy: 0.8916 - val_loss: 0.2382\n",
      "Epoch 15/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9013 - loss: 0.2177 - val_accuracy: 0.8934 - val_loss: 0.2394\n",
      "Epoch 16/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9030 - loss: 0.2132 - val_accuracy: 0.8891 - val_loss: 0.2439\n",
      "Epoch 17/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9004 - loss: 0.2201 - val_accuracy: 0.8903 - val_loss: 0.2384\n",
      "Epoch 18/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9014 - loss: 0.2172 - val_accuracy: 0.8893 - val_loss: 0.2401\n",
      "Epoch 19/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9028 - loss: 0.2133 - val_accuracy: 0.8936 - val_loss: 0.2372\n",
      "Epoch 20/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9025 - loss: 0.2128 - val_accuracy: 0.8924 - val_loss: 0.2364\n",
      "Epoch 21/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9005 - loss: 0.2197 - val_accuracy: 0.8938 - val_loss: 0.2368\n",
      "Epoch 22/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9023 - loss: 0.2144 - val_accuracy: 0.8924 - val_loss: 0.2379\n",
      "Epoch 23/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.2109 - val_accuracy: 0.8924 - val_loss: 0.2363\n",
      "Epoch 24/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9076 - loss: 0.2082 - val_accuracy: 0.8909 - val_loss: 0.2386\n",
      "Epoch 25/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9036 - loss: 0.2128 - val_accuracy: 0.8909 - val_loss: 0.2375\n",
      "Epoch 26/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9052 - loss: 0.2124 - val_accuracy: 0.8938 - val_loss: 0.2358\n",
      "Epoch 27/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9021 - loss: 0.2125 - val_accuracy: 0.8819 - val_loss: 0.2469\n",
      "Epoch 28/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9031 - loss: 0.2087 - val_accuracy: 0.8893 - val_loss: 0.2393\n",
      "Epoch 29/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9062 - loss: 0.2109 - val_accuracy: 0.8924 - val_loss: 0.2362\n",
      "Epoch 30/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9064 - loss: 0.2059 - val_accuracy: 0.8899 - val_loss: 0.2365\n",
      "Epoch 31/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9056 - loss: 0.2113 - val_accuracy: 0.8864 - val_loss: 0.2393\n",
      "Epoch 32/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9012 - loss: 0.2105 - val_accuracy: 0.8883 - val_loss: 0.2409\n",
      "Epoch 33/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2060 - val_accuracy: 0.8903 - val_loss: 0.2400\n",
      "Epoch 34/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9063 - loss: 0.2059 - val_accuracy: 0.8872 - val_loss: 0.2381\n",
      "Epoch 35/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2023 - val_accuracy: 0.8897 - val_loss: 0.2372\n",
      "Epoch 36/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9020 - loss: 0.2144 - val_accuracy: 0.8940 - val_loss: 0.2346\n",
      "Epoch 37/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9054 - loss: 0.2066 - val_accuracy: 0.8885 - val_loss: 0.2398\n",
      "Epoch 38/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2015 - val_accuracy: 0.8930 - val_loss: 0.2376\n",
      "Epoch 39/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9037 - loss: 0.2124 - val_accuracy: 0.8852 - val_loss: 0.2387\n",
      "Epoch 40/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9059 - loss: 0.2067 - val_accuracy: 0.8895 - val_loss: 0.2390\n",
      "Epoch 41/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9106 - loss: 0.2035 - val_accuracy: 0.8766 - val_loss: 0.2531\n",
      "Epoch 42/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.2088 - val_accuracy: 0.8926 - val_loss: 0.2343\n",
      "Epoch 43/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9080 - loss: 0.2023 - val_accuracy: 0.8872 - val_loss: 0.2364\n",
      "Epoch 44/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9080 - loss: 0.2016 - val_accuracy: 0.8911 - val_loss: 0.2356\n",
      "Epoch 45/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9049 - loss: 0.2074 - val_accuracy: 0.8838 - val_loss: 0.2419\n",
      "Epoch 46/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9055 - loss: 0.2068 - val_accuracy: 0.8887 - val_loss: 0.2375\n",
      "Epoch 47/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9071 - loss: 0.2085 - val_accuracy: 0.8909 - val_loss: 0.2397\n",
      "Epoch 48/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9077 - loss: 0.1999 - val_accuracy: 0.8860 - val_loss: 0.2426\n",
      "Epoch 49/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9078 - loss: 0.1990 - val_accuracy: 0.8897 - val_loss: 0.2357\n",
      "Epoch 50/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9110 - loss: 0.1953 - val_accuracy: 0.8842 - val_loss: 0.2405\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step\n",
      "Model BM-7.keras - Accuracy: 0.889963922597573\n",
      "Model BM-7.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./bank/bank_onnx/BM-7.onnx\n",
      "Loading model BM-6.keras\n",
      "Training model BM-6.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 15:53:01.129250: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:53:01.129352: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-19 15:53:01.151177: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:53:01.151320: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "/home/annemtumlin/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8723 - loss: 0.5038 - val_accuracy: 0.8713 - val_loss: 0.3396\n",
      "Epoch 2/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8722 - loss: 0.3325 - val_accuracy: 0.8713 - val_loss: 0.3324\n",
      "Epoch 3/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8757 - loss: 0.3247 - val_accuracy: 0.8694 - val_loss: 0.3265\n",
      "Epoch 4/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8731 - loss: 0.3227 - val_accuracy: 0.8700 - val_loss: 0.3235\n",
      "Epoch 5/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8742 - loss: 0.3179 - val_accuracy: 0.8774 - val_loss: 0.3171\n",
      "Epoch 6/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8789 - loss: 0.3156 - val_accuracy: 0.8784 - val_loss: 0.3127\n",
      "Epoch 7/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8824 - loss: 0.3060 - val_accuracy: 0.8823 - val_loss: 0.3095\n",
      "Epoch 8/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8844 - loss: 0.3022 - val_accuracy: 0.8829 - val_loss: 0.3069\n",
      "Epoch 9/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8878 - loss: 0.2951 - val_accuracy: 0.8817 - val_loss: 0.3045\n",
      "Epoch 10/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8865 - loss: 0.2951 - val_accuracy: 0.8834 - val_loss: 0.3008\n",
      "Epoch 11/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8896 - loss: 0.2865 - val_accuracy: 0.8860 - val_loss: 0.2829\n",
      "Epoch 12/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8937 - loss: 0.2651 - val_accuracy: 0.8858 - val_loss: 0.2750\n",
      "Epoch 13/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8892 - loss: 0.2616 - val_accuracy: 0.8831 - val_loss: 0.2649\n",
      "Epoch 14/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8928 - loss: 0.2510 - val_accuracy: 0.8829 - val_loss: 0.2634\n",
      "Epoch 15/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8923 - loss: 0.2446 - val_accuracy: 0.8827 - val_loss: 0.2598\n",
      "Epoch 16/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8892 - loss: 0.2514 - val_accuracy: 0.8827 - val_loss: 0.2600\n",
      "Epoch 17/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8862 - loss: 0.2493 - val_accuracy: 0.8817 - val_loss: 0.2581\n",
      "Epoch 18/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8913 - loss: 0.2463 - val_accuracy: 0.8825 - val_loss: 0.2575\n",
      "Epoch 19/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8938 - loss: 0.2382 - val_accuracy: 0.8827 - val_loss: 0.2565\n",
      "Epoch 20/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8923 - loss: 0.2389 - val_accuracy: 0.8838 - val_loss: 0.2574\n",
      "Epoch 21/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8882 - loss: 0.2445 - val_accuracy: 0.8838 - val_loss: 0.2559\n",
      "Epoch 22/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8931 - loss: 0.2397 - val_accuracy: 0.8842 - val_loss: 0.2553\n",
      "Epoch 23/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8917 - loss: 0.2390 - val_accuracy: 0.8848 - val_loss: 0.2552\n",
      "Epoch 24/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8936 - loss: 0.2403 - val_accuracy: 0.8852 - val_loss: 0.2546\n",
      "Epoch 25/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8930 - loss: 0.2384 - val_accuracy: 0.8854 - val_loss: 0.2545\n",
      "Epoch 26/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8928 - loss: 0.2426 - val_accuracy: 0.8852 - val_loss: 0.2557\n",
      "Epoch 27/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8936 - loss: 0.2383 - val_accuracy: 0.8848 - val_loss: 0.2560\n",
      "Epoch 28/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8908 - loss: 0.2463 - val_accuracy: 0.8870 - val_loss: 0.2535\n",
      "Epoch 29/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8934 - loss: 0.2373 - val_accuracy: 0.8852 - val_loss: 0.2551\n",
      "Epoch 30/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8899 - loss: 0.2434 - val_accuracy: 0.8877 - val_loss: 0.2529\n",
      "Epoch 31/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8988 - loss: 0.2338 - val_accuracy: 0.8877 - val_loss: 0.2528\n",
      "Epoch 32/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8925 - loss: 0.2356 - val_accuracy: 0.8848 - val_loss: 0.2581\n",
      "Epoch 33/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8940 - loss: 0.2376 - val_accuracy: 0.8875 - val_loss: 0.2523\n",
      "Epoch 34/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8935 - loss: 0.2388 - val_accuracy: 0.8862 - val_loss: 0.2548\n",
      "Epoch 35/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8969 - loss: 0.2358 - val_accuracy: 0.8877 - val_loss: 0.2523\n",
      "Epoch 36/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8952 - loss: 0.2379 - val_accuracy: 0.8877 - val_loss: 0.2516\n",
      "Epoch 37/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8963 - loss: 0.2357 - val_accuracy: 0.8852 - val_loss: 0.2574\n",
      "Epoch 38/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8955 - loss: 0.2352 - val_accuracy: 0.8883 - val_loss: 0.2523\n",
      "Epoch 39/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8962 - loss: 0.2331 - val_accuracy: 0.8885 - val_loss: 0.2511\n",
      "Epoch 40/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8941 - loss: 0.2408 - val_accuracy: 0.8883 - val_loss: 0.2513\n",
      "Epoch 41/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8959 - loss: 0.2348 - val_accuracy: 0.8854 - val_loss: 0.2544\n",
      "Epoch 42/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8944 - loss: 0.2373 - val_accuracy: 0.8887 - val_loss: 0.2506\n",
      "Epoch 43/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8978 - loss: 0.2349 - val_accuracy: 0.8893 - val_loss: 0.2507\n",
      "Epoch 44/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8986 - loss: 0.2335 - val_accuracy: 0.8848 - val_loss: 0.2546\n",
      "Epoch 45/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8972 - loss: 0.2305 - val_accuracy: 0.8872 - val_loss: 0.2533\n",
      "Epoch 46/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8999 - loss: 0.2331 - val_accuracy: 0.8881 - val_loss: 0.2520\n",
      "Epoch 47/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8972 - loss: 0.2311 - val_accuracy: 0.8879 - val_loss: 0.2522\n",
      "Epoch 48/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8977 - loss: 0.2296 - val_accuracy: 0.8868 - val_loss: 0.2512\n",
      "Epoch 49/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8893 - loss: 0.2422 - val_accuracy: 0.8891 - val_loss: 0.2499\n",
      "Epoch 50/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9021 - loss: 0.2265 - val_accuracy: 0.8887 - val_loss: 0.2494\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step\n",
      "Model BM-6.keras - Accuracy: 0.8881600524762218\n",
      "Model BM-6.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./bank/bank_onnx/BM-6.onnx\n",
      "Loading model BM-5.keras\n",
      "Training model BM-5.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 15:53:36.744539: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:53:36.744705: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-19 15:53:36.770696: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:53:36.770839: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "/home/annemtumlin/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7303 - loss: 0.7644 - val_accuracy: 0.8713 - val_loss: 0.3808\n",
      "Epoch 2/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8776 - loss: 0.3630 - val_accuracy: 0.8713 - val_loss: 0.3613\n",
      "Epoch 3/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8778 - loss: 0.3453 - val_accuracy: 0.8713 - val_loss: 0.3444\n",
      "Epoch 4/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8765 - loss: 0.3310 - val_accuracy: 0.8713 - val_loss: 0.3256\n",
      "Epoch 5/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8746 - loss: 0.3126 - val_accuracy: 0.8741 - val_loss: 0.3082\n",
      "Epoch 6/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8837 - loss: 0.2930 - val_accuracy: 0.8825 - val_loss: 0.2903\n",
      "Epoch 7/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8888 - loss: 0.2766 - val_accuracy: 0.8848 - val_loss: 0.2705\n",
      "Epoch 8/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8943 - loss: 0.2523 - val_accuracy: 0.8864 - val_loss: 0.2543\n",
      "Epoch 9/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8947 - loss: 0.2369 - val_accuracy: 0.8864 - val_loss: 0.2495\n",
      "Epoch 10/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9003 - loss: 0.2291 - val_accuracy: 0.8829 - val_loss: 0.2530\n",
      "Epoch 11/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8941 - loss: 0.2346 - val_accuracy: 0.8854 - val_loss: 0.2449\n",
      "Epoch 12/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8982 - loss: 0.2225 - val_accuracy: 0.8848 - val_loss: 0.2441\n",
      "Epoch 13/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8994 - loss: 0.2247 - val_accuracy: 0.8862 - val_loss: 0.2446\n",
      "Epoch 14/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8989 - loss: 0.2219 - val_accuracy: 0.8866 - val_loss: 0.2432\n",
      "Epoch 15/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8952 - loss: 0.2290 - val_accuracy: 0.8860 - val_loss: 0.2433\n",
      "Epoch 16/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9004 - loss: 0.2222 - val_accuracy: 0.8838 - val_loss: 0.2437\n",
      "Epoch 17/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8988 - loss: 0.2232 - val_accuracy: 0.8877 - val_loss: 0.2427\n",
      "Epoch 18/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8980 - loss: 0.2253 - val_accuracy: 0.8864 - val_loss: 0.2416\n",
      "Epoch 19/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9013 - loss: 0.2236 - val_accuracy: 0.8872 - val_loss: 0.2419\n",
      "Epoch 20/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8960 - loss: 0.2280 - val_accuracy: 0.8883 - val_loss: 0.2422\n",
      "Epoch 21/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8982 - loss: 0.2250 - val_accuracy: 0.8860 - val_loss: 0.2413\n",
      "Epoch 22/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8945 - loss: 0.2315 - val_accuracy: 0.8854 - val_loss: 0.2414\n",
      "Epoch 23/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8962 - loss: 0.2291 - val_accuracy: 0.8895 - val_loss: 0.2414\n",
      "Epoch 24/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8984 - loss: 0.2290 - val_accuracy: 0.8885 - val_loss: 0.2413\n",
      "Epoch 25/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8993 - loss: 0.2210 - val_accuracy: 0.8866 - val_loss: 0.2402\n",
      "Epoch 26/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8987 - loss: 0.2196 - val_accuracy: 0.8877 - val_loss: 0.2417\n",
      "Epoch 27/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8977 - loss: 0.2265 - val_accuracy: 0.8848 - val_loss: 0.2438\n",
      "Epoch 28/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8967 - loss: 0.2254 - val_accuracy: 0.8889 - val_loss: 0.2414\n",
      "Epoch 29/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9015 - loss: 0.2181 - val_accuracy: 0.8877 - val_loss: 0.2405\n",
      "Epoch 30/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8994 - loss: 0.2206 - val_accuracy: 0.8881 - val_loss: 0.2403\n",
      "Epoch 31/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8978 - loss: 0.2259 - val_accuracy: 0.8864 - val_loss: 0.2420\n",
      "Epoch 32/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9011 - loss: 0.2193 - val_accuracy: 0.8887 - val_loss: 0.2401\n",
      "Epoch 33/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8988 - loss: 0.2246 - val_accuracy: 0.8879 - val_loss: 0.2399\n",
      "Epoch 34/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.2175 - val_accuracy: 0.8887 - val_loss: 0.2405\n",
      "Epoch 35/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8993 - loss: 0.2189 - val_accuracy: 0.8868 - val_loss: 0.2397\n",
      "Epoch 36/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8987 - loss: 0.2245 - val_accuracy: 0.8866 - val_loss: 0.2398\n",
      "Epoch 37/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9022 - loss: 0.2156 - val_accuracy: 0.8870 - val_loss: 0.2403\n",
      "Epoch 38/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.2212 - val_accuracy: 0.8883 - val_loss: 0.2404\n",
      "Epoch 39/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8988 - loss: 0.2250 - val_accuracy: 0.8870 - val_loss: 0.2396\n",
      "Epoch 40/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8976 - loss: 0.2228 - val_accuracy: 0.8864 - val_loss: 0.2431\n",
      "Epoch 41/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9015 - loss: 0.2171 - val_accuracy: 0.8875 - val_loss: 0.2397\n",
      "Epoch 42/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9011 - loss: 0.2218 - val_accuracy: 0.8877 - val_loss: 0.2395\n",
      "Epoch 43/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9015 - loss: 0.2169 - val_accuracy: 0.8883 - val_loss: 0.2404\n",
      "Epoch 44/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9027 - loss: 0.2187 - val_accuracy: 0.8875 - val_loss: 0.2394\n",
      "Epoch 45/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8979 - loss: 0.2243 - val_accuracy: 0.8872 - val_loss: 0.2409\n",
      "Epoch 46/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8993 - loss: 0.2242 - val_accuracy: 0.8887 - val_loss: 0.2439\n",
      "Epoch 47/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9006 - loss: 0.2224 - val_accuracy: 0.8883 - val_loss: 0.2403\n",
      "Epoch 48/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8976 - loss: 0.2272 - val_accuracy: 0.8870 - val_loss: 0.2421\n",
      "Epoch 49/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8989 - loss: 0.2212 - val_accuracy: 0.8868 - val_loss: 0.2393\n",
      "Epoch 50/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8976 - loss: 0.2279 - val_accuracy: 0.8879 - val_loss: 0.2396\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step\n",
      "Model BM-5.keras - Accuracy: 0.8906198753689735\n",
      "Model BM-5.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./bank/bank_onnx/BM-5.onnx\n",
      "Loading model BM-8.keras\n",
      "Training model BM-8.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 15:54:12.864168: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:54:12.864261: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-19 15:54:12.894691: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:54:12.894814: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "/home/annemtumlin/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 26 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8771 - loss: 1.0317 - val_accuracy: 0.8713 - val_loss: 0.3451\n",
      "Epoch 2/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8774 - loss: 0.3322 - val_accuracy: 0.8713 - val_loss: 0.3326\n",
      "Epoch 3/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8742 - loss: 0.3233 - val_accuracy: 0.8713 - val_loss: 0.3221\n",
      "Epoch 4/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8757 - loss: 0.3064 - val_accuracy: 0.8713 - val_loss: 0.3087\n",
      "Epoch 5/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8722 - loss: 0.2992 - val_accuracy: 0.8854 - val_loss: 0.2847\n",
      "Epoch 6/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8931 - loss: 0.2616 - val_accuracy: 0.8875 - val_loss: 0.2542\n",
      "Epoch 7/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8960 - loss: 0.2319 - val_accuracy: 0.8879 - val_loss: 0.2487\n",
      "Epoch 8/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8959 - loss: 0.2379 - val_accuracy: 0.8780 - val_loss: 0.2496\n",
      "Epoch 9/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8952 - loss: 0.2313 - val_accuracy: 0.8866 - val_loss: 0.2447\n",
      "Epoch 10/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8956 - loss: 0.2265 - val_accuracy: 0.8817 - val_loss: 0.2443\n",
      "Epoch 11/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8943 - loss: 0.2270 - val_accuracy: 0.8834 - val_loss: 0.2450\n",
      "Epoch 12/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8946 - loss: 0.2259 - val_accuracy: 0.8809 - val_loss: 0.2449\n",
      "Epoch 13/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8928 - loss: 0.2303 - val_accuracy: 0.8858 - val_loss: 0.2423\n",
      "Epoch 14/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8930 - loss: 0.2307 - val_accuracy: 0.8819 - val_loss: 0.2435\n",
      "Epoch 15/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8942 - loss: 0.2310 - val_accuracy: 0.8815 - val_loss: 0.2423\n",
      "Epoch 16/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8956 - loss: 0.2255 - val_accuracy: 0.8815 - val_loss: 0.2440\n",
      "Epoch 17/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8983 - loss: 0.2252 - val_accuracy: 0.8868 - val_loss: 0.2428\n",
      "Epoch 18/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8957 - loss: 0.2242 - val_accuracy: 0.8858 - val_loss: 0.2436\n",
      "Epoch 19/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8984 - loss: 0.2243 - val_accuracy: 0.8846 - val_loss: 0.2425\n",
      "Epoch 20/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8988 - loss: 0.2211 - val_accuracy: 0.8848 - val_loss: 0.2438\n",
      "Epoch 21/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8936 - loss: 0.2275 - val_accuracy: 0.8881 - val_loss: 0.2458\n",
      "Epoch 22/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8972 - loss: 0.2249 - val_accuracy: 0.8823 - val_loss: 0.2437\n",
      "Epoch 23/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.2225 - val_accuracy: 0.8825 - val_loss: 0.2443\n",
      "Epoch 24/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8953 - loss: 0.2249 - val_accuracy: 0.8870 - val_loss: 0.2434\n",
      "Epoch 25/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8952 - loss: 0.2293 - val_accuracy: 0.8866 - val_loss: 0.2426\n",
      "Epoch 26/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8949 - loss: 0.2248 - val_accuracy: 0.8862 - val_loss: 0.2447\n",
      "Epoch 27/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8973 - loss: 0.2196 - val_accuracy: 0.8868 - val_loss: 0.2416\n",
      "Epoch 28/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8972 - loss: 0.2239 - val_accuracy: 0.8840 - val_loss: 0.2422\n",
      "Epoch 29/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8975 - loss: 0.2273 - val_accuracy: 0.8862 - val_loss: 0.2408\n",
      "Epoch 30/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9007 - loss: 0.2132 - val_accuracy: 0.8846 - val_loss: 0.2436\n",
      "Epoch 31/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9002 - loss: 0.2197 - val_accuracy: 0.8852 - val_loss: 0.2421\n",
      "Epoch 32/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8936 - loss: 0.2277 - val_accuracy: 0.8850 - val_loss: 0.2421\n",
      "Epoch 33/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8952 - loss: 0.2237 - val_accuracy: 0.8860 - val_loss: 0.2410\n",
      "Epoch 34/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8991 - loss: 0.2164 - val_accuracy: 0.8850 - val_loss: 0.2405\n",
      "Epoch 35/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8927 - loss: 0.2300 - val_accuracy: 0.8840 - val_loss: 0.2431\n",
      "Epoch 36/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8970 - loss: 0.2237 - val_accuracy: 0.8879 - val_loss: 0.2411\n",
      "Epoch 37/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8960 - loss: 0.2236 - val_accuracy: 0.8858 - val_loss: 0.2406\n",
      "Epoch 38/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8987 - loss: 0.2214 - val_accuracy: 0.8834 - val_loss: 0.2410\n",
      "Epoch 39/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8963 - loss: 0.2188 - val_accuracy: 0.8870 - val_loss: 0.2394\n",
      "Epoch 40/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8985 - loss: 0.2194 - val_accuracy: 0.8825 - val_loss: 0.2441\n",
      "Epoch 41/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9004 - loss: 0.2186 - val_accuracy: 0.8877 - val_loss: 0.2410\n",
      "Epoch 42/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8951 - loss: 0.2291 - val_accuracy: 0.8864 - val_loss: 0.2404\n",
      "Epoch 43/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8983 - loss: 0.2214 - val_accuracy: 0.8838 - val_loss: 0.2401\n",
      "Epoch 44/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8960 - loss: 0.2247 - val_accuracy: 0.8870 - val_loss: 0.2400\n",
      "Epoch 45/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8967 - loss: 0.2218 - val_accuracy: 0.8850 - val_loss: 0.2420\n",
      "Epoch 46/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8972 - loss: 0.2244 - val_accuracy: 0.8875 - val_loss: 0.2405\n",
      "Epoch 47/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8971 - loss: 0.2222 - val_accuracy: 0.8860 - val_loss: 0.2398\n",
      "Epoch 48/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8986 - loss: 0.2177 - val_accuracy: 0.8850 - val_loss: 0.2410\n",
      "Epoch 49/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9005 - loss: 0.2168 - val_accuracy: 0.8858 - val_loss: 0.2439\n",
      "Epoch 50/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8992 - loss: 0.2199 - val_accuracy: 0.8881 - val_loss: 0.2427\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Model BM-8.keras - Accuracy: 0.8916038045260741\n",
      "Model BM-8.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./bank/bank_onnx/BM-8.onnx\n",
      "Loading model BM-4.keras\n",
      "Training model BM-4.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 15:54:56.512632: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:54:56.512773: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-19 15:54:56.551765: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:54:56.551870: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "/home/annemtumlin/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.9212 - val_accuracy: 0.8764 - val_loss: 0.3294\n",
      "Epoch 2/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8815 - loss: 0.3146 - val_accuracy: 0.8850 - val_loss: 0.2902\n",
      "Epoch 3/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8936 - loss: 0.2596 - val_accuracy: 0.8885 - val_loss: 0.2588\n",
      "Epoch 4/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8968 - loss: 0.2383 - val_accuracy: 0.8875 - val_loss: 0.2618\n",
      "Epoch 5/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8979 - loss: 0.2318 - val_accuracy: 0.8899 - val_loss: 0.2494\n",
      "Epoch 6/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9003 - loss: 0.2248 - val_accuracy: 0.8918 - val_loss: 0.2430\n",
      "Epoch 7/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8985 - loss: 0.2307 - val_accuracy: 0.8905 - val_loss: 0.2438\n",
      "Epoch 8/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8946 - loss: 0.2271 - val_accuracy: 0.8911 - val_loss: 0.2416\n",
      "Epoch 9/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8973 - loss: 0.2245 - val_accuracy: 0.8897 - val_loss: 0.2376\n",
      "Epoch 10/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.2151 - val_accuracy: 0.8881 - val_loss: 0.2404\n",
      "Epoch 11/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8992 - loss: 0.2236 - val_accuracy: 0.8922 - val_loss: 0.2430\n",
      "Epoch 12/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9036 - loss: 0.2161 - val_accuracy: 0.8926 - val_loss: 0.2336\n",
      "Epoch 13/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8993 - loss: 0.2174 - val_accuracy: 0.8916 - val_loss: 0.2372\n",
      "Epoch 14/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9031 - loss: 0.2144 - val_accuracy: 0.8930 - val_loss: 0.2358\n",
      "Epoch 15/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9032 - loss: 0.2158 - val_accuracy: 0.8920 - val_loss: 0.2370\n",
      "Epoch 16/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8994 - loss: 0.2190 - val_accuracy: 0.8854 - val_loss: 0.2361\n",
      "Epoch 17/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.2193 - val_accuracy: 0.8807 - val_loss: 0.2418\n",
      "Epoch 18/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.2135 - val_accuracy: 0.8891 - val_loss: 0.2335\n",
      "Epoch 19/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9046 - loss: 0.2090 - val_accuracy: 0.8870 - val_loss: 0.2377\n",
      "Epoch 20/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9026 - loss: 0.2139 - val_accuracy: 0.8913 - val_loss: 0.2324\n",
      "Epoch 21/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9011 - loss: 0.2140 - val_accuracy: 0.8860 - val_loss: 0.2332\n",
      "Epoch 22/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9006 - loss: 0.2156 - val_accuracy: 0.8868 - val_loss: 0.2357\n",
      "Epoch 23/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9053 - loss: 0.2117 - val_accuracy: 0.8827 - val_loss: 0.2365\n",
      "Epoch 24/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9075 - loss: 0.1991 - val_accuracy: 0.8926 - val_loss: 0.2375\n",
      "Epoch 25/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9053 - loss: 0.2061 - val_accuracy: 0.8846 - val_loss: 0.2332\n",
      "Epoch 26/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9051 - loss: 0.2094 - val_accuracy: 0.8895 - val_loss: 0.2313\n",
      "Epoch 27/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9051 - loss: 0.2062 - val_accuracy: 0.8856 - val_loss: 0.2374\n",
      "Epoch 28/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.2107 - val_accuracy: 0.8889 - val_loss: 0.2692\n",
      "Epoch 29/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9053 - loss: 0.2081 - val_accuracy: 0.8879 - val_loss: 0.2344\n",
      "Epoch 30/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9050 - loss: 0.2079 - val_accuracy: 0.8879 - val_loss: 0.2313\n",
      "Epoch 31/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9070 - loss: 0.2023 - val_accuracy: 0.8856 - val_loss: 0.2311\n",
      "Epoch 32/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9050 - loss: 0.2077 - val_accuracy: 0.8885 - val_loss: 0.2343\n",
      "Epoch 33/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9063 - loss: 0.2068 - val_accuracy: 0.8909 - val_loss: 0.2319\n",
      "Epoch 34/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9040 - loss: 0.2096 - val_accuracy: 0.8918 - val_loss: 0.2306\n",
      "Epoch 35/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9085 - loss: 0.2006 - val_accuracy: 0.8897 - val_loss: 0.2488\n",
      "Epoch 36/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9060 - loss: 0.2029 - val_accuracy: 0.8883 - val_loss: 0.2356\n",
      "Epoch 37/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9021 - loss: 0.2086 - val_accuracy: 0.8932 - val_loss: 0.2316\n",
      "Epoch 38/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9046 - loss: 0.2025 - val_accuracy: 0.8889 - val_loss: 0.2299\n",
      "Epoch 39/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.2029 - val_accuracy: 0.8940 - val_loss: 0.2297\n",
      "Epoch 40/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9055 - loss: 0.2038 - val_accuracy: 0.8895 - val_loss: 0.2293\n",
      "Epoch 41/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.1992 - val_accuracy: 0.8942 - val_loss: 0.2336\n",
      "Epoch 42/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.2017 - val_accuracy: 0.8940 - val_loss: 0.2376\n",
      "Epoch 43/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.2009 - val_accuracy: 0.8918 - val_loss: 0.2331\n",
      "Epoch 44/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9072 - loss: 0.1993 - val_accuracy: 0.8895 - val_loss: 0.2341\n",
      "Epoch 45/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9060 - loss: 0.2013 - val_accuracy: 0.8918 - val_loss: 0.2326\n",
      "Epoch 46/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9051 - loss: 0.2007 - val_accuracy: 0.8899 - val_loss: 0.2436\n",
      "Epoch 47/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9050 - loss: 0.2029 - val_accuracy: 0.8928 - val_loss: 0.2315\n",
      "Epoch 48/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.1967 - val_accuracy: 0.8795 - val_loss: 0.2404\n",
      "Epoch 49/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9072 - loss: 0.1942 - val_accuracy: 0.8854 - val_loss: 0.2349\n",
      "Epoch 50/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9069 - loss: 0.1957 - val_accuracy: 0.8881 - val_loss: 0.2357\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Model BM-4.keras - Accuracy: 0.8896359462118727\n",
      "Model BM-4.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./bank/bank_onnx/BM-4.onnx\n",
      "Loading model BM-3.keras\n",
      "Training model BM-3.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 15:55:42.786432: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:55:42.786522: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-19 15:55:42.818322: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:55:42.818423: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "/home/annemtumlin/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 10 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6164 - loss: 2.1814 - val_accuracy: 0.8768 - val_loss: 0.3054\n",
      "Epoch 2/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8895 - loss: 0.2856 - val_accuracy: 0.8854 - val_loss: 0.2757\n",
      "Epoch 3/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994us/step - accuracy: 0.8935 - loss: 0.2588 - val_accuracy: 0.8889 - val_loss: 0.2634\n",
      "Epoch 4/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8937 - loss: 0.2473 - val_accuracy: 0.8893 - val_loss: 0.2545\n",
      "Epoch 5/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8951 - loss: 0.2425 - val_accuracy: 0.8903 - val_loss: 0.2599\n",
      "Epoch 6/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8973 - loss: 0.2350 - val_accuracy: 0.8907 - val_loss: 0.2539\n",
      "Epoch 7/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8986 - loss: 0.2356 - val_accuracy: 0.8885 - val_loss: 0.2487\n",
      "Epoch 8/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8955 - loss: 0.2344 - val_accuracy: 0.8913 - val_loss: 0.2478\n",
      "Epoch 9/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - accuracy: 0.8997 - loss: 0.2303 - val_accuracy: 0.8901 - val_loss: 0.2460\n",
      "Epoch 10/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8999 - loss: 0.2292 - val_accuracy: 0.8891 - val_loss: 0.2557\n",
      "Epoch 11/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8981 - loss: 0.2256 - val_accuracy: 0.8916 - val_loss: 0.2426\n",
      "Epoch 12/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8995 - loss: 0.2229 - val_accuracy: 0.8903 - val_loss: 0.2504\n",
      "Epoch 13/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9001 - loss: 0.2263 - val_accuracy: 0.8893 - val_loss: 0.2451\n",
      "Epoch 14/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9038 - loss: 0.2192 - val_accuracy: 0.8913 - val_loss: 0.2435\n",
      "Epoch 15/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9020 - loss: 0.2208 - val_accuracy: 0.8866 - val_loss: 0.2452\n",
      "Epoch 16/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9022 - loss: 0.2196 - val_accuracy: 0.8924 - val_loss: 0.2385\n",
      "Epoch 17/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8983 - loss: 0.2241 - val_accuracy: 0.8916 - val_loss: 0.2400\n",
      "Epoch 18/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9041 - loss: 0.2181 - val_accuracy: 0.8899 - val_loss: 0.2374\n",
      "Epoch 19/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1000us/step - accuracy: 0.9031 - loss: 0.2142 - val_accuracy: 0.8946 - val_loss: 0.2374\n",
      "Epoch 20/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1000us/step - accuracy: 0.9008 - loss: 0.2182 - val_accuracy: 0.8916 - val_loss: 0.2364\n",
      "Epoch 21/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9067 - loss: 0.2122 - val_accuracy: 0.8881 - val_loss: 0.2405\n",
      "Epoch 22/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967us/step - accuracy: 0.9063 - loss: 0.2104 - val_accuracy: 0.8870 - val_loss: 0.2439\n",
      "Epoch 23/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - accuracy: 0.9016 - loss: 0.2200 - val_accuracy: 0.8907 - val_loss: 0.2391\n",
      "Epoch 24/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9012 - loss: 0.2175 - val_accuracy: 0.8930 - val_loss: 0.2361\n",
      "Epoch 25/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9038 - loss: 0.2164 - val_accuracy: 0.8920 - val_loss: 0.2357\n",
      "Epoch 26/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9055 - loss: 0.2092 - val_accuracy: 0.8891 - val_loss: 0.2357\n",
      "Epoch 27/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8999 - loss: 0.2162 - val_accuracy: 0.8895 - val_loss: 0.2357\n",
      "Epoch 28/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9035 - loss: 0.2138 - val_accuracy: 0.8866 - val_loss: 0.2404\n",
      "Epoch 29/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9003 - loss: 0.2163 - val_accuracy: 0.8916 - val_loss: 0.2334\n",
      "Epoch 30/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9059 - loss: 0.2106 - val_accuracy: 0.8928 - val_loss: 0.2343\n",
      "Epoch 31/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9050 - loss: 0.2075 - val_accuracy: 0.8916 - val_loss: 0.2347\n",
      "Epoch 32/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9063 - loss: 0.2080 - val_accuracy: 0.8913 - val_loss: 0.2373\n",
      "Epoch 33/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9011 - loss: 0.2159 - val_accuracy: 0.8870 - val_loss: 0.2389\n",
      "Epoch 34/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9051 - loss: 0.2113 - val_accuracy: 0.8891 - val_loss: 0.2398\n",
      "Epoch 35/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9031 - loss: 0.2133 - val_accuracy: 0.8932 - val_loss: 0.2354\n",
      "Epoch 36/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9076 - loss: 0.2089 - val_accuracy: 0.8893 - val_loss: 0.2397\n",
      "Epoch 37/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9022 - loss: 0.2159 - val_accuracy: 0.8852 - val_loss: 0.2447\n",
      "Epoch 38/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9053 - loss: 0.2088 - val_accuracy: 0.8901 - val_loss: 0.2374\n",
      "Epoch 39/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - accuracy: 0.9026 - loss: 0.2127 - val_accuracy: 0.8899 - val_loss: 0.2378\n",
      "Epoch 40/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9032 - loss: 0.2083 - val_accuracy: 0.8916 - val_loss: 0.2362\n",
      "Epoch 41/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9088 - loss: 0.2028 - val_accuracy: 0.8922 - val_loss: 0.2344\n",
      "Epoch 42/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9033 - loss: 0.2107 - val_accuracy: 0.8858 - val_loss: 0.2425\n",
      "Epoch 43/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.2063 - val_accuracy: 0.8891 - val_loss: 0.2358\n",
      "Epoch 44/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9061 - loss: 0.2061 - val_accuracy: 0.8922 - val_loss: 0.2359\n",
      "Epoch 45/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9053 - loss: 0.2085 - val_accuracy: 0.8942 - val_loss: 0.2366\n",
      "Epoch 46/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8993 - loss: 0.2174 - val_accuracy: 0.8938 - val_loss: 0.2358\n",
      "Epoch 47/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9057 - loss: 0.2044 - val_accuracy: 0.8909 - val_loss: 0.2352\n",
      "Epoch 48/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9073 - loss: 0.2087 - val_accuracy: 0.8913 - val_loss: 0.2363\n",
      "Epoch 49/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9046 - loss: 0.2028 - val_accuracy: 0.8870 - val_loss: 0.2379\n",
      "Epoch 50/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9048 - loss: 0.2100 - val_accuracy: 0.8930 - val_loss: 0.2386\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step\n",
      "Model BM-3.keras - Accuracy: 0.8934076746474254\n",
      "Model BM-3.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./bank/bank_onnx/BM-3.onnx\n",
      "Loading model BM-2.keras\n",
      "Training model BM-2.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 15:56:20.287058: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:56:20.287149: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-19 15:56:20.306438: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:56:20.306528: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "/home/annemtumlin/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.6006 - val_accuracy: 0.8676 - val_loss: 0.3525\n",
      "Epoch 2/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8765 - loss: 0.3296 - val_accuracy: 0.8797 - val_loss: 0.2976\n",
      "Epoch 3/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8851 - loss: 0.2897 - val_accuracy: 0.8854 - val_loss: 0.2814\n",
      "Epoch 4/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8887 - loss: 0.2714 - val_accuracy: 0.8852 - val_loss: 0.2789\n",
      "Epoch 5/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8900 - loss: 0.2608 - val_accuracy: 0.8883 - val_loss: 0.2584\n",
      "Epoch 6/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8947 - loss: 0.2511 - val_accuracy: 0.8897 - val_loss: 0.2570\n",
      "Epoch 7/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.2380 - val_accuracy: 0.8907 - val_loss: 0.2533\n",
      "Epoch 8/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8903 - loss: 0.2487 - val_accuracy: 0.8893 - val_loss: 0.2538\n",
      "Epoch 9/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8982 - loss: 0.2382 - val_accuracy: 0.8893 - val_loss: 0.2559\n",
      "Epoch 10/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8968 - loss: 0.2413 - val_accuracy: 0.8905 - val_loss: 0.2541\n",
      "Epoch 11/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8953 - loss: 0.2407 - val_accuracy: 0.8911 - val_loss: 0.2517\n",
      "Epoch 12/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8973 - loss: 0.2367 - val_accuracy: 0.8889 - val_loss: 0.2544\n",
      "Epoch 13/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8943 - loss: 0.2440 - val_accuracy: 0.8903 - val_loss: 0.2479\n",
      "Epoch 14/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8959 - loss: 0.2396 - val_accuracy: 0.8889 - val_loss: 0.2523\n",
      "Epoch 15/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9032 - loss: 0.2251 - val_accuracy: 0.8870 - val_loss: 0.2608\n",
      "Epoch 16/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8989 - loss: 0.2310 - val_accuracy: 0.8889 - val_loss: 0.2625\n",
      "Epoch 17/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8980 - loss: 0.2315 - val_accuracy: 0.8899 - val_loss: 0.2449\n",
      "Epoch 18/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.2289 - val_accuracy: 0.8911 - val_loss: 0.2428\n",
      "Epoch 19/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8969 - loss: 0.2285 - val_accuracy: 0.8872 - val_loss: 0.2537\n",
      "Epoch 20/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8973 - loss: 0.2262 - val_accuracy: 0.8891 - val_loss: 0.2439\n",
      "Epoch 21/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8999 - loss: 0.2259 - val_accuracy: 0.8922 - val_loss: 0.2423\n",
      "Epoch 22/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8964 - loss: 0.2321 - val_accuracy: 0.8889 - val_loss: 0.2499\n",
      "Epoch 23/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9025 - loss: 0.2207 - val_accuracy: 0.8920 - val_loss: 0.2391\n",
      "Epoch 24/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9009 - loss: 0.2220 - val_accuracy: 0.8889 - val_loss: 0.2443\n",
      "Epoch 25/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8980 - loss: 0.2289 - val_accuracy: 0.8877 - val_loss: 0.2460\n",
      "Epoch 26/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8993 - loss: 0.2276 - val_accuracy: 0.8936 - val_loss: 0.2400\n",
      "Epoch 27/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9030 - loss: 0.2220 - val_accuracy: 0.8918 - val_loss: 0.2411\n",
      "Epoch 28/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9026 - loss: 0.2212 - val_accuracy: 0.8924 - val_loss: 0.2380\n",
      "Epoch 29/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9048 - loss: 0.2197 - val_accuracy: 0.8916 - val_loss: 0.2382\n",
      "Epoch 30/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.2125 - val_accuracy: 0.8838 - val_loss: 0.2533\n",
      "Epoch 31/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9004 - loss: 0.2211 - val_accuracy: 0.8920 - val_loss: 0.2388\n",
      "Epoch 32/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9036 - loss: 0.2153 - val_accuracy: 0.8901 - val_loss: 0.2388\n",
      "Epoch 33/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9048 - loss: 0.2133 - val_accuracy: 0.8764 - val_loss: 0.2561\n",
      "Epoch 34/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8978 - loss: 0.2231 - val_accuracy: 0.8911 - val_loss: 0.2382\n",
      "Epoch 35/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9001 - loss: 0.2198 - val_accuracy: 0.8909 - val_loss: 0.2381\n",
      "Epoch 36/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.2164 - val_accuracy: 0.8918 - val_loss: 0.2377\n",
      "Epoch 37/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9031 - loss: 0.2139 - val_accuracy: 0.8834 - val_loss: 0.2487\n",
      "Epoch 38/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9038 - loss: 0.2194 - val_accuracy: 0.8895 - val_loss: 0.2399\n",
      "Epoch 39/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8990 - loss: 0.2248 - val_accuracy: 0.8866 - val_loss: 0.2401\n",
      "Epoch 40/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9006 - loss: 0.2191 - val_accuracy: 0.8875 - val_loss: 0.2394\n",
      "Epoch 41/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8988 - loss: 0.2173 - val_accuracy: 0.8918 - val_loss: 0.2370\n",
      "Epoch 42/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9042 - loss: 0.2169 - val_accuracy: 0.8920 - val_loss: 0.2375\n",
      "Epoch 43/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9048 - loss: 0.2151 - val_accuracy: 0.8891 - val_loss: 0.2405\n",
      "Epoch 44/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8989 - loss: 0.2197 - val_accuracy: 0.8913 - val_loss: 0.2365\n",
      "Epoch 45/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9042 - loss: 0.2169 - val_accuracy: 0.8916 - val_loss: 0.2371\n",
      "Epoch 46/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8996 - loss: 0.2190 - val_accuracy: 0.8883 - val_loss: 0.2390\n",
      "Epoch 47/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9027 - loss: 0.2216 - val_accuracy: 0.8911 - val_loss: 0.2356\n",
      "Epoch 48/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9030 - loss: 0.2150 - val_accuracy: 0.8905 - val_loss: 0.2358\n",
      "Epoch 49/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9025 - loss: 0.2143 - val_accuracy: 0.8924 - val_loss: 0.2356\n",
      "Epoch 50/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9024 - loss: 0.2169 - val_accuracy: 0.8881 - val_loss: 0.2473\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n",
      "Model BM-2.keras - Accuracy: 0.8855362413906199\n",
      "Model BM-2.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./bank/bank_onnx/BM-2.onnx\n",
      "Loading model BM-1.keras\n",
      "Training model BM-1.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 15:56:57.261902: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:56:57.261989: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-19 15:56:57.282848: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:56:57.282965: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "/home/annemtumlin/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8654 - loss: 2.1468 - val_accuracy: 0.8692 - val_loss: 0.3443\n",
      "Epoch 2/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8722 - loss: 0.3309 - val_accuracy: 0.8711 - val_loss: 0.3337\n",
      "Epoch 3/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8762 - loss: 0.3210 - val_accuracy: 0.8729 - val_loss: 0.3282\n",
      "Epoch 4/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8829 - loss: 0.3106 - val_accuracy: 0.8745 - val_loss: 0.3195\n",
      "Epoch 5/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8797 - loss: 0.3073 - val_accuracy: 0.8793 - val_loss: 0.3069\n",
      "Epoch 6/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8880 - loss: 0.2880 - val_accuracy: 0.8838 - val_loss: 0.2779\n",
      "Epoch 7/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8877 - loss: 0.2678 - val_accuracy: 0.8881 - val_loss: 0.2565\n",
      "Epoch 8/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8930 - loss: 0.2405 - val_accuracy: 0.8823 - val_loss: 0.2551\n",
      "Epoch 9/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8972 - loss: 0.2325 - val_accuracy: 0.8848 - val_loss: 0.2455\n",
      "Epoch 10/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8993 - loss: 0.2251 - val_accuracy: 0.8860 - val_loss: 0.2446\n",
      "Epoch 11/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9036 - loss: 0.2173 - val_accuracy: 0.8852 - val_loss: 0.2435\n",
      "Epoch 12/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8943 - loss: 0.2297 - val_accuracy: 0.8858 - val_loss: 0.2427\n",
      "Epoch 13/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8986 - loss: 0.2244 - val_accuracy: 0.8866 - val_loss: 0.2455\n",
      "Epoch 14/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8956 - loss: 0.2296 - val_accuracy: 0.8844 - val_loss: 0.2420\n",
      "Epoch 15/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8925 - loss: 0.2361 - val_accuracy: 0.8860 - val_loss: 0.2423\n",
      "Epoch 16/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8964 - loss: 0.2296 - val_accuracy: 0.8829 - val_loss: 0.2436\n",
      "Epoch 17/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8959 - loss: 0.2270 - val_accuracy: 0.8807 - val_loss: 0.2440\n",
      "Epoch 18/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8966 - loss: 0.2232 - val_accuracy: 0.8799 - val_loss: 0.2469\n",
      "Epoch 19/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8975 - loss: 0.2248 - val_accuracy: 0.8895 - val_loss: 0.2439\n",
      "Epoch 20/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8978 - loss: 0.2248 - val_accuracy: 0.8893 - val_loss: 0.2428\n",
      "Epoch 21/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9009 - loss: 0.2215 - val_accuracy: 0.8870 - val_loss: 0.2400\n",
      "Epoch 22/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9006 - loss: 0.2202 - val_accuracy: 0.8811 - val_loss: 0.2438\n",
      "Epoch 23/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.2234 - val_accuracy: 0.8836 - val_loss: 0.2422\n",
      "Epoch 24/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.2225 - val_accuracy: 0.8881 - val_loss: 0.2402\n",
      "Epoch 25/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.2217 - val_accuracy: 0.8875 - val_loss: 0.2401\n",
      "Epoch 26/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8955 - loss: 0.2253 - val_accuracy: 0.8885 - val_loss: 0.2402\n",
      "Epoch 27/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8981 - loss: 0.2259 - val_accuracy: 0.8860 - val_loss: 0.2400\n",
      "Epoch 28/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9006 - loss: 0.2201 - val_accuracy: 0.8881 - val_loss: 0.2400\n",
      "Epoch 29/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8999 - loss: 0.2210 - val_accuracy: 0.8872 - val_loss: 0.2396\n",
      "Epoch 30/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8972 - loss: 0.2205 - val_accuracy: 0.8877 - val_loss: 0.2404\n",
      "Epoch 31/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8974 - loss: 0.2269 - val_accuracy: 0.8930 - val_loss: 0.2443\n",
      "Epoch 32/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9003 - loss: 0.2242 - val_accuracy: 0.8850 - val_loss: 0.2423\n",
      "Epoch 33/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.2221 - val_accuracy: 0.8875 - val_loss: 0.2393\n",
      "Epoch 34/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8986 - loss: 0.2217 - val_accuracy: 0.8922 - val_loss: 0.2403\n",
      "Epoch 35/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9007 - loss: 0.2228 - val_accuracy: 0.8887 - val_loss: 0.2398\n",
      "Epoch 36/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.2305 - val_accuracy: 0.8881 - val_loss: 0.2392\n",
      "Epoch 37/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9020 - loss: 0.2186 - val_accuracy: 0.8899 - val_loss: 0.2413\n",
      "Epoch 38/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8985 - loss: 0.2234 - val_accuracy: 0.8866 - val_loss: 0.2394\n",
      "Epoch 39/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9029 - loss: 0.2152 - val_accuracy: 0.8881 - val_loss: 0.2396\n",
      "Epoch 40/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9069 - loss: 0.2122 - val_accuracy: 0.8870 - val_loss: 0.2389\n",
      "Epoch 41/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8997 - loss: 0.2206 - val_accuracy: 0.8889 - val_loss: 0.2387\n",
      "Epoch 42/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9029 - loss: 0.2168 - val_accuracy: 0.8905 - val_loss: 0.2386\n",
      "Epoch 43/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9068 - loss: 0.2168 - val_accuracy: 0.8866 - val_loss: 0.2392\n",
      "Epoch 44/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8975 - loss: 0.2252 - val_accuracy: 0.8907 - val_loss: 0.2398\n",
      "Epoch 45/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9061 - loss: 0.2147 - val_accuracy: 0.8856 - val_loss: 0.2405\n",
      "Epoch 46/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8998 - loss: 0.2228 - val_accuracy: 0.8893 - val_loss: 0.2392\n",
      "Epoch 47/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9004 - loss: 0.2208 - val_accuracy: 0.8875 - val_loss: 0.2391\n",
      "Epoch 48/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8991 - loss: 0.2230 - val_accuracy: 0.8864 - val_loss: 0.2384\n",
      "Epoch 49/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9021 - loss: 0.2171 - val_accuracy: 0.8885 - val_loss: 0.2390\n",
      "Epoch 50/50\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9017 - loss: 0.2207 - val_accuracy: 0.8877 - val_loss: 0.2389\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step\n",
      "Model BM-1.keras - Accuracy: 0.8907838635618236\n",
      "Model BM-1.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./bank/bank_onnx/BM-1.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 15:57:35.946426: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:57:35.946526: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-19 15:57:35.970757: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-19 15:57:35.970968: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the Bank dataset\n",
    "X_train, X_test, y_train, y_test = load_and_save_bank_data()\n",
    "\n",
    "for model_file in os.listdir(save_dir):\n",
    "    if model_file.endswith('.keras'):\n",
    "        model_path = os.path.join(save_dir, model_file)\n",
    "        \n",
    "        try:\n",
    "            # Load the modified model\n",
    "            print(f\"Loading model {model_file}\")\n",
    "            # with warnings.catch_warnings():\n",
    "            #     warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "            model = load_model(model_path)\n",
    "\n",
    "            # Reinitialize the optimizer\n",
    "            model.compile(\n",
    "                optimizer=Adam(),\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "            # Fit the model\n",
    "            print(f\"Training model {model_file}\")\n",
    "            history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "            # Evaluate the model\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "            accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred_classes)\n",
    "\n",
    "            print(f\"Model {model_file} - Accuracy: {accuracy}\")\n",
    "\n",
    "            # Save the retrained model\n",
    "            model.save(model_path)\n",
    "            print(f\"Model {model_file} retrained and saved successfully.\")\n",
    "\n",
    "            # Save the model as ONNX\n",
    "            onnx_save_path = os.path.join(onnx_save_dir, model_file.replace('.keras', '.onnx'))\n",
    "            save_model_onnx(model, (16,), onnx_save_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {model_file}. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
