{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to process Adult Census data, edit/train models, and perform adversarial debiasing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary libraries for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.utils import to_categorical\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.onnx\n",
    "from scipy.io import savemat\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_adult_adf():\n",
    "    # Define paths and column names\n",
    "    train_path = '../data/adult/adult.data' \n",
    "    test_path = '../data/adult/adult.test'\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "    # Load data\n",
    "    train = pd.read_csv(train_path, names=column_names, na_values='?')\n",
    "    test = pd.read_csv(test_path, names=column_names, na_values='?', skiprows=1)\n",
    "\n",
    "    # Combine and preprocess\n",
    "    df = pd.concat([train, test], ignore_index=True)\n",
    "    df.drop(columns=['fnlwgt'], inplace=True) # 'education-num'\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Encode categorical features\n",
    "    categorical_features = ['workclass', 'education', 'marital-status', 'occupation', \n",
    "                            'relationship', 'race', 'sex', 'native-country']\n",
    "    for col in categorical_features:\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "    \n",
    "    # Ensure 'income' is correctly labeled\n",
    "    df['income'] = df['income'].apply(lambda x: 1 if '>50K' in x.strip() else 0)\n",
    "\n",
    "    # Split the data\n",
    "    X = df.drop('income', axis=1)\n",
    "    y = to_categorical(df['income'], num_classes=2)\n",
    "    \n",
    "    # Extract the protected attribute ('sex')\n",
    "    protected_attribute = X['sex'].values\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test, protected_train, protected_test = train_test_split(\n",
    "        X, y, protected_attribute, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, protected_train, protected_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves data for use in verification\n",
    "def load_and_save_adult_data():\n",
    "    X_train, X_test, y_train, y_test,_,_ = load_adult_adf() \n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Prepare data dictionary to save as .mat file\n",
    "    data_dict = {\n",
    "        'X': X_test,  \n",
    "        'y': y_test   \n",
    "    }\n",
    "    \n",
    "    # Save to .mat file for use in MATLAB\n",
    "    savemat(\"adult_fairify_data.mat\", data_dict)\n",
    "    print(\"Data saved to adult_fairify_data.mat\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Editing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to save the models as onnx files for verification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model as ONNX format\n",
    "def save_model_onnx(model, input_shape, onnx_file_path):\n",
    "    # Create a dummy input tensor with the correct input shape (batch_size, input_shape)\n",
    "    dummy_input = tf.random.normal([1] + list(input_shape))\n",
    "\n",
    "    # Convert the model to ONNX\n",
    "    model_proto, external_tensor_storage = tf2onnx.convert.from_keras(model, \n",
    "                                                                      input_signature=(tf.TensorSpec(shape=[None] + list(input_shape), dtype=tf.float32),),\n",
    "                                                                      opset=13)\n",
    "    \n",
    "    # Save the ONNX model to the specified path\n",
    "    with open(onnx_file_path, \"wb\") as f:\n",
    "        f.write(model_proto.SerializeToString())\n",
    "    \n",
    "    print(f\"Model has been saved in ONNX format at {onnx_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the models so they are able to be used in FairNNV. FairNNV cannot handle sigmoid so shift to softmax and adjust final layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './adult/adult_h5'\n",
    "save_dir = './adult/adult_keras'\n",
    "onnx_save_dir = './adult/adult_onnx'\n",
    "num_classes = 2\n",
    "\n",
    "# Ensure the save directories exist\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "if not os.path.exists(onnx_save_dir):\n",
    "    os.makedirs(onnx_save_dir)\n",
    "\n",
    "def modify_model_for_multiclass(model_path, num_classes):\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Create a new input layer with the correct shape\n",
    "    new_input = tf.keras.layers.Input(shape=(13,))\n",
    "    x = new_input\n",
    "\n",
    "    # Transfer the layers except the last one\n",
    "    for layer in model.layers[:-1]:\n",
    "        x = layer(x)\n",
    "\n",
    "    # Create a new output layer\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='softmax', name='new_output')(x)\n",
    "    \n",
    "    # Create a new model\n",
    "    new_model = tf.keras.models.Model(inputs=new_input, outputs=output)\n",
    "    \n",
    "    return new_model\n",
    "\n",
    "# Modify each model in the directory to remove sigmoid\n",
    "for model_file in os.listdir(model_dir):\n",
    "    if model_file.endswith('.h5'):\n",
    "        model_path = os.path.join(model_dir, model_file)\n",
    "        new_model = modify_model_for_multiclass(model_path, num_classes)\n",
    "        \n",
    "        # Update the model's loss function\n",
    "        new_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Save the modified model\n",
    "        save_path = os.path.join(save_dir, model_file.replace('.h5', '.keras'))\n",
    "        new_model.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-train models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test,_,_ = load_adult_adf()\n",
    "\n",
    "for model_file in os.listdir(save_dir):\n",
    "    if model_file.endswith('.keras'):\n",
    "        model_path = os.path.join(save_dir, model_file)\n",
    "        \n",
    "        try:\n",
    "            # Load the modified model\n",
    "            print(f\"Loading model {model_file}\")\n",
    "            model = load_model(model_path)\n",
    "\n",
    "            # Compile the model\n",
    "            model.compile(\n",
    "                optimizer=Adam(),\n",
    "                loss='categorical_crossentropy',  # Update loss function if needed\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "            # Fit the model\n",
    "            print(f\"Training model {model_file}\")\n",
    "            history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "            # Evaluate the model\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "            accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred_classes)\n",
    "\n",
    "            print(f\"Model {model_file} - Accuracy: {accuracy}\")\n",
    "            # Save the retrained model\n",
    "            model.save(model_path)\n",
    "            print(f\"Model {model_file} retrained and saved successfully.\")\n",
    "\n",
    "             # Save the model as ONNX\n",
    "            onnx_save_path = os.path.join(onnx_save_dir, model_file.replace('.keras', '.onnx'))\n",
    "            save_model_onnx(model, (13,), onnx_save_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {model_file}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To determine which adversarial debiasing framework to run to collect results\n",
    "multiple_runs = True\n",
    "singular_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save model metrics to csv\n",
    "def save_metrics_to_csv(filename, model_file, model_name, classification_accuracy, balanced_accuracy, disparate_impact, equal_opportunity_difference, average_odds_difference,precision,recall,f1):\n",
    "    # Check if the file exists to write the header only once\n",
    "    file_exists = os.path.isfile(filename)\n",
    "\n",
    "    with open(filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            # Write the header if the file does not exist\n",
    "            writer.writerow(['Model File', 'Model', 'Classification Accuracy', 'Balanced Accuracy', 'Disparate Impact', 'Equal Opportunity Difference', 'Average Odds Difference', 'Precision', 'Recall','F1'])\n",
    "        \n",
    "        # Write the metrics\n",
    "        writer.writerow([model_file, model_name, classification_accuracy, balanced_accuracy, disparate_impact, equal_opportunity_difference, average_odds_difference, precision, recall, f1])\n",
    "\n",
    "# function to save the mean/std dev of model metrics for multiple runs to csv\n",
    "def save_metrics_to_csv_mr(filename, model_name, model_type, means, stds):\n",
    "    headers = [\n",
    "        'model_name', 'model_type', 'metric', 'mean', 'std_dev'\n",
    "    ]\n",
    "    with open(filename, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if os.path.getsize(filename) == 0:\n",
    "            writer.writerow(headers)\n",
    "        for metric, mean_value in means.items():\n",
    "            writer.writerow([model_name, model_type, metric, mean_value, stds[metric]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various metrics for evaluation including accuracy and fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Metrics calculation functions\n",
    "def precision(y_true, y_pred, average='binary'):\n",
    "    return precision_score(y_true, y_pred, average=average)\n",
    "\n",
    "def recall(y_true, y_pred, average='binary'):\n",
    "    return recall_score(y_true, y_pred, average=average)\n",
    "\n",
    "def f1(y_true, y_pred, average='binary'):\n",
    "    return f1_score(y_true, y_pred, average=average)\n",
    "\n",
    "def classification_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    classes = np.unique(y_true)\n",
    "    recall_scores = []\n",
    "    for cls in classes:\n",
    "        true_positives = np.sum((y_true == cls) & (y_pred == cls))\n",
    "        possible_positives = np.sum(y_true == cls)\n",
    "        recall_scores.append(true_positives / possible_positives)\n",
    "    return np.mean(recall_scores)\n",
    "\n",
    "def disparate_impact(y_true, y_pred, protected_attribute):\n",
    "    privileged = protected_attribute == 1\n",
    "    unprivileged = protected_attribute == 0\n",
    "    if np.sum(privileged) == 0 or np.sum(unprivileged) == 0:\n",
    "        return np.nan\n",
    "    privileged_outcome = np.mean(y_pred[privileged]) if np.sum(privileged) > 0 else np.nan\n",
    "    unprivileged_outcome = np.mean(y_pred[unprivileged]) if np.sum(unprivileged) > 0 else np.nan\n",
    "    if privileged_outcome == 0:\n",
    "        return np.nan  \n",
    "    return unprivileged_outcome / privileged_outcome\n",
    "\n",
    "def equal_opportunity_difference(y_true, y_pred, protected_attribute):\n",
    "    privileged = protected_attribute == 1\n",
    "    unprivileged = protected_attribute == 0\n",
    "    true_positive_rate_privileged = np.sum((y_true[privileged] == 1) & (y_pred[privileged] == 1)) / np.sum(y_true[privileged] == 1)\n",
    "    true_positive_rate_unprivileged = np.sum((y_true[unprivileged] == 1) & (y_pred[unprivileged] == 1)) / np.sum(y_true[unprivileged] == 1)\n",
    "    return true_positive_rate_unprivileged - true_positive_rate_privileged\n",
    "\n",
    "def average_odds_difference(y_true, y_pred, protected_attribute):\n",
    "    privileged = protected_attribute == 1\n",
    "    unprivileged = protected_attribute == 0\n",
    "    tpr_privileged = np.sum((y_true[privileged] == 1) & (y_pred[privileged] == 1)) / np.sum(y_true[privileged] == 1)\n",
    "    tpr_unprivileged = np.sum((y_true[unprivileged] == 1) & (y_pred[unprivileged] == 1)) / np.sum(y_true[unprivileged] == 1)\n",
    "    fpr_privileged = np.sum((y_true[privileged] == 0) & (y_pred[privileged] == 1)) / np.sum(y_true[privileged] == 0)\n",
    "    fpr_unprivileged = np.sum((y_true[unprivileged] == 0) & (y_pred[unprivileged] == 1)) / np.sum(y_true[unprivileged] == 0)\n",
    "    average_odds_privileged = (tpr_privileged + fpr_privileged) / 2\n",
    "    average_odds_unprivileged = (tpr_unprivileged + fpr_unprivileged) / 2\n",
    "    return average_odds_unprivileged - average_odds_privileged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adversarial debiasing code for one run of each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if singular_run:\n",
    "    def build_adversary_model(input_shape):\n",
    "        adversary_input = layers.Input(shape=input_shape)\n",
    "        x = layers.Dense(64, activation='relu')(adversary_input)\n",
    "        x = layers.Dense(32, activation='relu')(x)\n",
    "        adversary_output = layers.Dense(1, activation='sigmoid')(x)\n",
    "        adversary_model = models.Model(inputs=adversary_input, outputs=adversary_output)\n",
    "        adversary_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "        return adversary_model\n",
    "\n",
    "    # Directory paths\n",
    "    input_directory = './adult/adult_keras'\n",
    "    output_directory = './adult/adult_debiased_onnx'\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Load and preprocess the data\n",
    "    X_train, X_test, y_train, y_test, protected_train, protected_test = load_adult_adf()\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    metrics_filename = './model_metrics/adult_model_metrics.csv'\n",
    "\n",
    "    # List of models to process\n",
    "    model_list = ['AC-1', 'AC-4', 'AC-5', 'AC-10', 'AC-3']\n",
    "\n",
    "    # Iterate over all .keras files in the input directory to convert to ONNX file\n",
    "    for file in os.listdir(input_directory):\n",
    "        if file.endswith('.keras') and any(model in file for model in model_list):\n",
    "            # Full path to the current model file\n",
    "            input_path = os.path.join(input_directory, file)\n",
    "            output_path = os.path.join(output_directory, file.replace('.keras', '.onnx'))\n",
    "\n",
    "            try:\n",
    "                # Load the model\n",
    "                print(f\"Loading model from {input_path}\")\n",
    "                classifier_model = load_model(input_path)\n",
    "\n",
    "                # Ensure the model is compiled with the correct optimizer and metrics\n",
    "                classifier_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "                # Print metrics for plain model\n",
    "                y_test_pred_plain = classifier_model.predict(X_test).argmax(axis=1)\n",
    "                y_test_true = y_test.argmax(axis=1)\n",
    "\n",
    "                plain_classification_accuracy = classification_accuracy(y_test_true, y_test_pred_plain)\n",
    "                plain_balanced_accuracy = balanced_accuracy(y_test_true, y_test_pred_plain)\n",
    "                plain_disparate_impact = disparate_impact(y_test_true, y_test_pred_plain, protected_test)\n",
    "                plain_equal_opportunity_difference = equal_opportunity_difference(y_test_true, y_test_pred_plain, protected_test)\n",
    "                plain_average_odds_difference = average_odds_difference(y_test_true, y_test_pred_plain, protected_test)\n",
    "                plain_precision = precision(y_test_true, y_test_pred_plain, average='macro')  # Use 'macro' for multi-class\n",
    "                plain_recall = recall(y_test_true, y_test_pred_plain, average='macro')        # Use 'macro' for multi-class\n",
    "                plain_f1 = f1(y_test_true, y_test_pred_plain, average='macro')                # Use 'macro' for multi-class\n",
    "\n",
    "                save_metrics_to_csv(metrics_filename, file, 'Plain Model', plain_classification_accuracy, plain_balanced_accuracy, plain_disparate_impact, plain_equal_opportunity_difference, plain_average_odds_difference, plain_precision, plain_recall, plain_f1)\n",
    "                \n",
    "                # Build and compile the adversary model\n",
    "                adversary_model = build_adversary_model(classifier_model.output_shape[1:])\n",
    "\n",
    "                # Training parameters\n",
    "                num_epochs = 50\n",
    "                batch_size = 128\n",
    "                learning_rate = 0.001\n",
    "                adversary_loss_weight = 0.7\n",
    "\n",
    "                # Optimizers\n",
    "                classifier_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "                adversary_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "                # Loss functions\n",
    "                classification_loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "                adversary_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "                # Training loop\n",
    "                for epoch in range(num_epochs):\n",
    "                    # Shuffle the training data\n",
    "                    indices = np.arange(X_train.shape[0])\n",
    "                    np.random.shuffle(indices)\n",
    "                    \n",
    "                    # Mini-batch training\n",
    "                    for start in range(0, X_train.shape[0], batch_size):\n",
    "                        end = min(start + batch_size, X_train.shape[0])\n",
    "                        batch_indices = indices[start:end]\n",
    "                        \n",
    "                        X_batch = X_train[batch_indices]\n",
    "                        y_batch = y_train[batch_indices]\n",
    "                        protected_batch = protected_train[batch_indices].reshape(-1, 1)\n",
    "                        \n",
    "                        with tf.GradientTape() as classifier_tape, tf.GradientTape() as adversary_tape:\n",
    "                            # Forward pass through the classifier\n",
    "                            classifier_predictions = classifier_model(X_batch, training=True)\n",
    "                            \n",
    "                            # Forward pass through the adversary\n",
    "                            adversary_predictions = adversary_model(classifier_predictions, training=True)\n",
    "                            \n",
    "                            # Compute losses\n",
    "                            classification_loss = classification_loss_fn(y_batch, classifier_predictions)\n",
    "                            adversary_loss = adversary_loss_fn(protected_batch, adversary_predictions)\n",
    "                            total_loss = classification_loss - adversary_loss_weight * adversary_loss\n",
    "                        \n",
    "                        # Compute gradients and update classifier weights\n",
    "                        classifier_gradients = classifier_tape.gradient(total_loss, classifier_model.trainable_variables)\n",
    "                        classifier_optimizer.apply_gradients(zip(classifier_gradients, classifier_model.trainable_variables))\n",
    "                        \n",
    "                        with tf.GradientTape() as adversary_tape:\n",
    "                            # Forward pass through the classifier\n",
    "                            classifier_predictions = classifier_model(X_batch, training=True)\n",
    "                            \n",
    "                            # Forward pass through the adversary\n",
    "                            adversary_predictions = adversary_model(classifier_predictions, training=True)\n",
    "                            \n",
    "                            # Compute adversary loss\n",
    "                            adversary_loss = adversary_loss_fn(protected_batch, adversary_predictions)\n",
    "                        \n",
    "                        # Compute gradients and update adversary weights\n",
    "                        adversary_gradients = adversary_tape.gradient(adversary_loss, adversary_model.trainable_variables)\n",
    "                        adversary_optimizer.apply_gradients(zip(adversary_gradients, adversary_model.trainable_variables))\n",
    "                    \n",
    "                    print(f\"Epoch {epoch + 1}/{num_epochs}, Classification Loss: {classification_loss.numpy()}, Adversary Loss: {adversary_loss.numpy()}\")\n",
    "                \n",
    "                # Predictions for debiased model\n",
    "                y_test_pred_debiased = classifier_model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "                debiased_classification_accuracy = classification_accuracy(y_test_true, y_test_pred_debiased)\n",
    "                debiased_balanced_accuracy = balanced_accuracy(y_test_true, y_test_pred_debiased)\n",
    "                debiased_disparate_impact = disparate_impact(y_test_true, y_test_pred_debiased, protected_test)\n",
    "                debiased_equal_opportunity_difference = equal_opportunity_difference(y_test_true, y_test_pred_debiased, protected_test)\n",
    "                debiased_average_odds_difference = average_odds_difference(y_test_true, y_test_pred_debiased, protected_test)\n",
    "                debiased_precision = precision(y_test_true, y_test_pred_plain, average='macro')  # Use 'macro' for multi-class\n",
    "                debiased_recall = recall(y_test_true, y_test_pred_plain, average='macro')        # Use 'macro' for multi-class\n",
    "                debiased_f1 = f1(y_test_true, y_test_pred_plain, average='macro')                # Use 'macro' for multi-class\n",
    "                \n",
    "                save_metrics_to_csv(metrics_filename, file, 'Debiased Model', debiased_classification_accuracy, debiased_balanced_accuracy, debiased_disparate_impact, debiased_equal_opportunity_difference, debiased_average_odds_difference,debiased_precision,debiased_recall,debiased_f1)\n",
    "                \n",
    "                # Save the debiased model as ONNX\n",
    "                input_shape = (13,)  # Adjust the input shape based on your model's expected input\n",
    "                save_model_onnx(classifier_model, input_shape, output_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert {file}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Debiasing Process For Multiple Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "if multiple_runs:\n",
    "    # Number of runs\n",
    "    num_runs = 10\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True)\n",
    "\n",
    "    # Directory paths\n",
    "    input_directory = './adult/adult_keras'\n",
    "    output_directory = './adult/adult_debiased_onnx'\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Load and preprocess the data\n",
    "    X_train, X_test, y_train, y_test, protected_train, protected_test = load_adult_adf()\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    metrics_filename = './model_metrics/adult_model_metrics_multiple_runs.csv'\n",
    "\n",
    "    # List of models to process\n",
    "    model_list = ['AC-1', 'AC-4', 'AC-5', 'AC-10', 'AC-3']\n",
    "\n",
    "    # Iterate over all .keras files in the input directory to convert to ONNX file\n",
    "    for file in os.listdir(input_directory):\n",
    "        if file.endswith('.keras') and any(model in file for model in model_list):\n",
    "            input_path = os.path.join(input_directory, file)\n",
    "            output_path = os.path.join(output_directory, file.replace('.keras', '.onnx'))\n",
    "\n",
    "            try:\n",
    "                plain_metrics = {\n",
    "                    'classification_accuracy': [],\n",
    "                    'balanced_accuracy': [],\n",
    "                    'disparate_impact': [],\n",
    "                    'equal_opportunity_difference': [],\n",
    "                    'average_odds_difference': [],\n",
    "                    'precision': [],\n",
    "                    'recall': [],\n",
    "                    'f1': []\n",
    "                }\n",
    "\n",
    "                debiased_metrics = {\n",
    "                    'classification_accuracy': [],\n",
    "                    'balanced_accuracy': [],\n",
    "                    'disparate_impact': [],\n",
    "                    'equal_opportunity_difference': [],\n",
    "                    'average_odds_difference': [],\n",
    "                    'precision': [],\n",
    "                    'recall': [],\n",
    "                    'f1': []\n",
    "                }\n",
    "            \n",
    "                # Inside the loop for each .keras file\n",
    "                for run in range(num_runs):\n",
    "                    print(f\"Run {run + 1}/{num_runs}\")\n",
    "\n",
    "                    # Random seed for variability\n",
    "                    np.random.seed(run)\n",
    "                    tf.random.set_seed(run)\n",
    "\n",
    "                    # Shuffle the training data\n",
    "                    indices = np.arange(X_train.shape[0])\n",
    "                    np.random.shuffle(indices)\n",
    "                    X_train_shuffled = X_train[indices]\n",
    "                    y_train_shuffled = y_train[indices]\n",
    "                    protected_train_shuffled = protected_train[indices]\n",
    "\n",
    "                    # Load the model\n",
    "                    classifier_model = load_model(input_path)\n",
    "\n",
    "                    # Compile the model\n",
    "                    classifier_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "                    # Train the model with shuffled data\n",
    "                    classifier_model.fit(X_train_shuffled, y_train_shuffled, epochs=10, batch_size=128, verbose=0)\n",
    "\n",
    "                    # Train and evaluate the plain model\n",
    "                    y_test_pred_plain = classifier_model.predict(X_test).argmax(axis=1)\n",
    "                    y_test_true = y_test.argmax(axis=1)\n",
    "\n",
    "                    plain_metrics['classification_accuracy'].append(classification_accuracy(y_test_true, y_test_pred_plain))\n",
    "                    plain_metrics['balanced_accuracy'].append(balanced_accuracy(y_test_true, y_test_pred_plain))\n",
    "                    plain_metrics['disparate_impact'].append(disparate_impact(y_test_true, y_test_pred_plain, protected_test))\n",
    "                    plain_metrics['equal_opportunity_difference'].append(equal_opportunity_difference(y_test_true, y_test_pred_plain, protected_test))\n",
    "                    plain_metrics['average_odds_difference'].append(average_odds_difference(y_test_true, y_test_pred_plain, protected_test))\n",
    "                    plain_metrics['precision'].append(precision_score(y_test_true, y_test_pred_plain, average='macro', zero_division=1))\n",
    "                    plain_metrics['recall'].append(recall_score(y_test_true, y_test_pred_plain, average='macro'))\n",
    "                    plain_metrics['f1'].append(f1_score(y_test_true, y_test_pred_plain, average='macro'))\n",
    "\n",
    "                    # Build and compile the adversary model\n",
    "                    adversary_model = build_adversary_model(classifier_model.output_shape[1:])\n",
    "\n",
    "                    # Training parameters\n",
    "                    num_epochs = 500\n",
    "                    batch_size = 128\n",
    "                    initial_learning_rate = 0.001\n",
    "                    adversary_loss_weight_initial = 0.1\n",
    "                    adversary_loss_weight_final = 0.7\n",
    "\n",
    "                    # Optimizers\n",
    "                    classifier_optimizer = tf.keras.optimizers.Adam(initial_learning_rate)\n",
    "                    adversary_optimizer = tf.keras.optimizers.Adam(initial_learning_rate)\n",
    "\n",
    "                    # Learning rate scheduler\n",
    "                    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                        initial_learning_rate,\n",
    "                        decay_steps=10000,\n",
    "                        decay_rate=0.96,\n",
    "                        staircase=True\n",
    "                    )\n",
    "\n",
    "                    # Update the optimizer to use the learning rate scheduler\n",
    "                    classifier_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "                    adversary_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "                    # Loss functions\n",
    "                    classification_loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "                    adversary_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "                    best_val_loss = float('inf')\n",
    "                    epochs_since_best = 0\n",
    "\n",
    "                    # Training loop\n",
    "                    for epoch in range(num_epochs):\n",
    "                        # Shuffle the training data\n",
    "                        indices = np.arange(X_train.shape[0])\n",
    "                        np.random.shuffle(indices)\n",
    "\n",
    "                        # Mini-batch training\n",
    "                        epoch_train_loss = 0\n",
    "                        epoch_train_accuracy = 0\n",
    "                        num_batches = 0\n",
    "                        for start in range(0, X_train.shape[0], batch_size):\n",
    "                            end = min(start + batch_size, X_train.shape[0])\n",
    "                            batch_indices = indices[start:end]\n",
    "\n",
    "                            X_batch = X_train[batch_indices]\n",
    "                            y_batch = y_train[batch_indices]\n",
    "                            protected_batch = protected_train[batch_indices].reshape(-1, 1)\n",
    "\n",
    "                            with tf.GradientTape(persistent=True) as tape:\n",
    "                                # Forward pass through the classifier\n",
    "                                classifier_predictions = classifier_model(X_batch, training=True)\n",
    "\n",
    "                                # Forward pass through the adversary with no gradient accumulation\n",
    "                                adversary_predictions = adversary_model(classifier_predictions, training=False)\n",
    "\n",
    "                                # Compute losses\n",
    "                                classification_loss = classification_loss_fn(y_batch, classifier_predictions)\n",
    "                                adversary_loss = adversary_loss_fn(protected_batch, adversary_predictions)\n",
    "\n",
    "                                # Linearly increase the adversary loss weight over epochs\n",
    "                                adversary_loss_weight = adversary_loss_weight_initial + \\\n",
    "                                                        (adversary_loss_weight_final - adversary_loss_weight_initial) * (epoch / num_epochs)\n",
    "\n",
    "                                total_loss = classification_loss - adversary_loss_weight * adversary_loss\n",
    "\n",
    "                            # Compute gradients and update classifier weights\n",
    "                            classifier_gradients = tape.gradient(total_loss, classifier_model.trainable_variables)\n",
    "                            classifier_optimizer.apply_gradients(zip(classifier_gradients, classifier_model.trainable_variables))\n",
    "\n",
    "                            with tape:\n",
    "                                # Forward pass through the classifier\n",
    "                                classifier_predictions = classifier_model(X_batch, training=True)\n",
    "\n",
    "                                # Forward pass through the adversary\n",
    "                                adversary_predictions = adversary_model(classifier_predictions, training=True)\n",
    "\n",
    "                                # Compute adversary loss\n",
    "                                adversary_loss = adversary_loss_fn(protected_batch, adversary_predictions)\n",
    "\n",
    "                            # Compute gradients and update adversary weights\n",
    "                            adversary_vars = [var for var in adversary_model.trainable_variables]\n",
    "                            adversary_gradients = tape.gradient(adversary_loss, adversary_vars)\n",
    "                            adversary_optimizer.apply_gradients(zip(adversary_gradients, adversary_vars))\n",
    "\n",
    "                            # Accumulate training loss and accuracy\n",
    "                            epoch_train_loss += classification_loss.numpy()\n",
    "                            epoch_train_accuracy += np.mean(np.argmax(classifier_predictions, axis=1) == np.argmax(y_batch, axis=1))\n",
    "                            num_batches += 1\n",
    "\n",
    "                        print(f\"Epoch {epoch + 1}/{num_epochs}, Classification Loss: {classification_loss.numpy()}, Adversary Loss: {adversary_loss.numpy()}\")\n",
    "\n",
    "                        # Calculate average training loss and accuracy\n",
    "                        epoch_train_loss /= num_batches\n",
    "                        epoch_train_accuracy /= num_batches\n",
    "\n",
    "                        # Evaluate on validation set\n",
    "                        val_predictions = classifier_model.predict(X_test)\n",
    "                        val_loss = classification_loss_fn(y_test, val_predictions).numpy()\n",
    "                        val_accuracy = np.mean(np.argmax(val_predictions, axis=1) == np.argmax(y_test, axis=1))\n",
    "\n",
    "                        # Early stopping check\n",
    "                        if val_loss < best_val_loss:\n",
    "                            best_val_loss = val_loss\n",
    "                            epochs_since_best = 0\n",
    "                        else:\n",
    "                            epochs_since_best += 1\n",
    "                            if epochs_since_best >= early_stopping.patience:\n",
    "                                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                                break\n",
    "\n",
    "                    y_test_pred_debiased = classifier_model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "                    debiased_metrics['classification_accuracy'].append(classification_accuracy(y_test_true, y_test_pred_debiased))\n",
    "                    debiased_metrics['balanced_accuracy'].append(balanced_accuracy(y_test_true, y_test_pred_debiased))\n",
    "                    debiased_metrics['disparate_impact'].append(disparate_impact(y_test_true, y_test_pred_debiased, protected_test))\n",
    "                    debiased_metrics['equal_opportunity_difference'].append(equal_opportunity_difference(y_test_true, y_test_pred_debiased, protected_test))\n",
    "                    debiased_metrics['average_odds_difference'].append(average_odds_difference(y_test_true, y_test_pred_debiased, protected_test))\n",
    "                    debiased_metrics['precision'].append(precision_score(y_test_true, y_test_pred_debiased, average='macro', zero_division=1))\n",
    "                    debiased_metrics['recall'].append(recall_score(y_test_true, y_test_pred_debiased, average='macro'))\n",
    "                    debiased_metrics['f1'].append(f1_score(y_test_true, y_test_pred_debiased, average='macro'))\n",
    "\n",
    "                # Calculate mean and std for plain metrics\n",
    "                plain_means = {key: np.mean(values) for key, values in plain_metrics.items()}\n",
    "                plain_stds = {key: np.std(values) for key, values in plain_metrics.items()}\n",
    "\n",
    "                # Calculate mean and std for debiased metrics\n",
    "                debiased_means = {key: np.mean(values) for key, values in debiased_metrics.items()}\n",
    "                debiased_stds = {key: np.std(values) for key, values in debiased_metrics.items()}\n",
    "\n",
    "                # Save metrics to CSV\n",
    "                save_metrics_to_csv_mr(metrics_filename, file, 'Plain Model', plain_means, plain_stds)\n",
    "                save_metrics_to_csv_mr(metrics_filename, file, 'Debiased Model', debiased_means, debiased_stds)\n",
    "\n",
    "                # Save the debiased model as ONNX\n",
    "                input_shape = (20,)  # Adjust the input shape based on your model's expected input\n",
    "                save_model_onnx(classifier_model, input_shape, output_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert {file}. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
