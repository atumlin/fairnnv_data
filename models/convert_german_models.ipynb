{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to process German Credit data, edit/train models, and perform adversarial debiasing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary libraries for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 13:59:18.770131: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-11 13:59:33.124788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from scipy.io import savemat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom preprocessing function for the German dataset\n",
    "def german_custom_preprocessing(df):\n",
    "    def group_credit_hist(x):\n",
    "        if x in ['A30', 'A31', 'A32']:\n",
    "            return 'None/Paid'\n",
    "        elif x == 'A33':\n",
    "            return 'Delay'\n",
    "        elif x == 'A34':\n",
    "            return 'Other'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    def group_employ(x):\n",
    "        if x == 'A71':\n",
    "            return 'Unemployed'\n",
    "        elif x in ['A72', 'A73']:\n",
    "            return '1-4 years'\n",
    "        elif x in ['A74', 'A75']:\n",
    "            return '4+ years'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    def group_savings(x):\n",
    "        if x in ['A61', 'A62']:\n",
    "            return '<500'\n",
    "        elif x in ['A63', 'A64']:\n",
    "            return '500+'\n",
    "        elif x == 'A65':\n",
    "            return 'Unknown/None'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    def group_status(x):\n",
    "        if x in ['A11', 'A12']:\n",
    "            return '<200'\n",
    "        elif x in ['A13']:\n",
    "            return '200+'\n",
    "        elif x == 'A14':\n",
    "            return 'None'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    status_map = {'A91': 1, 'A93': 1, 'A94': 1, 'A92': 0, 'A95': 0}  # 1: 'male'\n",
    "    df['sex'] = df['personal_status'].replace(status_map)\n",
    "\n",
    "    df['credit_history'] = df['credit_history'].apply(lambda x: group_credit_hist(x))\n",
    "    df['savings'] = df['savings'].apply(lambda x: group_savings(x))\n",
    "    df['employment'] = df['employment'].apply(lambda x: group_employ(x))\n",
    "    df['status'] = df['status'].apply(lambda x: group_status(x))\n",
    "\n",
    "    df.credit.replace([1, 2], [1, 0], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_german():\n",
    "    filepath = '../data/german/german.data'\n",
    "    column_names = ['status', 'month', 'credit_history', 'purpose', 'credit_amount', 'savings', 'employment',\n",
    "                    'investment_as_income_percentage', 'personal_status', 'other_debtors', 'residence_since', \n",
    "                    'property', 'age', 'installment_plans', 'housing', 'number_of_credits', 'skill_level', \n",
    "                    'people_liable_for', 'telephone', 'foreign_worker', 'credit']\n",
    "    na_values = []\n",
    "    df = pd.read_csv(filepath, sep=' ', header=None, names=column_names, na_values=na_values)\n",
    "    \n",
    "    df = german_custom_preprocessing(df)\n",
    "    feat_to_drop = ['personal_status']\n",
    "    df = df.drop(feat_to_drop, axis=1)\n",
    "    \n",
    "    # Encode categorical features\n",
    "    cat_feat = ['status', 'credit_history', 'purpose', 'savings', 'employment', 'other_debtors', 'property', \n",
    "                'installment_plans', 'housing', 'skill_level', 'telephone', 'foreign_worker']\n",
    "    for col in cat_feat:\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "    \n",
    "    # Encode the target variable\n",
    "    label_name = 'credit'\n",
    "    \n",
    "    X = df.drop(labels=[label_name], axis=1, inplace=False)\n",
    "    y = df[label_name]\n",
    "    \n",
    "    # Extract the protected attribute ('sex')\n",
    "    protected_attribute = X['sex'].values\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    seed = 42\n",
    "    X_train, X_test, y_train, y_test, protected_train, protected_test = train_test_split(\n",
    "        X, y, protected_attribute, test_size=0.15, random_state=seed\n",
    "    )\n",
    "    \n",
    "    # One-hot encode the labels\n",
    "    y_train = to_categorical(y_train, num_classes=2)\n",
    "    y_test = to_categorical(y_test, num_classes=2)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, protected_train, protected_test\n",
    "\n",
    "# Saves data for use in verification\n",
    "def load_and_save_german_data():\n",
    "    X_train, X_test, y_train, y_test, _, _ = load_german()\n",
    "    \n",
    "    # Scaling numerical features with MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Prepare data dictionary to save as .mat file\n",
    "    data_dict = {\n",
    "        'X': X_test, \n",
    "        'y': y_test   \n",
    "    }\n",
    "    \n",
    "    # Save to .mat file for use in MATLAB\n",
    "    savemat(\"./processed_data/german_data.mat\", data_dict)\n",
    "    print(\"Data saved to german_data.mat\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Editing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to save the models as onnx files for verification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model as ONNX format\n",
    "def save_model_onnx(model, input_shape, onnx_file_path):\n",
    "    # Create a dummy input tensor with the correct input shape (batch_size, input_shape)\n",
    "    dummy_input = tf.random.normal([1] + list(input_shape))\n",
    "\n",
    "    # Convert the model to ONNX\n",
    "    model_proto, external_tensor_storage = tf2onnx.convert.from_keras(model, \n",
    "                                                                      input_signature=(tf.TensorSpec(shape=[None] + list(input_shape), dtype=tf.float32),),\n",
    "                                                                      opset=13)\n",
    "    \n",
    "    # Save the ONNX model to the specified path\n",
    "    with open(onnx_file_path, \"wb\") as f:\n",
    "        f.write(model_proto.SerializeToString())\n",
    "    \n",
    "    print(f\"Model has been saved in ONNX format at {onnx_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the models so they are able to be used in FairNNV. FairNNV cannot handle sigmoid so shift to softmax and adjust final layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Function to modify a model for multiclass classification\n",
    "def modify_model_for_multiclass(model_path, num_classes):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "        model = load_model(model_path)\n",
    "\n",
    "    # Create a new input layer with the correct shape\n",
    "    new_input = tf.keras.layers.Input(shape=(20,))\n",
    "    x = new_input\n",
    "\n",
    "    # Transfer the layers except the last one\n",
    "    for layer in model.layers[:-1]:\n",
    "        x = layer(x)\n",
    "\n",
    "    # Create a new output layer\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='softmax', name='new_output')(x)\n",
    "    \n",
    "    # Create a new model\n",
    "    new_model = tf.keras.models.Model(inputs=new_input, outputs=output)\n",
    "    \n",
    "    return new_model\n",
    "\n",
    "# Ensure the save directories exist\n",
    "model_dir = './german/german_h5'\n",
    "save_dir = './german/german_keras'\n",
    "onnx_save_dir = './german/german_onnx'\n",
    "num_classes = 2\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "if not os.path.exists(onnx_save_dir):\n",
    "    os.makedirs(onnx_save_dir)\n",
    "\n",
    "# Modify each model in the directory to remove sigmoid\n",
    "for model_file in os.listdir(model_dir):\n",
    "    if model_file.endswith('.h5'):\n",
    "        model_path = os.path.join(model_dir, model_file)\n",
    "        new_model = modify_model_for_multiclass(model_path, num_classes)\n",
    "        \n",
    "        # Update the model's loss function\n",
    "        new_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Save the modified model\n",
    "        save_path = os.path.join(save_dir, model_file.replace('.h5', '.keras'))\n",
    "        new_model.save(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-train models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to german_data.mat\n",
      "Loading model GC-1.keras\n",
      "Training model GC-1.keras\n",
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7007 - loss: 0.6246 - val_accuracy: 0.6941 - val_loss: 0.6084\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.5697 - val_accuracy: 0.7059 - val_loss: 0.5946\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7239 - loss: 0.5620 - val_accuracy: 0.7059 - val_loss: 0.5841\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6937 - loss: 0.5689 - val_accuracy: 0.6941 - val_loss: 0.5763\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7141 - loss: 0.5514 - val_accuracy: 0.6824 - val_loss: 0.5696\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5438 - val_accuracy: 0.7000 - val_loss: 0.5643\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: 0.5435 - val_accuracy: 0.7059 - val_loss: 0.5598\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.5455 - val_accuracy: 0.7059 - val_loss: 0.5560\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7502 - loss: 0.5070 - val_accuracy: 0.6941 - val_loss: 0.5545\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.5355 - val_accuracy: 0.7000 - val_loss: 0.5515\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7314 - loss: 0.5154 - val_accuracy: 0.6941 - val_loss: 0.5483\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7265 - loss: 0.5344 - val_accuracy: 0.7000 - val_loss: 0.5472\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7351 - loss: 0.5277 - val_accuracy: 0.7059 - val_loss: 0.5472\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7405 - loss: 0.5142 - val_accuracy: 0.6882 - val_loss: 0.5466\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7503 - loss: 0.4971 - val_accuracy: 0.6765 - val_loss: 0.5503\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7276 - loss: 0.5282 - val_accuracy: 0.7000 - val_loss: 0.5493\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.5338 - val_accuracy: 0.6765 - val_loss: 0.5464\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7334 - loss: 0.5140 - val_accuracy: 0.6765 - val_loss: 0.5468\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7249 - loss: 0.5321 - val_accuracy: 0.6882 - val_loss: 0.5473\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7140 - loss: 0.5356 - val_accuracy: 0.6765 - val_loss: 0.5489\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7062 - loss: 0.5423 - val_accuracy: 0.6706 - val_loss: 0.5474\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.5231 - val_accuracy: 0.6706 - val_loss: 0.5481\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7497 - loss: 0.5019 - val_accuracy: 0.7000 - val_loss: 0.5484\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7093 - loss: 0.5361 - val_accuracy: 0.6765 - val_loss: 0.5489\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7592 - loss: 0.4804 - val_accuracy: 0.7059 - val_loss: 0.5505\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7442 - loss: 0.4998 - val_accuracy: 0.6824 - val_loss: 0.5474\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.5084 - val_accuracy: 0.6882 - val_loss: 0.5492\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7603 - loss: 0.4747 - val_accuracy: 0.6941 - val_loss: 0.5486\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7436 - loss: 0.5021 - val_accuracy: 0.6882 - val_loss: 0.5493\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7639 - loss: 0.4933 - val_accuracy: 0.6765 - val_loss: 0.5491\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7480 - loss: 0.4844 - val_accuracy: 0.6882 - val_loss: 0.5497\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7487 - loss: 0.4728 - val_accuracy: 0.6882 - val_loss: 0.5504\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7395 - loss: 0.4974 - val_accuracy: 0.6824 - val_loss: 0.5499\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7422 - loss: 0.4806 - val_accuracy: 0.6882 - val_loss: 0.5512\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7518 - loss: 0.4967 - val_accuracy: 0.6941 - val_loss: 0.5509\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7488 - loss: 0.4624 - val_accuracy: 0.6882 - val_loss: 0.5511\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7656 - loss: 0.4761 - val_accuracy: 0.6824 - val_loss: 0.5531\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7591 - loss: 0.4885 - val_accuracy: 0.6882 - val_loss: 0.5546\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7691 - loss: 0.4633 - val_accuracy: 0.6941 - val_loss: 0.5540\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7620 - loss: 0.4855 - val_accuracy: 0.6824 - val_loss: 0.5525\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7562 - loss: 0.4745 - val_accuracy: 0.6765 - val_loss: 0.5536\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7533 - loss: 0.4747 - val_accuracy: 0.6882 - val_loss: 0.5529\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7602 - loss: 0.4599 - val_accuracy: 0.6941 - val_loss: 0.5534\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7427 - loss: 0.4742 - val_accuracy: 0.6824 - val_loss: 0.5526\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7656 - loss: 0.4682 - val_accuracy: 0.6765 - val_loss: 0.5528\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7714 - loss: 0.4530 - val_accuracy: 0.6882 - val_loss: 0.5553\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7401 - loss: 0.4822 - val_accuracy: 0.6706 - val_loss: 0.5535\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7819 - loss: 0.4518 - val_accuracy: 0.6765 - val_loss: 0.5533\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7556 - loss: 0.4518 - val_accuracy: 0.6882 - val_loss: 0.5542\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7577 - loss: 0.4653 - val_accuracy: 0.6882 - val_loss: 0.5540\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Model GC-1.keras - Accuracy: 0.7533333333333333\n",
      "Model GC-1.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./german/german_onnx/GC-1.onnx\n",
      "Loading model GC-2.keras\n",
      "Training model GC-2.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 14:00:13.771781: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-11 14:00:13.771873: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-11 14:00:13.790884: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-11 14:00:13.791012: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6996 - loss: 0.5965 - val_accuracy: 0.7000 - val_loss: 0.5900\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7115 - loss: 0.5607 - val_accuracy: 0.6882 - val_loss: 0.5736\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7291 - loss: 0.5471 - val_accuracy: 0.6941 - val_loss: 0.5666\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7305 - loss: 0.5354 - val_accuracy: 0.6941 - val_loss: 0.5623\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.5379 - val_accuracy: 0.6882 - val_loss: 0.5606\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.5437 - val_accuracy: 0.7000 - val_loss: 0.5577\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.5340 - val_accuracy: 0.6882 - val_loss: 0.5576\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 0.5188 - val_accuracy: 0.6941 - val_loss: 0.5575\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7310 - loss: 0.5394 - val_accuracy: 0.6882 - val_loss: 0.5576\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: 0.5291 - val_accuracy: 0.6882 - val_loss: 0.5547\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7088 - loss: 0.5197 - val_accuracy: 0.6941 - val_loss: 0.5520\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7348 - loss: 0.5154 - val_accuracy: 0.6941 - val_loss: 0.5515\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.5259 - val_accuracy: 0.6765 - val_loss: 0.5505\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7480 - loss: 0.5157 - val_accuracy: 0.6824 - val_loss: 0.5554\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7533 - loss: 0.4830 - val_accuracy: 0.6765 - val_loss: 0.5601\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7232 - loss: 0.5275 - val_accuracy: 0.6824 - val_loss: 0.5503\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7144 - loss: 0.5166 - val_accuracy: 0.6941 - val_loss: 0.5523\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7464 - loss: 0.5099 - val_accuracy: 0.6824 - val_loss: 0.5551\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7466 - loss: 0.4978 - val_accuracy: 0.6765 - val_loss: 0.5509\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7196 - loss: 0.5086 - val_accuracy: 0.6824 - val_loss: 0.5517\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7262 - loss: 0.5108 - val_accuracy: 0.6765 - val_loss: 0.5537\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7324 - loss: 0.5167 - val_accuracy: 0.6824 - val_loss: 0.5581\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7589 - loss: 0.4903 - val_accuracy: 0.6765 - val_loss: 0.5551\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7547 - loss: 0.4855 - val_accuracy: 0.6765 - val_loss: 0.5537\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7554 - loss: 0.4781 - val_accuracy: 0.6765 - val_loss: 0.5553\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7711 - loss: 0.4802 - val_accuracy: 0.6706 - val_loss: 0.5496\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7563 - loss: 0.4961 - val_accuracy: 0.7000 - val_loss: 0.5576\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7617 - loss: 0.4677 - val_accuracy: 0.6765 - val_loss: 0.5501\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7629 - loss: 0.4906 - val_accuracy: 0.6706 - val_loss: 0.5512\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7559 - loss: 0.4820 - val_accuracy: 0.6824 - val_loss: 0.5536\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7661 - loss: 0.4703 - val_accuracy: 0.6765 - val_loss: 0.5497\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7655 - loss: 0.4797 - val_accuracy: 0.7059 - val_loss: 0.5532\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7704 - loss: 0.4656 - val_accuracy: 0.6765 - val_loss: 0.5509\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7759 - loss: 0.4631 - val_accuracy: 0.6706 - val_loss: 0.5480\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7802 - loss: 0.4557 - val_accuracy: 0.6824 - val_loss: 0.5500\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7869 - loss: 0.4661 - val_accuracy: 0.6824 - val_loss: 0.5537\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7662 - loss: 0.4553 - val_accuracy: 0.6765 - val_loss: 0.5484\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7674 - loss: 0.4585 - val_accuracy: 0.6882 - val_loss: 0.5509\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8022 - loss: 0.4277 - val_accuracy: 0.6706 - val_loss: 0.5515\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7463 - loss: 0.4867 - val_accuracy: 0.6941 - val_loss: 0.5547\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7711 - loss: 0.4622 - val_accuracy: 0.6588 - val_loss: 0.5505\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7795 - loss: 0.4491 - val_accuracy: 0.6941 - val_loss: 0.5575\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7860 - loss: 0.4311 - val_accuracy: 0.6588 - val_loss: 0.5585\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7806 - loss: 0.4558 - val_accuracy: 0.6706 - val_loss: 0.5485\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.4298 - val_accuracy: 0.6471 - val_loss: 0.5510\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8078 - loss: 0.4163 - val_accuracy: 0.6588 - val_loss: 0.5521\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7940 - loss: 0.4445 - val_accuracy: 0.6529 - val_loss: 0.5527\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8043 - loss: 0.4264 - val_accuracy: 0.6647 - val_loss: 0.5503\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7794 - loss: 0.4460 - val_accuracy: 0.6765 - val_loss: 0.5495\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7987 - loss: 0.4309 - val_accuracy: 0.6529 - val_loss: 0.5491\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Model GC-2.keras - Accuracy: 0.7466666666666667\n",
      "Model GC-2.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./german/german_onnx/GC-2.onnx\n",
      "Loading model GC-3.keras\n",
      "Training model GC-3.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 14:00:17.397107: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-11 14:00:17.397195: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-11 14:00:17.419735: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-11 14:00:17.419857: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3110 - loss: 5.7657 - val_accuracy: 0.3059 - val_loss: 5.2232\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3000 - loss: 5.2054 - val_accuracy: 0.3059 - val_loss: 4.5671\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3022 - loss: 4.5166 - val_accuracy: 0.3059 - val_loss: 3.9421\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2780 - loss: 4.0788 - val_accuracy: 0.3059 - val_loss: 3.3576\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3061 - loss: 3.3241 - val_accuracy: 0.3118 - val_loss: 2.8127\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3114 - loss: 2.6889 - val_accuracy: 0.3000 - val_loss: 2.3056\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2787 - loss: 2.3304 - val_accuracy: 0.2824 - val_loss: 1.8499\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2824 - loss: 1.7799 - val_accuracy: 0.3059 - val_loss: 1.4950\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2793 - loss: 1.5114 - val_accuracy: 0.3118 - val_loss: 1.2229\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2806 - loss: 1.2001 - val_accuracy: 0.3412 - val_loss: 1.0527\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3971 - loss: 1.0484 - val_accuracy: 0.3765 - val_loss: 0.9520\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4542 - loss: 0.9531 - val_accuracy: 0.4706 - val_loss: 0.9012\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5083 - loss: 0.8960 - val_accuracy: 0.5471 - val_loss: 0.8742\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5574 - loss: 0.9043 - val_accuracy: 0.5882 - val_loss: 0.8582\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5686 - loss: 0.8696 - val_accuracy: 0.6059 - val_loss: 0.8466\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5946 - loss: 0.8665 - val_accuracy: 0.6059 - val_loss: 0.8376\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5801 - loss: 0.8571 - val_accuracy: 0.6176 - val_loss: 0.8302\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5742 - loss: 0.8908 - val_accuracy: 0.6176 - val_loss: 0.8228\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5990 - loss: 0.8503 - val_accuracy: 0.6412 - val_loss: 0.8151\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5877 - loss: 0.8641 - val_accuracy: 0.6471 - val_loss: 0.8043\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6211 - loss: 0.8052 - val_accuracy: 0.6471 - val_loss: 0.7910\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6003 - loss: 0.8239 - val_accuracy: 0.6294 - val_loss: 0.7757\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6315 - loss: 0.7685 - val_accuracy: 0.6471 - val_loss: 0.7611\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6315 - loss: 0.7546 - val_accuracy: 0.6353 - val_loss: 0.7466\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6397 - loss: 0.7501 - val_accuracy: 0.6412 - val_loss: 0.7319\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6298 - loss: 0.7629 - val_accuracy: 0.6706 - val_loss: 0.7182\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6581 - loss: 0.7132 - val_accuracy: 0.6824 - val_loss: 0.7048\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6490 - loss: 0.7205 - val_accuracy: 0.6824 - val_loss: 0.6912\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6706 - loss: 0.6718 - val_accuracy: 0.6882 - val_loss: 0.6793\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6707 - loss: 0.6799 - val_accuracy: 0.6941 - val_loss: 0.6678\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6630 - loss: 0.6761 - val_accuracy: 0.7000 - val_loss: 0.6574\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7037 - loss: 0.6339 - val_accuracy: 0.6941 - val_loss: 0.6476\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6944 - loss: 0.6315 - val_accuracy: 0.6941 - val_loss: 0.6385\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7254 - loss: 0.6027 - val_accuracy: 0.6941 - val_loss: 0.6303\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7176 - loss: 0.6081 - val_accuracy: 0.6941 - val_loss: 0.6228\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7417 - loss: 0.5691 - val_accuracy: 0.6882 - val_loss: 0.6164\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6793 - loss: 0.6183 - val_accuracy: 0.6882 - val_loss: 0.6100\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.5861 - val_accuracy: 0.6882 - val_loss: 0.6044\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7039 - loss: 0.5872 - val_accuracy: 0.6882 - val_loss: 0.5990\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: 0.5766 - val_accuracy: 0.6824 - val_loss: 0.5946\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7061 - loss: 0.5765 - val_accuracy: 0.6765 - val_loss: 0.5899\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6760 - loss: 0.5915 - val_accuracy: 0.6706 - val_loss: 0.5866\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.5716 - val_accuracy: 0.6765 - val_loss: 0.5836\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: 0.5599 - val_accuracy: 0.6765 - val_loss: 0.5801\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7179 - loss: 0.5388 - val_accuracy: 0.6765 - val_loss: 0.5775\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.5351 - val_accuracy: 0.6765 - val_loss: 0.5754\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7239 - loss: 0.5422 - val_accuracy: 0.6824 - val_loss: 0.5729\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7132 - loss: 0.5614 - val_accuracy: 0.6706 - val_loss: 0.5714\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6900 - loss: 0.5669 - val_accuracy: 0.6765 - val_loss: 0.5697\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7042 - loss: 0.5445 - val_accuracy: 0.6647 - val_loss: 0.5684\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x724b92ecfac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x724b92ecfac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x724b92ecfac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x724b92ecfac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Model GC-3.keras - Accuracy: 0.7066666666666667\n",
      "Model GC-3.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./german/german_onnx/GC-3.onnx\n",
      "Loading model GC-4.keras\n",
      "Training model GC-4.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 14:00:21.273456: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-11 14:00:21.273539: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-11 14:00:21.290779: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-11 14:00:21.290867: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6395 - loss: 0.6911 - val_accuracy: 0.6941 - val_loss: 0.6855\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7205 - loss: 0.6826 - val_accuracy: 0.6941 - val_loss: 0.6786\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6572 - loss: 0.6800 - val_accuracy: 0.6941 - val_loss: 0.6724\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.6692 - val_accuracy: 0.6941 - val_loss: 0.6660\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7050 - loss: 0.6630 - val_accuracy: 0.6941 - val_loss: 0.6608\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7050 - loss: 0.6572 - val_accuracy: 0.6941 - val_loss: 0.6556\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7067 - loss: 0.6516 - val_accuracy: 0.6941 - val_loss: 0.6513\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7180 - loss: 0.6443 - val_accuracy: 0.6941 - val_loss: 0.6477\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6971 - loss: 0.6460 - val_accuracy: 0.6941 - val_loss: 0.6442\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.6372 - val_accuracy: 0.6941 - val_loss: 0.6407\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6698 - loss: 0.6485 - val_accuracy: 0.6941 - val_loss: 0.6380\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6941 - loss: 0.6373 - val_accuracy: 0.6941 - val_loss: 0.6353\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: 0.6240 - val_accuracy: 0.6941 - val_loss: 0.6328\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7069 - loss: 0.6267 - val_accuracy: 0.6941 - val_loss: 0.6306\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6992 - loss: 0.6277 - val_accuracy: 0.6941 - val_loss: 0.6287\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7260 - loss: 0.6130 - val_accuracy: 0.6941 - val_loss: 0.6270\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7055 - loss: 0.6209 - val_accuracy: 0.6941 - val_loss: 0.6255\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7063 - loss: 0.6188 - val_accuracy: 0.6941 - val_loss: 0.6241\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6911 - loss: 0.6255 - val_accuracy: 0.6941 - val_loss: 0.6230\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7088 - loss: 0.6145 - val_accuracy: 0.6941 - val_loss: 0.6219\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6968 - loss: 0.6201 - val_accuracy: 0.6941 - val_loss: 0.6210\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7010 - loss: 0.6166 - val_accuracy: 0.6941 - val_loss: 0.6201\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7031 - loss: 0.6144 - val_accuracy: 0.6941 - val_loss: 0.6195\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6975 - loss: 0.6172 - val_accuracy: 0.6941 - val_loss: 0.6189\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7042 - loss: 0.6121 - val_accuracy: 0.6941 - val_loss: 0.6183\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7406 - loss: 0.5872 - val_accuracy: 0.6941 - val_loss: 0.6178\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: 0.6052 - val_accuracy: 0.6941 - val_loss: 0.6174\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7266 - loss: 0.5948 - val_accuracy: 0.6941 - val_loss: 0.6172\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7121 - loss: 0.6044 - val_accuracy: 0.6941 - val_loss: 0.6170\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.6032 - val_accuracy: 0.6941 - val_loss: 0.6168\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7016 - loss: 0.6112 - val_accuracy: 0.6941 - val_loss: 0.6165\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.6047 - val_accuracy: 0.6941 - val_loss: 0.6163\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7062 - loss: 0.6072 - val_accuracy: 0.6941 - val_loss: 0.6162\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6992 - loss: 0.6123 - val_accuracy: 0.6941 - val_loss: 0.6161\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7087 - loss: 0.6049 - val_accuracy: 0.6941 - val_loss: 0.6160\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6932 - loss: 0.6167 - val_accuracy: 0.6941 - val_loss: 0.6159\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.5864 - val_accuracy: 0.6941 - val_loss: 0.6159\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6772 - loss: 0.6292 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6869 - loss: 0.6216 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6824 - loss: 0.6251 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7196 - loss: 0.5953 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7107 - loss: 0.6024 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7179 - loss: 0.5965 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7157 - loss: 0.5982 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7090 - loss: 0.6036 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6802 - loss: 0.6272 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 0.5986 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7192 - loss: 0.5949 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 0.6020 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6919 - loss: 0.6177 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Model GC-4.keras - Accuracy: 0.6933333333333334\n",
      "Model GC-4.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./german/german_onnx/GC-4.onnx\n",
      "Loading model GC-5.keras\n",
      "Training model GC-5.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 14:00:24.859838: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-11 14:00:24.859921: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-11 14:00:24.881069: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-11 14:00:24.881197: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6471 - loss: 0.6861 - val_accuracy: 0.6941 - val_loss: 0.6525\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7209 - loss: 0.6336 - val_accuracy: 0.6941 - val_loss: 0.6159\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6803 - loss: 0.6177 - val_accuracy: 0.6941 - val_loss: 0.6136\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7208 - loss: 0.5849 - val_accuracy: 0.6941 - val_loss: 0.6088\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6845 - loss: 0.6147 - val_accuracy: 0.6941 - val_loss: 0.6067\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.5748 - val_accuracy: 0.6941 - val_loss: 0.6017\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6946 - loss: 0.5962 - val_accuracy: 0.6941 - val_loss: 0.5961\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7272 - loss: 0.5593 - val_accuracy: 0.6941 - val_loss: 0.5881\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7113 - loss: 0.5666 - val_accuracy: 0.6941 - val_loss: 0.5793\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7042 - loss: 0.5614 - val_accuracy: 0.6941 - val_loss: 0.5704\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6856 - loss: 0.5673 - val_accuracy: 0.6941 - val_loss: 0.5616\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.5167 - val_accuracy: 0.6941 - val_loss: 0.5517\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7055 - loss: 0.5397 - val_accuracy: 0.6941 - val_loss: 0.5449\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.5006 - val_accuracy: 0.6941 - val_loss: 0.5435\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.5015 - val_accuracy: 0.6941 - val_loss: 0.5394\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.4864 - val_accuracy: 0.6941 - val_loss: 0.5389\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7163 - loss: 0.4945 - val_accuracy: 0.6941 - val_loss: 0.5390\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 0.4978 - val_accuracy: 0.6882 - val_loss: 0.5416\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7432 - loss: 0.4738 - val_accuracy: 0.6941 - val_loss: 0.5388\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.5071 - val_accuracy: 0.6765 - val_loss: 0.5477\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7453 - loss: 0.4875 - val_accuracy: 0.6824 - val_loss: 0.5477\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7562 - loss: 0.4506 - val_accuracy: 0.6294 - val_loss: 0.5469\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.4937 - val_accuracy: 0.6647 - val_loss: 0.5412\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7626 - loss: 0.4657 - val_accuracy: 0.6529 - val_loss: 0.5499\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7640 - loss: 0.4350 - val_accuracy: 0.6529 - val_loss: 0.5450\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7807 - loss: 0.4413 - val_accuracy: 0.6294 - val_loss: 0.5441\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7985 - loss: 0.4558 - val_accuracy: 0.6529 - val_loss: 0.5604\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7766 - loss: 0.4445 - val_accuracy: 0.6529 - val_loss: 0.5631\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7592 - loss: 0.4411 - val_accuracy: 0.6353 - val_loss: 0.5463\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.4128 - val_accuracy: 0.6471 - val_loss: 0.5434\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7943 - loss: 0.4203 - val_accuracy: 0.6294 - val_loss: 0.5417\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7787 - loss: 0.4474 - val_accuracy: 0.6412 - val_loss: 0.5505\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7952 - loss: 0.4330 - val_accuracy: 0.6529 - val_loss: 0.5647\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.4210 - val_accuracy: 0.6588 - val_loss: 0.5842\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.4208 - val_accuracy: 0.6471 - val_loss: 0.5755\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.3975 - val_accuracy: 0.6765 - val_loss: 0.6490\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7687 - loss: 0.4493 - val_accuracy: 0.6941 - val_loss: 0.6345\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7933 - loss: 0.4132 - val_accuracy: 0.6824 - val_loss: 0.6048\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7547 - loss: 0.4006 - val_accuracy: 0.6941 - val_loss: 0.5894\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.3707 - val_accuracy: 0.7000 - val_loss: 0.6183\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8174 - loss: 0.3482 - val_accuracy: 0.6765 - val_loss: 0.5978\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.3753 - val_accuracy: 0.6824 - val_loss: 0.6237\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8148 - loss: 0.3641 - val_accuracy: 0.6706 - val_loss: 0.6100\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8416 - loss: 0.3543 - val_accuracy: 0.6706 - val_loss: 0.5974\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.3539 - val_accuracy: 0.6706 - val_loss: 0.6246\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8212 - loss: 0.3724 - val_accuracy: 0.7000 - val_loss: 0.6263\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.3112 - val_accuracy: 0.6824 - val_loss: 0.6672\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3330 - val_accuracy: 0.6765 - val_loss: 0.6275\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.3196 - val_accuracy: 0.7000 - val_loss: 0.6630\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8243 - loss: 0.3416 - val_accuracy: 0.6882 - val_loss: 0.6714\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Model GC-5.keras - Accuracy: 0.78\n",
      "Model GC-5.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./german/german_onnx/GC-5.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 14:00:29.906391: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-11 14:00:29.906478: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-11 14:00:29.940395: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-11 14:00:29.940483: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the German dataset\n",
    "X_train, X_test, y_train, y_test = load_and_save_german_data()\n",
    "\n",
    "for model_file in os.listdir(save_dir):\n",
    "    if model_file.endswith('.keras'):\n",
    "        model_path = os.path.join(save_dir, model_file)\n",
    "        \n",
    "        try:\n",
    "            # Load the modified model\n",
    "            print(f\"Loading model {model_file}\")\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "                model = load_model(model_path)\n",
    "\n",
    "            # Reinitialize the optimizer\n",
    "            model.compile(\n",
    "                optimizer=Adam(),\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "            # Fit the model\n",
    "            print(f\"Training model {model_file}\")\n",
    "            history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "            # Evaluate the model\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "            accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred_classes)\n",
    "\n",
    "            print(f\"Model {model_file} - Accuracy: {accuracy}\")\n",
    "\n",
    "            # Save the retrained model\n",
    "            model.save(model_path)\n",
    "            print(f\"Model {model_file} retrained and saved successfully.\")\n",
    "\n",
    "            # Save the model as ONNX\n",
    "            onnx_save_path = os.path.join(onnx_save_dir, model_file.replace('.keras', '.onnx'))\n",
    "            save_model_onnx(model, (20,), onnx_save_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {model_file}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversairal Debiasing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_csv(filename, model_file, model_name, classification_accuracy, balanced_accuracy, disparate_impact, equal_opportunity_difference, average_odds_difference,precision,recall,f1):\n",
    "    # Check if the file exists to write the header only once\n",
    "    file_exists = os.path.isfile(filename)\n",
    "\n",
    "    with open(filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            # Write the header if the file does not exist\n",
    "            writer.writerow(['Model File', 'Model', 'Classification Accuracy', 'Balanced Accuracy', 'Disparate Impact', 'Equal Opportunity Difference', 'Average Odds Difference', 'Precision', 'Recall','F1'])\n",
    "        \n",
    "        # Write the metrics\n",
    "        writer.writerow([model_file, model_name, classification_accuracy, balanced_accuracy, disparate_impact, equal_opportunity_difference, average_odds_difference, precision, recall, f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various metrics for evaluation including accuracy and fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Metrics calculation functions\n",
    "def precision(y_true, y_pred, average='binary'):\n",
    "    return precision_score(y_true, y_pred, average=average)\n",
    "\n",
    "def recall(y_true, y_pred, average='binary'):\n",
    "    return recall_score(y_true, y_pred, average=average)\n",
    "\n",
    "def f1(y_true, y_pred, average='binary'):\n",
    "    return f1_score(y_true, y_pred, average=average)\n",
    "\n",
    "def classification_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    classes = np.unique(y_true)\n",
    "    recall_scores = []\n",
    "    for cls in classes:\n",
    "        true_positives = np.sum((y_true == cls) & (y_pred == cls))\n",
    "        possible_positives = np.sum(y_true == cls)\n",
    "        recall_scores.append(true_positives / possible_positives)\n",
    "    return np.mean(recall_scores)\n",
    "\n",
    "def disparate_impact(y_true, y_pred, protected_attribute):\n",
    "    privileged = protected_attribute == 1\n",
    "    unprivileged = protected_attribute == 0\n",
    "    if np.sum(privileged) == 0 or np.sum(unprivileged) == 0:\n",
    "        return np.nan\n",
    "    privileged_outcome = np.mean(y_pred[privileged]) if np.sum(privileged) > 0 else np.nan\n",
    "    unprivileged_outcome = np.mean(y_pred[unprivileged]) if np.sum(unprivileged) > 0 else np.nan\n",
    "    if privileged_outcome == 0:\n",
    "        return np.nan  \n",
    "    return unprivileged_outcome / privileged_outcome\n",
    "\n",
    "def equal_opportunity_difference(y_true, y_pred, protected_attribute):\n",
    "    privileged = protected_attribute == 1\n",
    "    unprivileged = protected_attribute == 0\n",
    "    true_positive_rate_privileged = np.sum((y_true[privileged] == 1) & (y_pred[privileged] == 1)) / np.sum(y_true[privileged] == 1)\n",
    "    true_positive_rate_unprivileged = np.sum((y_true[unprivileged] == 1) & (y_pred[unprivileged] == 1)) / np.sum(y_true[unprivileged] == 1)\n",
    "    return true_positive_rate_unprivileged - true_positive_rate_privileged\n",
    "\n",
    "def average_odds_difference(y_true, y_pred, protected_attribute):\n",
    "    privileged = protected_attribute == 1\n",
    "    unprivileged = protected_attribute == 0\n",
    "    tpr_privileged = np.sum((y_true[privileged] == 1) & (y_pred[privileged] == 1)) / np.sum(y_true[privileged] == 1)\n",
    "    tpr_unprivileged = np.sum((y_true[unprivileged] == 1) & (y_pred[unprivileged] == 1)) / np.sum(y_true[unprivileged] == 1)\n",
    "    fpr_privileged = np.sum((y_true[privileged] == 0) & (y_pred[privileged] == 1)) / np.sum(y_true[privileged] == 0)\n",
    "    fpr_unprivileged = np.sum((y_true[unprivileged] == 0) & (y_pred[unprivileged] == 1)) / np.sum(y_true[unprivileged] == 0)\n",
    "    average_odds_privileged = (tpr_privileged + fpr_privileged) / 2\n",
    "    average_odds_unprivileged = (tpr_unprivileged + fpr_unprivileged) / 2\n",
    "    return average_odds_unprivileged - average_odds_privileged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversary model definition\n",
    "def build_adversary_model(input_shape):\n",
    "    adversary_input = layers.Input(shape=input_shape)\n",
    "    x = layers.Dense(64, activation='relu')(adversary_input)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    adversary_output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    adversary_model = models.Model(inputs=adversary_input, outputs=adversary_output)\n",
    "    adversary_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return adversary_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "X_train, X_test, y_train, y_test, protected_train, protected_test = load_german()\n",
    "\n",
    "# Standardize the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Directory paths\n",
    "input_directory = './german/german_keras'\n",
    "output_directory = './german/german_debiased_onnx'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "metrics_filename = './model_metrics/german_model_metrics.csv'\n",
    "\n",
    "# Iterate over all .keras files in the input directory to convert to ONNX file\n",
    "for file in os.listdir(input_directory):\n",
    "    if file.endswith('.keras'):\n",
    "        # Full path to the current model file\n",
    "        input_path = os.path.join(input_directory, file)\n",
    "        output_path = os.path.join(output_directory, file.replace('.keras', '.onnx'))\n",
    "\n",
    "        try:\n",
    "            # Load the model\n",
    "            print(f\"Loading model from {input_path}\")\n",
    "            classifier_model = load_model(input_path)\n",
    "\n",
    "            # Ensure the model is compiled with the correct optimizer and metrics\n",
    "            classifier_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Print metrics for plain model\n",
    "            y_test_pred_plain = classifier_model.predict(X_test).argmax(axis=1)\n",
    "            y_test_true = y_test.argmax(axis=1)\n",
    "\n",
    "            plain_classification_accuracy = classification_accuracy(y_test_true, y_test_pred_plain)\n",
    "            plain_balanced_accuracy = balanced_accuracy(y_test_true, y_test_pred_plain)\n",
    "            plain_disparate_impact = disparate_impact(y_test_true, y_test_pred_plain, protected_test)\n",
    "            plain_equal_opportunity_difference = equal_opportunity_difference(y_test_true, y_test_pred_plain, protected_test)\n",
    "            plain_average_odds_difference = average_odds_difference(y_test_true, y_test_pred_plain, protected_test)\n",
    "            plain_precision = precision(y_test_true, y_test_pred_plain, average='macro')  # Use 'macro' for multi-class\n",
    "            plain_recall = recall(y_test_true, y_test_pred_plain, average='macro')        # Use 'macro' for multi-class\n",
    "            plain_f1 = f1(y_test_true, y_test_pred_plain, average='macro')                # Use 'macro' for multi-class\n",
    "\n",
    "            save_metrics_to_csv(metrics_filename, file, 'Plain Model', plain_classification_accuracy, plain_balanced_accuracy, plain_disparate_impact, plain_equal_opportunity_difference, plain_average_odds_difference, plain_precision, plain_recall, plain_f1)\n",
    "            \n",
    "            # Build and compile the adversary model\n",
    "            adversary_model = build_adversary_model(classifier_model.output_shape[1:])\n",
    "\n",
    "            # Training parameters\n",
    "            num_epochs = 50\n",
    "            batch_size = 128\n",
    "            learning_rate = 0.001\n",
    "            adversary_loss_weight = 0.7\n",
    "\n",
    "            # Optimizers\n",
    "            classifier_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "            adversary_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "            # Loss functions\n",
    "            classification_loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "            adversary_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "           # Training loop\n",
    "            for epoch in range(num_epochs):\n",
    "                # Shuffle the training data\n",
    "                indices = np.arange(X_train.shape[0])\n",
    "                np.random.shuffle(indices)\n",
    "                \n",
    "                # Mini-batch training\n",
    "                for start in range(0, X_train.shape[0], batch_size):\n",
    "                    end = min(start + batch_size, X_train.shape[0])\n",
    "                    batch_indices = indices[start:end]\n",
    "                    \n",
    "                    X_batch = X_train[batch_indices]\n",
    "                    y_batch = y_train[batch_indices]\n",
    "                    protected_batch = protected_train[batch_indices].reshape(-1, 1)\n",
    "                    \n",
    "                    with tf.GradientTape() as classifier_tape:\n",
    "                        # Forward pass through the classifier\n",
    "                        classifier_predictions = classifier_model(X_batch, training=True)\n",
    "                        \n",
    "                        # Forward pass through the adversary with no gradient accumulation\n",
    "                        adversary_predictions = adversary_model(classifier_predictions, training=False)\n",
    "                        \n",
    "                        # Compute losses\n",
    "                        classification_loss = classification_loss_fn(y_batch, classifier_predictions)\n",
    "                        adversary_loss = adversary_loss_fn(protected_batch, adversary_predictions)\n",
    "                        total_loss = classification_loss - adversary_loss_weight * adversary_loss\n",
    "                    \n",
    "                    # Compute gradients and update classifier weights\n",
    "                    classifier_gradients = classifier_tape.gradient(total_loss, classifier_model.trainable_variables)\n",
    "                    classifier_optimizer.apply_gradients(zip(classifier_gradients, classifier_model.trainable_variables))\n",
    "                    \n",
    "                    with tf.GradientTape() as adversary_tape:\n",
    "                        # Forward pass through the classifier\n",
    "                        classifier_predictions = classifier_model(X_batch, training=True)\n",
    "                        \n",
    "                        # Forward pass through the adversary\n",
    "                        adversary_predictions = adversary_model(classifier_predictions, training=True)\n",
    "                        \n",
    "                        # Compute adversary loss\n",
    "                        adversary_loss = adversary_loss_fn(protected_batch, adversary_predictions)\n",
    "                    \n",
    "                    # Compute gradients and update adversary weights\n",
    "                    adversary_gradients = adversary_tape.gradient(adversary_loss, adversary_model.trainable_variables)\n",
    "                    adversary_optimizer.apply_gradients(zip(adversary_gradients, adversary_model.trainable_variables))\n",
    "    \n",
    "                print(f\"Epoch {epoch + 1}/{num_epochs}, Classification Loss: {classification_loss.numpy()}, Adversary Loss: {adversary_loss.numpy()}\")\n",
    "\n",
    "            \n",
    "            # Predictions for debiased model\n",
    "            y_test_pred_debiased = classifier_model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "            debiased_classification_accuracy = classification_accuracy(y_test_true, y_test_pred_debiased)\n",
    "            debiased_balanced_accuracy = balanced_accuracy(y_test_true, y_test_pred_debiased)\n",
    "            debiased_disparate_impact = disparate_impact(y_test_true, y_test_pred_debiased, protected_test)\n",
    "            debiased_equal_opportunity_difference = equal_opportunity_difference(y_test_true, y_test_pred_debiased, protected_test)\n",
    "            debiased_average_odds_difference = average_odds_difference(y_test_true, y_test_pred_debiased, protected_test)\n",
    "            debiased_precision = precision(y_test_true, y_test_pred_plain, average='macro')  # Use 'macro' for multi-class\n",
    "            debiased_recall = recall(y_test_true, y_test_pred_plain, average='macro')        # Use 'macro' for multi-class\n",
    "            debiased_f1 = f1(y_test_true, y_test_pred_plain, average='macro')                # Use 'macro' for multi-class\n",
    "\n",
    "            save_metrics_to_csv(metrics_filename, file, 'Debiased Model', debiased_classification_accuracy, debiased_balanced_accuracy, debiased_disparate_impact, debiased_equal_opportunity_difference, debiased_average_odds_difference, debiased_precision, debiased_recall, debiased_f1)\n",
    "            \n",
    "            # Save the debiased model as ONNX\n",
    "            input_shape = (20,)  # Adjust the input shape based on your model's expected input\n",
    "            save_model_onnx(classifier_model, input_shape, output_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert {file}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Debiasing Process For Multiple Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_metrics_to_csv(filename, model_name, model_type, means, stds):\n",
    "    headers = [\n",
    "        'model_name', 'model_type', 'metric', 'mean', 'std_dev'\n",
    "    ]\n",
    "    with open(filename, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if os.path.getsize(filename) == 0:\n",
    "            writer.writerow(headers)\n",
    "        for metric, mean_value in means.items():\n",
    "            writer.writerow([model_name, model_type, metric, mean_value, stds[metric]])\n",
    "\n",
    "# Load and preprocess the data\n",
    "X_train, X_test, y_train, y_test, protected_train, protected_test = load_german()\n",
    "\n",
    "# Standardize the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Directory paths\n",
    "input_directory = './german/german_keras'\n",
    "output_directory = './german/german_debiased_onnx'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "metrics_filename = './model_metrics/german_model_metrics.csv'\n",
    "\n",
    "# Number of runs\n",
    "num_runs = 5\n",
    "\n",
    "# Iterate over all .keras files in the input directory to convert to ONNX file\n",
    "for file in os.listdir(input_directory):\n",
    "    if file.endswith('.keras'):\n",
    "        # Full path to the current model file\n",
    "        input_path = os.path.join(input_directory, file)\n",
    "        output_path = os.path.join(output_directory, file.replace('.keras', '.onnx'))\n",
    "\n",
    "        try:\n",
    "            plain_metrics = {\n",
    "                'classification_accuracy': [],\n",
    "                'balanced_accuracy': [],\n",
    "                'disparate_impact': [],\n",
    "                'equal_opportunity_difference': [],\n",
    "                'average_odds_difference': [],\n",
    "                'precision': [],\n",
    "                'recall': [],\n",
    "                'f1': []\n",
    "            }\n",
    "\n",
    "            debiased_metrics = {\n",
    "                'classification_accuracy': [],\n",
    "                'balanced_accuracy': [],\n",
    "                'disparate_impact': [],\n",
    "                'equal_opportunity_difference': [],\n",
    "                'average_odds_difference': [],\n",
    "                'precision': [],\n",
    "                'recall': [],\n",
    "                'f1': []\n",
    "            }\n",
    "           \n",
    "            # Inside the loop for each .keras file\n",
    "            for run in range(num_runs):\n",
    "                print(f\"Run {run + 1}/{num_runs}\")\n",
    "\n",
    "                # Random seed for variability\n",
    "                np.random.seed(run)\n",
    "                tf.random.set_seed(run)\n",
    "\n",
    "                # Shuffle the training data\n",
    "                indices = np.arange(X_train.shape[0])\n",
    "                np.random.shuffle(indices)\n",
    "                X_train_shuffled = X_train[indices]\n",
    "                y_train_shuffled = y_train[indices]\n",
    "                protected_train_shuffled = protected_train[indices]\n",
    "\n",
    "                # Load the model\n",
    "                classifier_model = load_model(input_path)\n",
    "\n",
    "                # Compile the model\n",
    "                classifier_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "                # Train the model with shuffled data\n",
    "                classifier_model.fit(X_train_shuffled, y_train_shuffled, epochs=10, batch_size=128, verbose=0)\n",
    "\n",
    "                # Train and evaluate the plain model\n",
    "                y_test_pred_plain = classifier_model.predict(X_test).argmax(axis=1)\n",
    "                y_test_true = y_test.argmax(axis=1)\n",
    "\n",
    "                plain_metrics['classification_accuracy'].append(classification_accuracy(y_test_true, y_test_pred_plain))\n",
    "                plain_metrics['balanced_accuracy'].append(balanced_accuracy(y_test_true, y_test_pred_plain))\n",
    "                plain_metrics['disparate_impact'].append(disparate_impact(y_test_true, y_test_pred_plain, protected_test))\n",
    "                plain_metrics['equal_opportunity_difference'].append(equal_opportunity_difference(y_test_true, y_test_pred_plain, protected_test))\n",
    "                plain_metrics['average_odds_difference'].append(average_odds_difference(y_test_true, y_test_pred_plain, protected_test))\n",
    "                plain_metrics['precision'].append(precision_score(y_test_true, y_test_pred_plain, average='macro', zero_division=1))\n",
    "                plain_metrics['recall'].append(recall_score(y_test_true, y_test_pred_plain, average='macro'))\n",
    "                plain_metrics['f1'].append(f1_score(y_test_true, y_test_pred_plain, average='macro'))\n",
    "\n",
    "                # Build and compile the adversary model\n",
    "                adversary_model = build_adversary_model(classifier_model.output_shape[1:])\n",
    "\n",
    "                # Training parameters\n",
    "                num_epochs = 50\n",
    "                batch_size = 128\n",
    "                learning_rate = 0.001\n",
    "                adversary_loss_weight = 0.7\n",
    "\n",
    "                # Optimizers\n",
    "                classifier_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "                adversary_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "                # Loss functions\n",
    "                classification_loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "                adversary_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "                # Training loop\n",
    "                for epoch in range(num_epochs):\n",
    "                    # Shuffle the training data\n",
    "                    indices = np.arange(X_train_shuffled.shape[0])\n",
    "                    np.random.shuffle(indices)\n",
    "                    \n",
    "                    # Mini-batch training\n",
    "                    for start in range(0, X_train_shuffled.shape[0], batch_size):\n",
    "                        end = min(start + batch_size, X_train_shuffled.shape[0])\n",
    "                        batch_indices = indices[start:end]\n",
    "                        \n",
    "                        X_batch = X_train_shuffled[batch_indices]\n",
    "                        y_batch = y_train_shuffled[batch_indices]\n",
    "                        protected_batch = protected_train_shuffled[batch_indices].reshape(-1, 1)\n",
    "                        \n",
    "                        with tf.GradientTape() as classifier_tape:\n",
    "                            # Forward pass through the classifier\n",
    "                            classifier_predictions = classifier_model(X_batch, training=True)\n",
    "                            \n",
    "                            # Forward pass through the adversary with no gradient accumulation\n",
    "                            adversary_predictions = adversary_model(classifier_predictions, training=False)\n",
    "                            \n",
    "                            # Compute losses\n",
    "                            classification_loss = classification_loss_fn(y_batch, classifier_predictions)\n",
    "                            adversary_loss = adversary_loss_fn(protected_batch, adversary_predictions)\n",
    "                            total_loss = classification_loss - adversary_loss_weight * adversary_loss\n",
    "                        \n",
    "                        # Compute gradients and update classifier weights\n",
    "                        classifier_gradients = classifier_tape.gradient(total_loss, classifier_model.trainable_variables)\n",
    "                        classifier_optimizer.apply_gradients(zip(classifier_gradients, classifier_model.trainable_variables))\n",
    "                        \n",
    "                        with tf.GradientTape() as adversary_tape:\n",
    "                            # Forward pass through the classifier\n",
    "                            classifier_predictions = classifier_model(X_batch, training=True)\n",
    "                            \n",
    "                            # Forward pass through the adversary\n",
    "                            adversary_predictions = adversary_model(classifier_predictions, training=True)\n",
    "                            \n",
    "                            # Compute adversary loss\n",
    "                            adversary_loss = adversary_loss_fn(protected_batch, adversary_predictions)\n",
    "                        \n",
    "                        # Compute gradients and update adversary weights\n",
    "                        adversary_gradients = adversary_tape.gradient(adversary_loss, adversary_model.trainable_variables)\n",
    "                        adversary_optimizer.apply_gradients(zip(adversary_gradients, adversary_model.trainable_variables))\n",
    "\n",
    "                    print(f\"Epoch {epoch + 1}/{num_epochs}, Classification Loss: {classification_loss.numpy()}, Adversary Loss: {adversary_loss.numpy()}\")\n",
    "\n",
    "                y_test_pred_debiased = classifier_model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "                debiased_metrics['classification_accuracy'].append(classification_accuracy(y_test_true, y_test_pred_debiased))\n",
    "                debiased_metrics['balanced_accuracy'].append(balanced_accuracy(y_test_true, y_test_pred_debiased))\n",
    "                debiased_metrics['disparate_impact'].append(disparate_impact(y_test_true, y_test_pred_debiased, protected_test))\n",
    "                debiased_metrics['equal_opportunity_difference'].append(equal_opportunity_difference(y_test_true, y_test_pred_debiased, protected_test))\n",
    "                debiased_metrics['average_odds_difference'].append(average_odds_difference(y_test_true, y_test_pred_debiased, protected_test))\n",
    "                debiased_metrics['precision'].append(precision_score(y_test_true, y_test_pred_debiased, average='macro', zero_division=1))\n",
    "                debiased_metrics['recall'].append(recall_score(y_test_true, y_test_pred_debiased, average='macro'))\n",
    "                debiased_metrics['f1'].append(f1_score(y_test_true, y_test_pred_debiased, average='macro'))\n",
    "\n",
    "            # Calculate mean and std for plain metrics\n",
    "            plain_means = {key: np.mean(values) for key, values in plain_metrics.items()}\n",
    "            plain_stds = {key: np.std(values) for key, values in plain_metrics.items()}\n",
    "\n",
    "            # Calculate mean and std for debiased metrics\n",
    "            debiased_means = {key: np.mean(values) for key, values in debiased_metrics.items()}\n",
    "            debiased_stds = {key: np.std(values) for key, values in debiased_metrics.items()}\n",
    "\n",
    "            # Save metrics to CSV\n",
    "            save_metrics_to_csv(metrics_filename, file, 'Plain Model', plain_means, plain_stds)\n",
    "            save_metrics_to_csv(metrics_filename, file, 'Debiased Model', debiased_means, debiased_stds)\n",
    "\n",
    "            # Save the debiased model as ONNX\n",
    "            input_shape = (20,)  # Adjust the input shape based on your model's expected input\n",
    "            save_model_onnx(classifier_model, input_shape, output_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert {file}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workshopping Adversarial Debiasing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adversary model definition\n",
    "# def build_adversary_model(input_shape):\n",
    "#     adversary_input = layers.Input(shape=input_shape)\n",
    "#     x = layers.Dense(64, activation='relu')(adversary_input)\n",
    "#     x = layers.Dense(32, activation='relu')(x)\n",
    "#     adversary_output = layers.Dense(1, activation='sigmoid')(x)\n",
    "#     adversary_model = models.Model(inputs=adversary_input, outputs=adversary_output)\n",
    "#     adversary_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "#     return adversary_model\n",
    "from tensorflow.keras.models import load_model, Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "# Function to build the adversary model\n",
    "def build_adversary_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)  # No activation here, we will use `from_logits=True` in the loss function\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Load and preprocess the data\n",
    "X_train, X_test, y_train, y_test, protected_train, protected_test = load_german()\n",
    "\n",
    "# Standardize the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Directory paths\n",
    "input_directory = './german/german_keras'\n",
    "output_directory = './german/german_debiased_onnx'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "metrics_filename = './model_metrics/german_model_metrics.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_24\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_24\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ new_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m1,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ new_output (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m102\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,458</span> (13.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,458\u001b[0m (13.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> (4.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,152\u001b[0m (4.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,306</span> (9.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,306\u001b[0m (9.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_149\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_149\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ new_output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m1,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ new_output_layer (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m102\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> (4.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,152\u001b[0m (4.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> (4.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,152\u001b[0m (4.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_151\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_151\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_146 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_147 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_61 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_146 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m150\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_147 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> (804.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m201\u001b[0m (804.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> (804.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m201\u001b[0m (804.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert GC-1.keras. Error: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [20,50] vs. [2,50] [Op:Mul] name: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 16:03:52.135386: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [20,50] vs. [2,50]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import numpy as np\n",
    "\n",
    "def build_adversary_model_from_classifier(classifier_model):\n",
    "    input_shape = classifier_model.output_shape[1:]  # Get the shape of the classifier's output\n",
    "    adversary_input = Input(shape=input_shape)\n",
    "    \n",
    "    x = adversary_input\n",
    "    for layer in classifier_model.layers[1:-1]:  # Skip the first and last layers\n",
    "        if isinstance(layer, Dense):\n",
    "            x = Dense(layer.units, activation='relu')(x)  # Use relu for hidden layers\n",
    "    \n",
    "    adversary_output = Dense(1)(x)  # Final adversary output layer without activation\n",
    "    adversary_model = Model(inputs=adversary_input, outputs=adversary_output)\n",
    "    \n",
    "    return adversary_model\n",
    "\n",
    "\n",
    "for file in os.listdir(input_directory):\n",
    "    if file.endswith('.keras'):\n",
    "        input_path = os.path.join(input_directory, file)\n",
    "        output_path = os.path.join(output_directory, file.replace('.keras', '.onnx'))\n",
    "\n",
    "        try:\n",
    "            # Load the classifier model\n",
    "            classifier_model = load_model(input_path)\n",
    "            # classifier_model.summary()\n",
    "\n",
    "            # Modify the classifier model\n",
    "            input_layer = classifier_model.input\n",
    "            hidden_layers = classifier_model.layers[:-1]\n",
    "            new_output_layer = Dense(units=2, name=\"new_output_layer\")(hidden_layers[-1].output)\n",
    "            modified_classifier_model = Model(inputs=input_layer, outputs=new_output_layer)\n",
    "            # modified_classifier_model.summary()\n",
    "\n",
    "            # Print metrics for plain model\n",
    "            y_test_pred_plain = classifier_model.predict(X_test).argmax(axis=1)\n",
    "            y_test_true = y_test.argmax(axis=1)\n",
    "            plain_classification_accuracy = classification_accuracy(y_test_true, y_test_pred_plain)\n",
    "            plain_balanced_accuracy = balanced_accuracy(y_test_true, y_test_pred_plain)\n",
    "            plain_disparate_impact = disparate_impact(y_test_true, y_test_pred_plain, protected_test)\n",
    "            plain_equal_opportunity_difference = equal_opportunity_difference(y_test_true, y_test_pred_plain, protected_test)\n",
    "            plain_average_odds_difference = average_odds_difference(y_test_true, y_test_pred_plain, protected_test)\n",
    "            save_metrics_to_csv(metrics_filename, file, 'Plain Model', plain_classification_accuracy, plain_balanced_accuracy, plain_disparate_impact, plain_equal_opportunity_difference, plain_average_odds_difference)\n",
    "\n",
    "            # Build the adversary model\n",
    "            adversary_model = build_adversary_model_from_classifier(modified_classifier_model)\n",
    "            # adversary_model.summary()\n",
    "\n",
    "            # Training parameters\n",
    "            num_epochs = 50\n",
    "            batch_size = 128\n",
    "\n",
    "            # Loss functions\n",
    "            classification_loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "            adversary_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "            # Parameters\n",
    "            adversary_loss_weight = 0.9\n",
    "            classifier_learning_rate = 0.0005\n",
    "            adversary_learning_rate = 0.001\n",
    "\n",
    "            # Optimizers\n",
    "            classifier_optimizer = tf.keras.optimizers.Adam(classifier_learning_rate)\n",
    "            adversary_optimizer = tf.keras.optimizers.Adam(adversary_learning_rate)\n",
    "\n",
    "            # Training loop\n",
    "            for epoch in range(num_epochs):\n",
    "                indices = np.arange(X_train.shape[0])\n",
    "                np.random.shuffle(indices)\n",
    "                \n",
    "                for start in range(0, X_train.shape[0], batch_size):\n",
    "                    end = min(start + batch_size, X_train.shape[0])\n",
    "                    batch_indices = indices[start:end]\n",
    "                    \n",
    "                    X_batch = X_train[batch_indices]\n",
    "                    y_batch = y_train[batch_indices]\n",
    "                    protected_batch = protected_train[batch_indices].reshape(-1, 1)\n",
    "                    \n",
    "                    with tf.GradientTape() as classifier_tape, tf.GradientTape() as adversary_tape:\n",
    "                        logits = modified_classifier_model(X_batch, training=True)\n",
    "                        adversary_predictions = adversary_model(logits, training=True)\n",
    "                        \n",
    "                        classification_loss = classification_loss_fn(y_batch, logits)\n",
    "                        adversary_loss = adversary_loss_fn(protected_batch, adversary_predictions)\n",
    "                        total_loss = classification_loss - adversary_loss_weight * adversary_loss\n",
    "                    \n",
    "                    classifier_gradients = classifier_tape.gradient(total_loss, modified_classifier_model.trainable_variables)\n",
    "                    adversary_gradients = adversary_tape.gradient(adversary_loss, adversary_model.trainable_variables)\n",
    "                    \n",
    "                    combined_gradients = []\n",
    "                    for c_grad, a_grad in zip(classifier_gradients, adversary_gradients):\n",
    "                        if c_grad is not None and a_grad is not None:\n",
    "                            proj = tf.reduce_sum(c_grad * a_grad) / (tf.reduce_sum(a_grad * a_grad) + 1e-8)\n",
    "                            combined_grad = c_grad - proj * a_grad - adversary_loss_weight * a_grad\n",
    "                            combined_gradients.append(combined_grad)\n",
    "                        else:\n",
    "                            combined_gradients.append(c_grad)\n",
    "\n",
    "                    classifier_optimizer.apply_gradients(zip(combined_gradients, modified_classifier_model.trainable_variables))\n",
    "                    adversary_optimizer.apply_gradients(zip(adversary_gradients, adversary_model.trainable_variables))\n",
    "                \n",
    "                print(f\"Epoch {epoch + 1}/{num_epochs}, Classification Loss: {classification_loss.numpy()}, Adversary Loss: {adversary_loss.numpy()}\")\n",
    "\n",
    "                classifier_predictions_test = modified_classifier_model.predict(X_test)\n",
    "                adversary_predictions_test = adversary_model.predict(classifier_predictions_test).round()\n",
    "                adversary_accuracy = np.mean(adversary_predictions_test == protected_test.reshape(-1, 1))\n",
    "                print(f\"Adversary accuracy on test set: {adversary_accuracy}\")\n",
    "\n",
    "                y_test_pred_debiased = modified_classifier_model.predict(X_test).argmax(axis=1)\n",
    "                debiased_classification_accuracy = classification_accuracy(y_test_true, y_test_pred_debiased)\n",
    "                debiased_balanced_accuracy = balanced_accuracy(y_test_true, y_test_pred_debiased)\n",
    "                debiased_disparate_impact = disparate_impact(y_test_true, y_test_pred_debiased, protected_test)\n",
    "                debiased_equal_opportunity_difference = equal_opportunity_difference(y_test_true, y_test_pred_debiased, protected_test)\n",
    "                debiased_average_odds_difference = average_odds_difference(y_test_true, y_test_pred_debiased, protected_test)\n",
    "                save_metrics_to_csv(metrics_filename, file, 'Debiased Model', debiased_classification_accuracy, debiased_balanced_accuracy, debiased_disparate_impact, debiased_equal_opportunity_difference, debiased_average_odds_difference)\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert {file}. Error: {e}\")\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
