{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to process German Credit data, edit/train models, and perform adversarial debiasing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary libraries for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 21:41:03.989184: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-10 21:41:17.502355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from scipy.io import savemat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom preprocessing function for the German dataset\n",
    "def german_custom_preprocessing(df):\n",
    "    def group_credit_hist(x):\n",
    "        if x in ['A30', 'A31', 'A32']:\n",
    "            return 'None/Paid'\n",
    "        elif x == 'A33':\n",
    "            return 'Delay'\n",
    "        elif x == 'A34':\n",
    "            return 'Other'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    def group_employ(x):\n",
    "        if x == 'A71':\n",
    "            return 'Unemployed'\n",
    "        elif x in ['A72', 'A73']:\n",
    "            return '1-4 years'\n",
    "        elif x in ['A74', 'A75']:\n",
    "            return '4+ years'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    def group_savings(x):\n",
    "        if x in ['A61', 'A62']:\n",
    "            return '<500'\n",
    "        elif x in ['A63', 'A64']:\n",
    "            return '500+'\n",
    "        elif x == 'A65':\n",
    "            return 'Unknown/None'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    def group_status(x):\n",
    "        if x in ['A11', 'A12']:\n",
    "            return '<200'\n",
    "        elif x in ['A13']:\n",
    "            return '200+'\n",
    "        elif x == 'A14':\n",
    "            return 'None'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    status_map = {'A91': 1, 'A93': 1, 'A94': 1, 'A92': 0, 'A95': 0}  # 1: 'male'\n",
    "    df['sex'] = df['personal_status'].replace(status_map)\n",
    "\n",
    "    df['credit_history'] = df['credit_history'].apply(lambda x: group_credit_hist(x))\n",
    "    df['savings'] = df['savings'].apply(lambda x: group_savings(x))\n",
    "    df['employment'] = df['employment'].apply(lambda x: group_employ(x))\n",
    "    df['status'] = df['status'].apply(lambda x: group_status(x))\n",
    "\n",
    "    df.credit.replace([1, 2], [1, 0], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_german():\n",
    "    filepath = '../data/german/german.data'\n",
    "    column_names = ['status', 'month', 'credit_history', 'purpose', 'credit_amount', 'savings', 'employment',\n",
    "                    'investment_as_income_percentage', 'personal_status', 'other_debtors', 'residence_since', \n",
    "                    'property', 'age', 'installment_plans', 'housing', 'number_of_credits', 'skill_level', \n",
    "                    'people_liable_for', 'telephone', 'foreign_worker', 'credit']\n",
    "    na_values = []\n",
    "    df = pd.read_csv(filepath, sep=' ', header=None, names=column_names, na_values=na_values)\n",
    "    \n",
    "    df = german_custom_preprocessing(df)\n",
    "    feat_to_drop = ['personal_status']\n",
    "    df = df.drop(feat_to_drop, axis=1)\n",
    "    \n",
    "    # Encode categorical features\n",
    "    cat_feat = ['status', 'credit_history', 'purpose', 'savings', 'employment', 'other_debtors', 'property', \n",
    "                'installment_plans', 'housing', 'skill_level', 'telephone', 'foreign_worker']\n",
    "    for col in cat_feat:\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "    \n",
    "    # Encode the target variable\n",
    "    label_name = 'credit'\n",
    "    \n",
    "    X = df.drop(labels=[label_name], axis=1, inplace=False)\n",
    "    y = df[label_name]\n",
    "    \n",
    "    # Extract the protected attribute ('sex')\n",
    "    protected_attribute = X['sex'].values\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    seed = 42\n",
    "    X_train, X_test, y_train, y_test, protected_train, protected_test = train_test_split(\n",
    "        X, y, protected_attribute, test_size=0.15, random_state=seed\n",
    "    )\n",
    "    \n",
    "    # One-hot encode the labels\n",
    "    y_train = to_categorical(y_train, num_classes=2)\n",
    "    y_test = to_categorical(y_test, num_classes=2)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, protected_train, protected_test\n",
    "\n",
    "# Saves data for use in verification\n",
    "def load_and_save_german_data():\n",
    "    X_train, X_test, y_train, y_test, _, _ = load_german()\n",
    "    \n",
    "    # Scaling numerical features with MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Prepare data dictionary to save as .mat file\n",
    "    data_dict = {\n",
    "        'X': X_test, \n",
    "        'y': y_test   \n",
    "    }\n",
    "    \n",
    "    # Save to .mat file for use in MATLAB\n",
    "    savemat(\"./processed_data/german_data.mat\", data_dict)\n",
    "    print(\"Data saved to german_data.mat\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Editing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to save the models as onnx files for verification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model as ONNX format\n",
    "def save_model_onnx(model, input_shape, onnx_file_path):\n",
    "    # Create a dummy input tensor with the correct input shape (batch_size, input_shape)\n",
    "    dummy_input = tf.random.normal([1] + list(input_shape))\n",
    "\n",
    "    # Convert the model to ONNX\n",
    "    model_proto, external_tensor_storage = tf2onnx.convert.from_keras(model, \n",
    "                                                                      input_signature=(tf.TensorSpec(shape=[None] + list(input_shape), dtype=tf.float32),),\n",
    "                                                                      opset=13)\n",
    "    \n",
    "    # Save the ONNX model to the specified path\n",
    "    with open(onnx_file_path, \"wb\") as f:\n",
    "        f.write(model_proto.SerializeToString())\n",
    "    \n",
    "    print(f\"Model has been saved in ONNX format at {onnx_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the models so they are able to be used in FairNNV. FairNNV cannot handle sigmoid so shift to softmax and adjust final layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Function to modify a model for multiclass classification\n",
    "def modify_model_for_multiclass(model_path, num_classes):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "        model = load_model(model_path)\n",
    "\n",
    "    # Create a new input layer with the correct shape\n",
    "    new_input = tf.keras.layers.Input(shape=(20,))\n",
    "    x = new_input\n",
    "\n",
    "    # Transfer the layers except the last one\n",
    "    for layer in model.layers[:-1]:\n",
    "        x = layer(x)\n",
    "\n",
    "    # Create a new output layer\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='softmax', name='new_output')(x)\n",
    "    \n",
    "    # Create a new model\n",
    "    new_model = tf.keras.models.Model(inputs=new_input, outputs=output)\n",
    "    \n",
    "    return new_model\n",
    "\n",
    "# Ensure the save directories exist\n",
    "model_dir = './german/german_h5'\n",
    "save_dir = './german/german_keras'\n",
    "onnx_save_dir = './german/german_onnx'\n",
    "num_classes = 2\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "if not os.path.exists(onnx_save_dir):\n",
    "    os.makedirs(onnx_save_dir)\n",
    "\n",
    "# Modify each model in the directory to remove sigmoid\n",
    "for model_file in os.listdir(model_dir):\n",
    "    if model_file.endswith('.h5'):\n",
    "        model_path = os.path.join(model_dir, model_file)\n",
    "        new_model = modify_model_for_multiclass(model_path, num_classes)\n",
    "        \n",
    "        # Update the model's loss function\n",
    "        new_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Save the modified model\n",
    "        save_path = os.path.join(save_dir, model_file.replace('.h5', '.keras'))\n",
    "        new_model.save(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-train models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to german_data.mat\n",
      "Loading model GC-1.keras\n",
      "Training model GC-1.keras\n",
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5173 - loss: 0.7113 - val_accuracy: 0.6941 - val_loss: 0.6186\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7063 - loss: 0.5806 - val_accuracy: 0.6882 - val_loss: 0.6028\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6971 - loss: 0.5836 - val_accuracy: 0.7000 - val_loss: 0.5954\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7073 - loss: 0.5725 - val_accuracy: 0.7000 - val_loss: 0.5888\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.5461 - val_accuracy: 0.6941 - val_loss: 0.5824\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6982 - loss: 0.5655 - val_accuracy: 0.6882 - val_loss: 0.5766\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7022 - loss: 0.5629 - val_accuracy: 0.6882 - val_loss: 0.5746\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.5437 - val_accuracy: 0.6882 - val_loss: 0.5695\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7305 - loss: 0.5231 - val_accuracy: 0.6941 - val_loss: 0.5668\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7509 - loss: 0.5114 - val_accuracy: 0.6882 - val_loss: 0.5654\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7372 - loss: 0.5244 - val_accuracy: 0.6941 - val_loss: 0.5628\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7247 - loss: 0.5148 - val_accuracy: 0.6941 - val_loss: 0.5620\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.5159 - val_accuracy: 0.6824 - val_loss: 0.5606\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7532 - loss: 0.4937 - val_accuracy: 0.6706 - val_loss: 0.5591\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7517 - loss: 0.5107 - val_accuracy: 0.6706 - val_loss: 0.5579\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7483 - loss: 0.5057 - val_accuracy: 0.6824 - val_loss: 0.5582\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7617 - loss: 0.4981 - val_accuracy: 0.6765 - val_loss: 0.5572\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7522 - loss: 0.5048 - val_accuracy: 0.7000 - val_loss: 0.5566\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7631 - loss: 0.4970 - val_accuracy: 0.6941 - val_loss: 0.5562\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7413 - loss: 0.5016 - val_accuracy: 0.7059 - val_loss: 0.5564\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7558 - loss: 0.5018 - val_accuracy: 0.6882 - val_loss: 0.5578\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7551 - loss: 0.5108 - val_accuracy: 0.6941 - val_loss: 0.5567\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7429 - loss: 0.4904 - val_accuracy: 0.7059 - val_loss: 0.5563\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7766 - loss: 0.4692 - val_accuracy: 0.6765 - val_loss: 0.5575\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7576 - loss: 0.4892 - val_accuracy: 0.7059 - val_loss: 0.5562\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7681 - loss: 0.4747 - val_accuracy: 0.6941 - val_loss: 0.5573\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7418 - loss: 0.4993 - val_accuracy: 0.7118 - val_loss: 0.5571\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7497 - loss: 0.4886 - val_accuracy: 0.6941 - val_loss: 0.5574\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7718 - loss: 0.4637 - val_accuracy: 0.7059 - val_loss: 0.5580\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7605 - loss: 0.4700 - val_accuracy: 0.6824 - val_loss: 0.5580\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.5045 - val_accuracy: 0.7000 - val_loss: 0.5572\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7688 - loss: 0.4945 - val_accuracy: 0.6882 - val_loss: 0.5575\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7590 - loss: 0.4777 - val_accuracy: 0.6706 - val_loss: 0.5612\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7232 - loss: 0.4996 - val_accuracy: 0.6882 - val_loss: 0.5587\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7638 - loss: 0.4834 - val_accuracy: 0.6941 - val_loss: 0.5584\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7811 - loss: 0.4696 - val_accuracy: 0.6941 - val_loss: 0.5639\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7587 - loss: 0.4934 - val_accuracy: 0.6941 - val_loss: 0.5631\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7752 - loss: 0.4691 - val_accuracy: 0.6824 - val_loss: 0.5601\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7636 - loss: 0.4674 - val_accuracy: 0.6824 - val_loss: 0.5609\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7852 - loss: 0.4630 - val_accuracy: 0.6824 - val_loss: 0.5616\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7602 - loss: 0.4838 - val_accuracy: 0.6765 - val_loss: 0.5627\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7746 - loss: 0.4696 - val_accuracy: 0.6765 - val_loss: 0.5613\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7765 - loss: 0.4682 - val_accuracy: 0.6824 - val_loss: 0.5626\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7592 - loss: 0.4843 - val_accuracy: 0.6824 - val_loss: 0.5603\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7512 - loss: 0.4842 - val_accuracy: 0.6824 - val_loss: 0.5609\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7812 - loss: 0.4506 - val_accuracy: 0.6647 - val_loss: 0.5618\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7644 - loss: 0.4676 - val_accuracy: 0.6824 - val_loss: 0.5606\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7876 - loss: 0.4472 - val_accuracy: 0.6765 - val_loss: 0.5650\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7961 - loss: 0.4481 - val_accuracy: 0.6765 - val_loss: 0.5635\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7786 - loss: 0.4590 - val_accuracy: 0.6647 - val_loss: 0.5630\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Model GC-1.keras - Accuracy: 0.7733333333333333\n",
      "Model GC-1.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./german/german_onnx/GC-1.onnx\n",
      "Loading model GC-2.keras\n",
      "Training model GC-2.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 21:41:48.073678: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:41:48.073819: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-10 21:41:48.091988: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:41:48.092130: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6942 - loss: 1.0844 - val_accuracy: 0.6824 - val_loss: 0.5855\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7127 - loss: 0.5564 - val_accuracy: 0.6882 - val_loss: 0.5745\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7218 - loss: 0.5249 - val_accuracy: 0.6882 - val_loss: 0.5706\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6990 - loss: 0.5621 - val_accuracy: 0.6882 - val_loss: 0.5677\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.5166 - val_accuracy: 0.7059 - val_loss: 0.5654\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.5426 - val_accuracy: 0.7000 - val_loss: 0.5627\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.5300 - val_accuracy: 0.7000 - val_loss: 0.5604\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7458 - loss: 0.5007 - val_accuracy: 0.7000 - val_loss: 0.5606\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7434 - loss: 0.5391 - val_accuracy: 0.7000 - val_loss: 0.5591\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 0.5362 - val_accuracy: 0.7059 - val_loss: 0.5586\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7569 - loss: 0.5068 - val_accuracy: 0.6706 - val_loss: 0.5608\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7363 - loss: 0.5213 - val_accuracy: 0.7059 - val_loss: 0.5585\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7357 - loss: 0.5167 - val_accuracy: 0.6824 - val_loss: 0.5567\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7464 - loss: 0.5114 - val_accuracy: 0.7059 - val_loss: 0.5548\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.5160 - val_accuracy: 0.7059 - val_loss: 0.5557\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7256 - loss: 0.5235 - val_accuracy: 0.6765 - val_loss: 0.5534\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7459 - loss: 0.5169 - val_accuracy: 0.6824 - val_loss: 0.5544\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5086 - val_accuracy: 0.6824 - val_loss: 0.5541\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7493 - loss: 0.4950 - val_accuracy: 0.6765 - val_loss: 0.5607\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7407 - loss: 0.5111 - val_accuracy: 0.7059 - val_loss: 0.5592\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.5065 - val_accuracy: 0.6706 - val_loss: 0.5568\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7567 - loss: 0.4905 - val_accuracy: 0.6706 - val_loss: 0.5544\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7515 - loss: 0.4927 - val_accuracy: 0.7059 - val_loss: 0.5557\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7613 - loss: 0.4939 - val_accuracy: 0.6765 - val_loss: 0.5631\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7403 - loss: 0.4970 - val_accuracy: 0.7059 - val_loss: 0.5580\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7255 - loss: 0.5079 - val_accuracy: 0.7059 - val_loss: 0.5558\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7504 - loss: 0.4714 - val_accuracy: 0.6765 - val_loss: 0.5540\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7276 - loss: 0.4996 - val_accuracy: 0.7000 - val_loss: 0.5727\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.5070 - val_accuracy: 0.7059 - val_loss: 0.5563\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7730 - loss: 0.4749 - val_accuracy: 0.6765 - val_loss: 0.5542\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7651 - loss: 0.4661 - val_accuracy: 0.6765 - val_loss: 0.5519\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7760 - loss: 0.4629 - val_accuracy: 0.6824 - val_loss: 0.5504\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7287 - loss: 0.4975 - val_accuracy: 0.6941 - val_loss: 0.5525\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7651 - loss: 0.4803 - val_accuracy: 0.7118 - val_loss: 0.5581\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7507 - loss: 0.4945 - val_accuracy: 0.7176 - val_loss: 0.5599\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7619 - loss: 0.4786 - val_accuracy: 0.6765 - val_loss: 0.5495\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7783 - loss: 0.4636 - val_accuracy: 0.6824 - val_loss: 0.5537\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7547 - loss: 0.4718 - val_accuracy: 0.7000 - val_loss: 0.5525\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7621 - loss: 0.4456 - val_accuracy: 0.6941 - val_loss: 0.5456\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7766 - loss: 0.4428 - val_accuracy: 0.7059 - val_loss: 0.5511\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7501 - loss: 0.4601 - val_accuracy: 0.6882 - val_loss: 0.5441\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7448 - loss: 0.4714 - val_accuracy: 0.7000 - val_loss: 0.5459\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7752 - loss: 0.4645 - val_accuracy: 0.7118 - val_loss: 0.5503\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7849 - loss: 0.4659 - val_accuracy: 0.6824 - val_loss: 0.5452\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7705 - loss: 0.4442 - val_accuracy: 0.6882 - val_loss: 0.5466\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7942 - loss: 0.4381 - val_accuracy: 0.6882 - val_loss: 0.5419\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7837 - loss: 0.4427 - val_accuracy: 0.6824 - val_loss: 0.5451\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7816 - loss: 0.4470 - val_accuracy: 0.6882 - val_loss: 0.5470\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7897 - loss: 0.4399 - val_accuracy: 0.6824 - val_loss: 0.5442\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7943 - loss: 0.4396 - val_accuracy: 0.6882 - val_loss: 0.5460\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Model GC-2.keras - Accuracy: 0.7533333333333333\n",
      "Model GC-2.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./german/german_onnx/GC-2.onnx\n",
      "Loading model GC-3.keras\n",
      "Training model GC-3.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 21:41:51.527744: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:41:51.527876: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-10 21:41:51.545422: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:41:51.545502: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5901 - loss: 0.7036 - val_accuracy: 0.6529 - val_loss: 0.6845\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6807 - loss: 0.6795 - val_accuracy: 0.6706 - val_loss: 0.6752\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6920 - loss: 0.6578 - val_accuracy: 0.6647 - val_loss: 0.6629\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7093 - loss: 0.6414 - val_accuracy: 0.6765 - val_loss: 0.6531\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7170 - loss: 0.6131 - val_accuracy: 0.6765 - val_loss: 0.6447\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.6210 - val_accuracy: 0.6765 - val_loss: 0.6359\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6955 - loss: 0.6164 - val_accuracy: 0.6765 - val_loss: 0.6292\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6949 - loss: 0.6258 - val_accuracy: 0.6765 - val_loss: 0.6230\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7020 - loss: 0.6086 - val_accuracy: 0.6765 - val_loss: 0.6169\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7058 - loss: 0.5918 - val_accuracy: 0.6765 - val_loss: 0.6122\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7108 - loss: 0.5862 - val_accuracy: 0.6765 - val_loss: 0.6074\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7111 - loss: 0.5702 - val_accuracy: 0.6765 - val_loss: 0.6043\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6710 - loss: 0.6046 - val_accuracy: 0.6765 - val_loss: 0.5992\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7046 - loss: 0.5753 - val_accuracy: 0.6824 - val_loss: 0.5973\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6775 - loss: 0.5954 - val_accuracy: 0.6647 - val_loss: 0.5913\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7334 - loss: 0.5370 - val_accuracy: 0.6706 - val_loss: 0.5888\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6886 - loss: 0.5768 - val_accuracy: 0.6706 - val_loss: 0.5853\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6910 - loss: 0.5638 - val_accuracy: 0.6647 - val_loss: 0.5826\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6845 - loss: 0.5710 - val_accuracy: 0.6647 - val_loss: 0.5807\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6631 - loss: 0.5761 - val_accuracy: 0.6647 - val_loss: 0.5773\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6909 - loss: 0.5480 - val_accuracy: 0.6647 - val_loss: 0.5765\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6660 - loss: 0.5729 - val_accuracy: 0.6588 - val_loss: 0.5728\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6965 - loss: 0.5508 - val_accuracy: 0.6647 - val_loss: 0.5724\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6773 - loss: 0.5650 - val_accuracy: 0.6706 - val_loss: 0.5699\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6966 - loss: 0.5410 - val_accuracy: 0.6647 - val_loss: 0.5680\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7042 - loss: 0.5404 - val_accuracy: 0.6588 - val_loss: 0.5662\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6961 - loss: 0.5470 - val_accuracy: 0.6588 - val_loss: 0.5667\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6883 - loss: 0.5562 - val_accuracy: 0.6647 - val_loss: 0.5641\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7063 - loss: 0.5321 - val_accuracy: 0.6588 - val_loss: 0.5635\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.5172 - val_accuracy: 0.6706 - val_loss: 0.5619\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7011 - loss: 0.5446 - val_accuracy: 0.6765 - val_loss: 0.5603\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7164 - loss: 0.5172 - val_accuracy: 0.6765 - val_loss: 0.5592\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7148 - loss: 0.5301 - val_accuracy: 0.6765 - val_loss: 0.5579\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7113 - loss: 0.5466 - val_accuracy: 0.6882 - val_loss: 0.5571\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7022 - loss: 0.5495 - val_accuracy: 0.6765 - val_loss: 0.5575\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.5330 - val_accuracy: 0.6824 - val_loss: 0.5561\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7380 - loss: 0.5094 - val_accuracy: 0.6941 - val_loss: 0.5552\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7331 - loss: 0.5313 - val_accuracy: 0.6941 - val_loss: 0.5552\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7559 - loss: 0.4907 - val_accuracy: 0.6941 - val_loss: 0.5555\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7609 - loss: 0.4941 - val_accuracy: 0.7059 - val_loss: 0.5543\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7398 - loss: 0.5246 - val_accuracy: 0.7000 - val_loss: 0.5537\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.5485 - val_accuracy: 0.6941 - val_loss: 0.5553\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 0.5219 - val_accuracy: 0.7000 - val_loss: 0.5539\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.5311 - val_accuracy: 0.6941 - val_loss: 0.5534\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7454 - loss: 0.5099 - val_accuracy: 0.7000 - val_loss: 0.5539\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7404 - loss: 0.5293 - val_accuracy: 0.6941 - val_loss: 0.5533\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7850 - loss: 0.4765 - val_accuracy: 0.6882 - val_loss: 0.5533\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7521 - loss: 0.5180 - val_accuracy: 0.6941 - val_loss: 0.5538\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6927 - loss: 0.5611 - val_accuracy: 0.6941 - val_loss: 0.5534\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7140 - loss: 0.5447 - val_accuracy: 0.6941 - val_loss: 0.5546\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x796bc82ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x796bc82ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x796bc82ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x796bc82ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Model GC-3.keras - Accuracy: 0.7\n",
      "Model GC-3.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./german/german_onnx/GC-3.onnx\n",
      "Loading model GC-4.keras\n",
      "Training model GC-4.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 21:41:55.433003: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:41:55.433095: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-10 21:41:55.450674: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:41:55.450761: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6520 - loss: 0.6911 - val_accuracy: 0.6941 - val_loss: 0.6854\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.6819 - val_accuracy: 0.6941 - val_loss: 0.6784\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6741 - loss: 0.6785 - val_accuracy: 0.6941 - val_loss: 0.6723\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6932 - loss: 0.6709 - val_accuracy: 0.6941 - val_loss: 0.6663\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6933 - loss: 0.6649 - val_accuracy: 0.6941 - val_loss: 0.6608\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6966 - loss: 0.6590 - val_accuracy: 0.6941 - val_loss: 0.6560\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7038 - loss: 0.6526 - val_accuracy: 0.6941 - val_loss: 0.6515\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7270 - loss: 0.6419 - val_accuracy: 0.6941 - val_loss: 0.6472\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7272 - loss: 0.6366 - val_accuracy: 0.6941 - val_loss: 0.6436\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6986 - loss: 0.6414 - val_accuracy: 0.6941 - val_loss: 0.6406\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7121 - loss: 0.6335 - val_accuracy: 0.6941 - val_loss: 0.6376\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7029 - loss: 0.6335 - val_accuracy: 0.6941 - val_loss: 0.6349\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6974 - loss: 0.6328 - val_accuracy: 0.6941 - val_loss: 0.6323\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.6250 - val_accuracy: 0.6941 - val_loss: 0.6304\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6922 - loss: 0.6307 - val_accuracy: 0.6941 - val_loss: 0.6285\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.6128 - val_accuracy: 0.6941 - val_loss: 0.6268\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6655 - loss: 0.6409 - val_accuracy: 0.6941 - val_loss: 0.6255\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7136 - loss: 0.6149 - val_accuracy: 0.6941 - val_loss: 0.6240\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7235 - loss: 0.6077 - val_accuracy: 0.6941 - val_loss: 0.6229\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7004 - loss: 0.6191 - val_accuracy: 0.6941 - val_loss: 0.6220\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6864 - loss: 0.6262 - val_accuracy: 0.6941 - val_loss: 0.6211\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6780 - loss: 0.6306 - val_accuracy: 0.6941 - val_loss: 0.6205\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7156 - loss: 0.6071 - val_accuracy: 0.6941 - val_loss: 0.6197\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.6057 - val_accuracy: 0.6941 - val_loss: 0.6190\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6863 - loss: 0.6239 - val_accuracy: 0.6941 - val_loss: 0.6185\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5950 - val_accuracy: 0.6941 - val_loss: 0.6180\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.5976 - val_accuracy: 0.6941 - val_loss: 0.6176\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7181 - loss: 0.6010 - val_accuracy: 0.6941 - val_loss: 0.6173\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7137 - loss: 0.6035 - val_accuracy: 0.6941 - val_loss: 0.6170\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7047 - loss: 0.6094 - val_accuracy: 0.6941 - val_loss: 0.6167\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6937 - loss: 0.6170 - val_accuracy: 0.6941 - val_loss: 0.6166\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7108 - loss: 0.6044 - val_accuracy: 0.6941 - val_loss: 0.6164\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6806 - loss: 0.6265 - val_accuracy: 0.6941 - val_loss: 0.6164\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6988 - loss: 0.6129 - val_accuracy: 0.6941 - val_loss: 0.6162\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7088 - loss: 0.6051 - val_accuracy: 0.6941 - val_loss: 0.6161\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7386 - loss: 0.5819 - val_accuracy: 0.6941 - val_loss: 0.6160\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7049 - loss: 0.6076 - val_accuracy: 0.6941 - val_loss: 0.6159\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7104 - loss: 0.6032 - val_accuracy: 0.6941 - val_loss: 0.6159\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6992 - loss: 0.6119 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6963 - loss: 0.6141 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.5854 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7120 - loss: 0.6015 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7025 - loss: 0.6090 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6953 - loss: 0.6148 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.5900 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6772 - loss: 0.6296 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.5920 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6955 - loss: 0.6146 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.5976 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7140 - loss: 0.5993 - val_accuracy: 0.6941 - val_loss: 0.6158\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Model GC-4.keras - Accuracy: 0.6933333333333334\n",
      "Model GC-4.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./german/german_onnx/GC-4.onnx\n",
      "Loading model GC-5.keras\n",
      "Training model GC-5.keras\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 21:41:59.709202: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:41:59.709322: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-10 21:41:59.729225: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:41:59.729341: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6530 - loss: 0.6861 - val_accuracy: 0.6941 - val_loss: 0.6558\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7178 - loss: 0.6389 - val_accuracy: 0.6941 - val_loss: 0.6179\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 0.6038 - val_accuracy: 0.6941 - val_loss: 0.6130\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6815 - loss: 0.6205 - val_accuracy: 0.6941 - val_loss: 0.6099\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7116 - loss: 0.5865 - val_accuracy: 0.6941 - val_loss: 0.6060\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7018 - loss: 0.5938 - val_accuracy: 0.6941 - val_loss: 0.6014\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7074 - loss: 0.5843 - val_accuracy: 0.6941 - val_loss: 0.5963\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6966 - loss: 0.5891 - val_accuracy: 0.6941 - val_loss: 0.5906\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6903 - loss: 0.5839 - val_accuracy: 0.6941 - val_loss: 0.5811\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 0.5600 - val_accuracy: 0.6941 - val_loss: 0.5671\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6868 - loss: 0.5587 - val_accuracy: 0.6941 - val_loss: 0.5567\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6948 - loss: 0.5388 - val_accuracy: 0.6941 - val_loss: 0.5498\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6970 - loss: 0.5262 - val_accuracy: 0.6941 - val_loss: 0.5434\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6947 - loss: 0.5319 - val_accuracy: 0.6941 - val_loss: 0.5390\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7045 - loss: 0.5229 - val_accuracy: 0.6941 - val_loss: 0.5488\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.5115 - val_accuracy: 0.6941 - val_loss: 0.5378\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7099 - loss: 0.5189 - val_accuracy: 0.6941 - val_loss: 0.5375\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 0.5091 - val_accuracy: 0.7000 - val_loss: 0.5405\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: 0.5027 - val_accuracy: 0.7000 - val_loss: 0.5460\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.4985 - val_accuracy: 0.7059 - val_loss: 0.5492\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7572 - loss: 0.4816 - val_accuracy: 0.6824 - val_loss: 0.5623\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7656 - loss: 0.4653 - val_accuracy: 0.6353 - val_loss: 0.5614\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7578 - loss: 0.4707 - val_accuracy: 0.6588 - val_loss: 0.5720\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7784 - loss: 0.4357 - val_accuracy: 0.6294 - val_loss: 0.5738\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7457 - loss: 0.4721 - val_accuracy: 0.6412 - val_loss: 0.5774\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7656 - loss: 0.4551 - val_accuracy: 0.6529 - val_loss: 0.5804\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8051 - loss: 0.4168 - val_accuracy: 0.6529 - val_loss: 0.6084\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7815 - loss: 0.4229 - val_accuracy: 0.6588 - val_loss: 0.5925\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7988 - loss: 0.4139 - val_accuracy: 0.6412 - val_loss: 0.5916\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7879 - loss: 0.4426 - val_accuracy: 0.6176 - val_loss: 0.5962\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7995 - loss: 0.4128 - val_accuracy: 0.6412 - val_loss: 0.6103\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8058 - loss: 0.4299 - val_accuracy: 0.6412 - val_loss: 0.5972\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.4226 - val_accuracy: 0.6412 - val_loss: 0.6119\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 0.3837 - val_accuracy: 0.6647 - val_loss: 0.5872\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8360 - loss: 0.3650 - val_accuracy: 0.6294 - val_loss: 0.6633\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8225 - loss: 0.3779 - val_accuracy: 0.6294 - val_loss: 0.5972\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8273 - loss: 0.3577 - val_accuracy: 0.6235 - val_loss: 0.6456\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.3592 - val_accuracy: 0.6706 - val_loss: 0.6184\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3556 - val_accuracy: 0.6471 - val_loss: 0.6456\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 0.3731 - val_accuracy: 0.6706 - val_loss: 0.6655\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3534 - val_accuracy: 0.6294 - val_loss: 0.6101\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3387 - val_accuracy: 0.6706 - val_loss: 0.7092\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.3926 - val_accuracy: 0.6412 - val_loss: 0.6693\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8309 - loss: 0.3508 - val_accuracy: 0.6412 - val_loss: 0.5925\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8443 - loss: 0.3335 - val_accuracy: 0.6529 - val_loss: 0.6755\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8497 - loss: 0.3072 - val_accuracy: 0.6588 - val_loss: 0.6720\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8652 - loss: 0.3042 - val_accuracy: 0.6471 - val_loss: 0.6729\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8786 - loss: 0.2869 - val_accuracy: 0.6647 - val_loss: 0.6740\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.2790 - val_accuracy: 0.6412 - val_loss: 0.6729\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8949 - loss: 0.2727 - val_accuracy: 0.6529 - val_loss: 0.7088\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Model GC-5.keras - Accuracy: 0.7733333333333333\n",
      "Model GC-5.keras retrained and saved successfully.\n",
      "Model has been saved in ONNX format at ./german/german_onnx/GC-5.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 21:42:04.178906: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:42:04.178987: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-10 21:42:04.211691: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:42:04.211774: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the German dataset\n",
    "X_train, X_test, y_train, y_test = load_and_save_german_data()\n",
    "\n",
    "for model_file in os.listdir(save_dir):\n",
    "    if model_file.endswith('.keras'):\n",
    "        model_path = os.path.join(save_dir, model_file)\n",
    "        \n",
    "        try:\n",
    "            # Load the modified model\n",
    "            print(f\"Loading model {model_file}\")\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "                model = load_model(model_path)\n",
    "\n",
    "            # Reinitialize the optimizer\n",
    "            model.compile(\n",
    "                optimizer=Adam(),\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "            # Fit the model\n",
    "            print(f\"Training model {model_file}\")\n",
    "            history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "            # Evaluate the model\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "            accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred_classes)\n",
    "\n",
    "            print(f\"Model {model_file} - Accuracy: {accuracy}\")\n",
    "\n",
    "            # Save the retrained model\n",
    "            model.save(model_path)\n",
    "            print(f\"Model {model_file} retrained and saved successfully.\")\n",
    "\n",
    "            # Save the model as ONNX\n",
    "            onnx_save_path = os.path.join(onnx_save_dir, model_file.replace('.keras', '.onnx'))\n",
    "            save_model_onnx(model, (20,), onnx_save_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {model_file}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversairal Debiasing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_csv(filename, model_file, model_name, classification_accuracy, balanced_accuracy, disparate_impact, equal_opportunity_difference, average_odds_difference):\n",
    "    # Check if the file exists to write the header only once\n",
    "    file_exists = os.path.isfile(filename)\n",
    "\n",
    "    with open(filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            # Write the header if the file does not exist\n",
    "            writer.writerow(['Model File', 'Model', 'Classification Accuracy', 'Balanced Accuracy', 'Disparate Impact', 'Equal Opportunity Difference', 'Average Odds Difference'])\n",
    "        \n",
    "        # Write the metrics\n",
    "        writer.writerow([model_file, model_name, classification_accuracy, balanced_accuracy, disparate_impact, equal_opportunity_difference, average_odds_difference])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various metrics for evaluation including accuracy and fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics calculation functions\n",
    "def classification_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    classes = np.unique(y_true)\n",
    "    recall_scores = []\n",
    "    for cls in classes:\n",
    "        true_positives = np.sum((y_true == cls) & (y_pred == cls))\n",
    "        possible_positives = np.sum(y_true == cls)\n",
    "        recall_scores.append(true_positives / possible_positives)\n",
    "    return np.mean(recall_scores)\n",
    "\n",
    "def disparate_impact(y_true, y_pred, protected_attribute):\n",
    "    privileged = protected_attribute == 1\n",
    "    unprivileged = protected_attribute == 0\n",
    "    if np.sum(privileged) == 0 or np.sum(unprivileged) == 0:\n",
    "        return np.nan\n",
    "    privileged_outcome = np.mean(y_pred[privileged]) if np.sum(privileged) > 0 else np.nan\n",
    "    unprivileged_outcome = np.mean(y_pred[unprivileged]) if np.sum(unprivileged) > 0 else np.nan\n",
    "    if privileged_outcome == 0:\n",
    "        return np.nan  \n",
    "    return unprivileged_outcome / privileged_outcome\n",
    "\n",
    "def equal_opportunity_difference(y_true, y_pred, protected_attribute):\n",
    "    privileged = protected_attribute == 1\n",
    "    unprivileged = protected_attribute == 0\n",
    "    true_positive_rate_privileged = np.sum((y_true[privileged] == 1) & (y_pred[privileged] == 1)) / np.sum(y_true[privileged] == 1)\n",
    "    true_positive_rate_unprivileged = np.sum((y_true[unprivileged] == 1) & (y_pred[unprivileged] == 1)) / np.sum(y_true[unprivileged] == 1)\n",
    "    return true_positive_rate_unprivileged - true_positive_rate_privileged\n",
    "\n",
    "def average_odds_difference(y_true, y_pred, protected_attribute):\n",
    "    privileged = protected_attribute == 1\n",
    "    unprivileged = protected_attribute == 0\n",
    "    tpr_privileged = np.sum((y_true[privileged] == 1) & (y_pred[privileged] == 1)) / np.sum(y_true[privileged] == 1)\n",
    "    tpr_unprivileged = np.sum((y_true[unprivileged] == 1) & (y_pred[unprivileged] == 1)) / np.sum(y_true[unprivileged] == 1)\n",
    "    fpr_privileged = np.sum((y_true[privileged] == 0) & (y_pred[privileged] == 1)) / np.sum(y_true[privileged] == 0)\n",
    "    fpr_unprivileged = np.sum((y_true[unprivileged] == 0) & (y_pred[unprivileged] == 1)) / np.sum(y_true[unprivileged] == 0)\n",
    "    average_odds_privileged = (tpr_privileged + fpr_privileged) / 2\n",
    "    average_odds_unprivileged = (tpr_unprivileged + fpr_unprivileged) / 2\n",
    "    return average_odds_unprivileged - average_odds_privileged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./german/german_keras/GC-1.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50, Classification Loss: 0.4777572453022003, Adversary Loss: 0.693507194519043\n",
      "Epoch 2/50, Classification Loss: 0.4861471951007843, Adversary Loss: 0.6141618490219116\n",
      "Epoch 3/50, Classification Loss: 0.5050150752067566, Adversary Loss: 0.5744163990020752\n",
      "Epoch 4/50, Classification Loss: 0.4967416822910309, Adversary Loss: 0.5904921889305115\n",
      "Epoch 5/50, Classification Loss: 0.386519193649292, Adversary Loss: 0.6527164578437805\n",
      "Epoch 6/50, Classification Loss: 0.43326056003570557, Adversary Loss: 0.5845215320587158\n",
      "Epoch 7/50, Classification Loss: 0.48554661870002747, Adversary Loss: 0.642375648021698\n",
      "Epoch 8/50, Classification Loss: 0.4750366806983948, Adversary Loss: 0.6102771162986755\n",
      "Epoch 9/50, Classification Loss: 0.5047731399536133, Adversary Loss: 0.6226220726966858\n",
      "Epoch 10/50, Classification Loss: 0.39498353004455566, Adversary Loss: 0.6417691707611084\n",
      "Epoch 11/50, Classification Loss: 0.4522440433502197, Adversary Loss: 0.6269094944000244\n",
      "Epoch 12/50, Classification Loss: 0.4680393636226654, Adversary Loss: 0.6580477952957153\n",
      "Epoch 13/50, Classification Loss: 0.4460863769054413, Adversary Loss: 0.656721830368042\n",
      "Epoch 14/50, Classification Loss: 0.5984110832214355, Adversary Loss: 0.6048567295074463\n",
      "Epoch 15/50, Classification Loss: 0.5440024137496948, Adversary Loss: 0.645285964012146\n",
      "Epoch 16/50, Classification Loss: 0.4992228150367737, Adversary Loss: 0.6179829835891724\n",
      "Epoch 17/50, Classification Loss: 0.4724515676498413, Adversary Loss: 0.5916156768798828\n",
      "Epoch 18/50, Classification Loss: 0.43095362186431885, Adversary Loss: 0.6418184041976929\n",
      "Epoch 19/50, Classification Loss: 0.42640596628189087, Adversary Loss: 0.6640487909317017\n",
      "Epoch 20/50, Classification Loss: 0.4505283534526825, Adversary Loss: 0.621985673904419\n",
      "Epoch 21/50, Classification Loss: 0.48383939266204834, Adversary Loss: 0.676442563533783\n",
      "Epoch 22/50, Classification Loss: 0.4975292980670929, Adversary Loss: 0.5884429812431335\n",
      "Epoch 23/50, Classification Loss: 0.43771302700042725, Adversary Loss: 0.6359832286834717\n",
      "Epoch 24/50, Classification Loss: 0.4103320837020874, Adversary Loss: 0.5950985550880432\n",
      "Epoch 25/50, Classification Loss: 0.3763546347618103, Adversary Loss: 0.6573222279548645\n",
      "Epoch 26/50, Classification Loss: 0.4545510411262512, Adversary Loss: 0.6571938395500183\n",
      "Epoch 27/50, Classification Loss: 0.4873242676258087, Adversary Loss: 0.6777117252349854\n",
      "Epoch 28/50, Classification Loss: 0.4491730332374573, Adversary Loss: 0.66596519947052\n",
      "Epoch 29/50, Classification Loss: 0.5014926195144653, Adversary Loss: 0.5101463794708252\n",
      "Epoch 30/50, Classification Loss: 0.5151974558830261, Adversary Loss: 0.6547703742980957\n",
      "Epoch 31/50, Classification Loss: 0.5340797901153564, Adversary Loss: 0.615575909614563\n",
      "Epoch 32/50, Classification Loss: 0.44214048981666565, Adversary Loss: 0.6074492335319519\n",
      "Epoch 33/50, Classification Loss: 0.4942997694015503, Adversary Loss: 0.5450475811958313\n",
      "Epoch 34/50, Classification Loss: 0.4052956700325012, Adversary Loss: 0.6611620187759399\n",
      "Epoch 35/50, Classification Loss: 0.413845956325531, Adversary Loss: 0.5897495746612549\n",
      "Epoch 36/50, Classification Loss: 0.4460756182670593, Adversary Loss: 0.6286814212799072\n",
      "Epoch 37/50, Classification Loss: 0.42164817452430725, Adversary Loss: 0.618257462978363\n",
      "Epoch 38/50, Classification Loss: 0.4741881191730499, Adversary Loss: 0.6771093606948853\n",
      "Epoch 39/50, Classification Loss: 0.43538349866867065, Adversary Loss: 0.6146058440208435\n",
      "Epoch 40/50, Classification Loss: 0.4087176024913788, Adversary Loss: 0.5993973016738892\n",
      "Epoch 41/50, Classification Loss: 0.4245399832725525, Adversary Loss: 0.5975378751754761\n",
      "Epoch 42/50, Classification Loss: 0.36787986755371094, Adversary Loss: 0.6794430017471313\n",
      "Epoch 43/50, Classification Loss: 0.38717877864837646, Adversary Loss: 0.6357623338699341\n",
      "Epoch 44/50, Classification Loss: 0.4784389138221741, Adversary Loss: 0.6566453576087952\n",
      "Epoch 45/50, Classification Loss: 0.4367777705192566, Adversary Loss: 0.7441784143447876\n",
      "Epoch 46/50, Classification Loss: 0.4612477421760559, Adversary Loss: 0.6232771873474121\n",
      "Epoch 47/50, Classification Loss: 0.3796861469745636, Adversary Loss: 0.5756536722183228\n",
      "Epoch 48/50, Classification Loss: 0.39749303460121155, Adversary Loss: 0.553986132144928\n",
      "Epoch 49/50, Classification Loss: 0.4271407127380371, Adversary Loss: 0.5833817720413208\n",
      "Epoch 50/50, Classification Loss: 0.43318840861320496, Adversary Loss: 0.6133450269699097\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step\n",
      "Model has been saved in ONNX format at ./german/german_debiased_onnx/GC-1.onnx\n",
      "Loading model from ./german/german_keras/GC-2.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 21:42:20.562575: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:42:20.562733: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-10 21:42:20.591673: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:42:20.591837: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Classification Loss: 0.41636988520622253, Adversary Loss: 0.6667576432228088\n",
      "Epoch 2/50, Classification Loss: 0.3881838023662567, Adversary Loss: 0.6283025145530701\n",
      "Epoch 3/50, Classification Loss: 0.4532621502876282, Adversary Loss: 0.604989230632782\n",
      "Epoch 4/50, Classification Loss: 0.44181907176971436, Adversary Loss: 0.685588538646698\n",
      "Epoch 5/50, Classification Loss: 0.39300113916397095, Adversary Loss: 0.5952778458595276\n",
      "Epoch 6/50, Classification Loss: 0.5146796703338623, Adversary Loss: 0.6283681988716125\n",
      "Epoch 7/50, Classification Loss: 0.4359915554523468, Adversary Loss: 0.6207285523414612\n",
      "Epoch 8/50, Classification Loss: 0.4620969295501709, Adversary Loss: 0.6686885356903076\n",
      "Epoch 9/50, Classification Loss: 0.35576242208480835, Adversary Loss: 0.6183834671974182\n",
      "Epoch 10/50, Classification Loss: 0.4114015996456146, Adversary Loss: 0.5780426859855652\n",
      "Epoch 11/50, Classification Loss: 0.4176478981971741, Adversary Loss: 0.6144431829452515\n",
      "Epoch 12/50, Classification Loss: 0.4118046164512634, Adversary Loss: 0.6033129096031189\n",
      "Epoch 13/50, Classification Loss: 0.39340829849243164, Adversary Loss: 0.6061866283416748\n",
      "Epoch 14/50, Classification Loss: 0.41526785492897034, Adversary Loss: 0.6555212736129761\n",
      "Epoch 15/50, Classification Loss: 0.49204152822494507, Adversary Loss: 0.6230217814445496\n",
      "Epoch 16/50, Classification Loss: 0.42657527327537537, Adversary Loss: 0.6035621166229248\n",
      "Epoch 17/50, Classification Loss: 0.46268075704574585, Adversary Loss: 0.655933678150177\n",
      "Epoch 18/50, Classification Loss: 0.36274880170822144, Adversary Loss: 0.5938170552253723\n",
      "Epoch 19/50, Classification Loss: 0.401599645614624, Adversary Loss: 0.61134272813797\n",
      "Epoch 20/50, Classification Loss: 0.48651763796806335, Adversary Loss: 0.6262454986572266\n",
      "Epoch 21/50, Classification Loss: 0.3885563910007477, Adversary Loss: 0.6575777530670166\n",
      "Epoch 22/50, Classification Loss: 0.43601664900779724, Adversary Loss: 0.6236437559127808\n",
      "Epoch 23/50, Classification Loss: 0.3906363844871521, Adversary Loss: 0.5901198983192444\n",
      "Epoch 24/50, Classification Loss: 0.4330381453037262, Adversary Loss: 0.6203079223632812\n",
      "Epoch 25/50, Classification Loss: 0.48559123277664185, Adversary Loss: 0.6580437421798706\n",
      "Epoch 26/50, Classification Loss: 0.4617338478565216, Adversary Loss: 0.539560854434967\n",
      "Epoch 27/50, Classification Loss: 0.43469876050949097, Adversary Loss: 0.5863668918609619\n",
      "Epoch 28/50, Classification Loss: 0.4231557250022888, Adversary Loss: 0.6486510038375854\n",
      "Epoch 29/50, Classification Loss: 0.4410029947757721, Adversary Loss: 0.5843282341957092\n",
      "Epoch 30/50, Classification Loss: 0.4426770508289337, Adversary Loss: 0.64327472448349\n",
      "Epoch 31/50, Classification Loss: 0.398366242647171, Adversary Loss: 0.5848126411437988\n",
      "Epoch 32/50, Classification Loss: 0.4543139636516571, Adversary Loss: 0.6300636529922485\n",
      "Epoch 33/50, Classification Loss: 0.5684911012649536, Adversary Loss: 0.6150184869766235\n",
      "Epoch 34/50, Classification Loss: 0.405657559633255, Adversary Loss: 0.6467341184616089\n",
      "Epoch 35/50, Classification Loss: 0.40784338116645813, Adversary Loss: 0.6406539082527161\n",
      "Epoch 36/50, Classification Loss: 0.44336965680122375, Adversary Loss: 0.6541820168495178\n",
      "Epoch 37/50, Classification Loss: 0.44585683941841125, Adversary Loss: 0.6277050375938416\n",
      "Epoch 38/50, Classification Loss: 0.38352057337760925, Adversary Loss: 0.6207525730133057\n",
      "Epoch 39/50, Classification Loss: 0.3770626485347748, Adversary Loss: 0.6336326003074646\n",
      "Epoch 40/50, Classification Loss: 0.4320971667766571, Adversary Loss: 0.630491316318512\n",
      "Epoch 41/50, Classification Loss: 0.443502277135849, Adversary Loss: 0.6462856531143188\n",
      "Epoch 42/50, Classification Loss: 0.37002241611480713, Adversary Loss: 0.6038098931312561\n",
      "Epoch 43/50, Classification Loss: 0.3866868019104004, Adversary Loss: 0.5722545981407166\n",
      "Epoch 44/50, Classification Loss: 0.41102367639541626, Adversary Loss: 0.5487868785858154\n",
      "Epoch 45/50, Classification Loss: 0.38009533286094666, Adversary Loss: 0.6214689016342163\n",
      "Epoch 46/50, Classification Loss: 0.45635437965393066, Adversary Loss: 0.5974692106246948\n",
      "Epoch 47/50, Classification Loss: 0.4289587438106537, Adversary Loss: 0.6499629020690918\n",
      "Epoch 48/50, Classification Loss: 0.4634406864643097, Adversary Loss: 0.6589899063110352\n",
      "Epoch 49/50, Classification Loss: 0.39200788736343384, Adversary Loss: 0.6828359365463257\n",
      "Epoch 50/50, Classification Loss: 0.4565441310405731, Adversary Loss: 0.6194620728492737\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step\n",
      "Model has been saved in ONNX format at ./german/german_debiased_onnx/GC-2.onnx\n",
      "Loading model from ./german/german_keras/GC-3.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 21:42:36.623799: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:42:36.623903: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-10 21:42:36.639931: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:42:36.640016: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Classification Loss: 0.5753607749938965, Adversary Loss: 0.6786452531814575\n",
      "Epoch 2/50, Classification Loss: 0.595988929271698, Adversary Loss: 0.6672905683517456\n",
      "Epoch 3/50, Classification Loss: 0.4906458854675293, Adversary Loss: 0.648726224899292\n",
      "Epoch 4/50, Classification Loss: 0.5723000764846802, Adversary Loss: 0.6367440819740295\n",
      "Epoch 5/50, Classification Loss: 0.5836803913116455, Adversary Loss: 0.6776368618011475\n",
      "Epoch 6/50, Classification Loss: 0.5085002183914185, Adversary Loss: 0.6295909881591797\n",
      "Epoch 7/50, Classification Loss: 0.5674439668655396, Adversary Loss: 0.6253600716590881\n",
      "Epoch 8/50, Classification Loss: 0.565727174282074, Adversary Loss: 0.6324254870414734\n",
      "Epoch 9/50, Classification Loss: 0.49937132000923157, Adversary Loss: 0.5367003679275513\n",
      "Epoch 10/50, Classification Loss: 0.5387239456176758, Adversary Loss: 0.6260751485824585\n",
      "Epoch 11/50, Classification Loss: 0.5506872534751892, Adversary Loss: 0.611318051815033\n",
      "Epoch 12/50, Classification Loss: 0.5417171120643616, Adversary Loss: 0.6157240271568298\n",
      "Epoch 13/50, Classification Loss: 0.5798987150192261, Adversary Loss: 0.5680382251739502\n",
      "Epoch 14/50, Classification Loss: 0.45173388719558716, Adversary Loss: 0.6003598570823669\n",
      "Epoch 15/50, Classification Loss: 0.5098963975906372, Adversary Loss: 0.6037800312042236\n",
      "Epoch 16/50, Classification Loss: 0.5291109085083008, Adversary Loss: 0.6085700988769531\n",
      "Epoch 17/50, Classification Loss: 0.5719907879829407, Adversary Loss: 0.617607831954956\n",
      "Epoch 18/50, Classification Loss: 0.5850205421447754, Adversary Loss: 0.6665902137756348\n",
      "Epoch 19/50, Classification Loss: 0.5456379055976868, Adversary Loss: 0.6139352917671204\n",
      "Epoch 20/50, Classification Loss: 0.5046026110649109, Adversary Loss: 0.6137204766273499\n",
      "Epoch 21/50, Classification Loss: 0.5372738242149353, Adversary Loss: 0.7084552049636841\n",
      "Epoch 22/50, Classification Loss: 0.632378339767456, Adversary Loss: 0.5919527411460876\n",
      "Epoch 23/50, Classification Loss: 0.5218199491500854, Adversary Loss: 0.5970292091369629\n",
      "Epoch 24/50, Classification Loss: 0.46011781692504883, Adversary Loss: 0.6096980571746826\n",
      "Epoch 25/50, Classification Loss: 0.5615754723548889, Adversary Loss: 0.696150541305542\n",
      "Epoch 26/50, Classification Loss: 0.459016889333725, Adversary Loss: 0.6585854887962341\n",
      "Epoch 27/50, Classification Loss: 0.5507147908210754, Adversary Loss: 0.6348303556442261\n",
      "Epoch 28/50, Classification Loss: 0.5728279948234558, Adversary Loss: 0.6091701984405518\n",
      "Epoch 29/50, Classification Loss: 0.4802665114402771, Adversary Loss: 0.5803488492965698\n",
      "Epoch 30/50, Classification Loss: 0.53444504737854, Adversary Loss: 0.665149450302124\n",
      "Epoch 31/50, Classification Loss: 0.5372889637947083, Adversary Loss: 0.592483639717102\n",
      "Epoch 32/50, Classification Loss: 0.5322175621986389, Adversary Loss: 0.6617093086242676\n",
      "Epoch 33/50, Classification Loss: 0.5550607442855835, Adversary Loss: 0.7161887288093567\n",
      "Epoch 34/50, Classification Loss: 0.5312598347663879, Adversary Loss: 0.686307430267334\n",
      "Epoch 35/50, Classification Loss: 0.5614600777626038, Adversary Loss: 0.6317822337150574\n",
      "Epoch 36/50, Classification Loss: 0.468234121799469, Adversary Loss: 0.6120839715003967\n",
      "Epoch 37/50, Classification Loss: 0.4927884042263031, Adversary Loss: 0.6238784193992615\n",
      "Epoch 38/50, Classification Loss: 0.5551919341087341, Adversary Loss: 0.7043233513832092\n",
      "Epoch 39/50, Classification Loss: 0.5509786605834961, Adversary Loss: 0.5919882655143738\n",
      "Epoch 40/50, Classification Loss: 0.46618732810020447, Adversary Loss: 0.6128552556037903\n",
      "Epoch 41/50, Classification Loss: 0.40692222118377686, Adversary Loss: 0.6127511262893677\n",
      "Epoch 42/50, Classification Loss: 0.5452550053596497, Adversary Loss: 0.7118052244186401\n",
      "Epoch 43/50, Classification Loss: 0.4932975769042969, Adversary Loss: 0.5600954294204712\n",
      "Epoch 44/50, Classification Loss: 0.49460452795028687, Adversary Loss: 0.6503909230232239\n",
      "Epoch 45/50, Classification Loss: 0.47428783774375916, Adversary Loss: 0.6054521203041077\n",
      "Epoch 46/50, Classification Loss: 0.5597610473632812, Adversary Loss: 0.5962309241294861\n",
      "Epoch 47/50, Classification Loss: 0.5339635014533997, Adversary Loss: 0.5966837406158447\n",
      "Epoch 48/50, Classification Loss: 0.6623423099517822, Adversary Loss: 0.6244073510169983\n",
      "Epoch 49/50, Classification Loss: 0.545929491519928, Adversary Loss: 0.6136873364448547\n",
      "Epoch 50/50, Classification Loss: 0.4868062138557434, Adversary Loss: 0.6362908482551575\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step\n",
      "Model has been saved in ONNX format at ./german/german_debiased_onnx/GC-3.onnx\n",
      "Loading model from ./german/german_keras/GC-4.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 21:42:52.340111: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:42:52.340195: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-10 21:42:52.356494: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:42:52.356581: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Classification Loss: 0.5646419525146484, Adversary Loss: 0.6427075266838074\n",
      "Epoch 2/50, Classification Loss: 0.6654554009437561, Adversary Loss: 0.6859434843063354\n",
      "Epoch 3/50, Classification Loss: 0.5745946168899536, Adversary Loss: 0.6129531264305115\n",
      "Epoch 4/50, Classification Loss: 0.5645034313201904, Adversary Loss: 0.6247860193252563\n",
      "Epoch 5/50, Classification Loss: 0.6149442195892334, Adversary Loss: 0.5949403643608093\n",
      "Epoch 6/50, Classification Loss: 0.6250980496406555, Adversary Loss: 0.6255003809928894\n",
      "Epoch 7/50, Classification Loss: 0.6149519681930542, Adversary Loss: 0.64559006690979\n",
      "Epoch 8/50, Classification Loss: 0.6455926895141602, Adversary Loss: 0.6755399107933044\n",
      "Epoch 9/50, Classification Loss: 0.512831449508667, Adversary Loss: 0.6054505109786987\n",
      "Epoch 10/50, Classification Loss: 0.5842449069023132, Adversary Loss: 0.6631074547767639\n",
      "Epoch 11/50, Classification Loss: 0.7178929448127747, Adversary Loss: 0.6058240532875061\n",
      "Epoch 12/50, Classification Loss: 0.62525475025177, Adversary Loss: 0.6060460805892944\n",
      "Epoch 13/50, Classification Loss: 0.6355627179145813, Adversary Loss: 0.5398210883140564\n",
      "Epoch 14/50, Classification Loss: 0.563603401184082, Adversary Loss: 0.6248864531517029\n",
      "Epoch 15/50, Classification Loss: 0.6149789094924927, Adversary Loss: 0.7034517526626587\n",
      "Epoch 16/50, Classification Loss: 0.5327905416488647, Adversary Loss: 0.6644473671913147\n",
      "Epoch 17/50, Classification Loss: 0.5943655371665955, Adversary Loss: 0.6055485010147095\n",
      "Epoch 18/50, Classification Loss: 0.6046692728996277, Adversary Loss: 0.6530428528785706\n",
      "Epoch 19/50, Classification Loss: 0.542661190032959, Adversary Loss: 0.6342340111732483\n",
      "Epoch 20/50, Classification Loss: 0.6253852248191833, Adversary Loss: 0.6342790722846985\n",
      "Epoch 21/50, Classification Loss: 0.6461355090141296, Adversary Loss: 0.6343498826026917\n",
      "Epoch 22/50, Classification Loss: 0.6669576168060303, Adversary Loss: 0.6340722441673279\n",
      "Epoch 23/50, Classification Loss: 0.6773014068603516, Adversary Loss: 0.6341779828071594\n",
      "Epoch 24/50, Classification Loss: 0.6460724472999573, Adversary Loss: 0.6438716053962708\n",
      "Epoch 25/50, Classification Loss: 0.5839466452598572, Adversary Loss: 0.5858139991760254\n",
      "Epoch 26/50, Classification Loss: 0.6046533584594727, Adversary Loss: 0.5857046842575073\n",
      "Epoch 27/50, Classification Loss: 0.6046578884124756, Adversary Loss: 0.624699592590332\n",
      "Epoch 28/50, Classification Loss: 0.6460705995559692, Adversary Loss: 0.6055325269699097\n",
      "Epoch 29/50, Classification Loss: 0.6357054710388184, Adversary Loss: 0.6149802803993225\n",
      "Epoch 30/50, Classification Loss: 0.583960771560669, Adversary Loss: 0.5854701399803162\n",
      "Epoch 31/50, Classification Loss: 0.6460956335067749, Adversary Loss: 0.654366135597229\n",
      "Epoch 32/50, Classification Loss: 0.6564352512359619, Adversary Loss: 0.5863127112388611\n",
      "Epoch 33/50, Classification Loss: 0.6149987578392029, Adversary Loss: 0.6343023180961609\n",
      "Epoch 34/50, Classification Loss: 0.6771013736724854, Adversary Loss: 0.6150863170623779\n",
      "Epoch 35/50, Classification Loss: 0.6667457222938538, Adversary Loss: 0.5665093660354614\n",
      "Epoch 36/50, Classification Loss: 0.6460144519805908, Adversary Loss: 0.6443087458610535\n",
      "Epoch 37/50, Classification Loss: 0.5633467435836792, Adversary Loss: 0.5668506622314453\n",
      "Epoch 38/50, Classification Loss: 0.5943430662155151, Adversary Loss: 0.5855265855789185\n",
      "Epoch 39/50, Classification Loss: 0.6356520652770996, Adversary Loss: 0.7350382804870605\n",
      "Epoch 40/50, Classification Loss: 0.6149976253509521, Adversary Loss: 0.5870251655578613\n",
      "Epoch 41/50, Classification Loss: 0.5839933753013611, Adversary Loss: 0.6625587344169617\n",
      "Epoch 42/50, Classification Loss: 0.6771532297134399, Adversary Loss: 0.6341740489006042\n",
      "Epoch 43/50, Classification Loss: 0.67709881067276, Adversary Loss: 0.6152559518814087\n",
      "Epoch 44/50, Classification Loss: 0.6770575046539307, Adversary Loss: 0.5487298965454102\n",
      "Epoch 45/50, Classification Loss: 0.6149905323982239, Adversary Loss: 0.6149623394012451\n",
      "Epoch 46/50, Classification Loss: 0.5943681597709656, Adversary Loss: 0.5851369500160217\n",
      "Epoch 47/50, Classification Loss: 0.5737435817718506, Adversary Loss: 0.6347671151161194\n",
      "Epoch 48/50, Classification Loss: 0.6253273487091064, Adversary Loss: 0.5960327982902527\n",
      "Epoch 49/50, Classification Loss: 0.6460493803024292, Adversary Loss: 0.605570375919342\n",
      "Epoch 50/50, Classification Loss: 0.6150009632110596, Adversary Loss: 0.5773046016693115\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step\n",
      "Model has been saved in ONNX format at ./german/german_debiased_onnx/GC-4.onnx\n",
      "Loading model from ./german/german_keras/GC-5.keras\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 21:43:10.153305: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:43:10.153411: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-10 21:43:10.173904: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:43:10.173987: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Epoch 1/50, Classification Loss: 0.43383508920669556, Adversary Loss: 0.6606075167655945\n",
      "Epoch 2/50, Classification Loss: 0.3096054196357727, Adversary Loss: 0.6543052196502686\n",
      "Epoch 3/50, Classification Loss: 0.38001078367233276, Adversary Loss: 0.6279376149177551\n",
      "Epoch 4/50, Classification Loss: 0.4212137460708618, Adversary Loss: 0.5857487916946411\n",
      "Epoch 5/50, Classification Loss: 0.3167945444583893, Adversary Loss: 0.553225040435791\n",
      "Epoch 6/50, Classification Loss: 0.3123852014541626, Adversary Loss: 0.6062723398208618\n",
      "Epoch 7/50, Classification Loss: 0.2863142490386963, Adversary Loss: 0.6174367070198059\n",
      "Epoch 8/50, Classification Loss: 0.32230493426322937, Adversary Loss: 0.74906986951828\n",
      "Epoch 9/50, Classification Loss: 0.38316476345062256, Adversary Loss: 0.5874425768852234\n",
      "Epoch 10/50, Classification Loss: 0.3167160749435425, Adversary Loss: 0.6269955039024353\n",
      "Epoch 11/50, Classification Loss: 0.3110535144805908, Adversary Loss: 0.5698184370994568\n",
      "Epoch 12/50, Classification Loss: 0.2817177176475525, Adversary Loss: 0.5981194972991943\n",
      "Epoch 13/50, Classification Loss: 0.40617239475250244, Adversary Loss: 0.7101376056671143\n",
      "Epoch 14/50, Classification Loss: 0.412908136844635, Adversary Loss: 0.6574311852455139\n",
      "Epoch 15/50, Classification Loss: 0.2688356041908264, Adversary Loss: 0.6089856624603271\n",
      "Epoch 16/50, Classification Loss: 0.23397909104824066, Adversary Loss: 0.571176290512085\n",
      "Epoch 17/50, Classification Loss: 0.4044068157672882, Adversary Loss: 0.6431466937065125\n",
      "Epoch 18/50, Classification Loss: 0.29195234179496765, Adversary Loss: 0.6871618628501892\n",
      "Epoch 19/50, Classification Loss: 0.3356418013572693, Adversary Loss: 0.625078558921814\n",
      "Epoch 20/50, Classification Loss: 0.2004849910736084, Adversary Loss: 0.5846183896064758\n",
      "Epoch 21/50, Classification Loss: 0.30425941944122314, Adversary Loss: 0.6612483859062195\n",
      "Epoch 22/50, Classification Loss: 0.23380663990974426, Adversary Loss: 0.5772188901901245\n",
      "Epoch 23/50, Classification Loss: 0.31368154287338257, Adversary Loss: 0.7037241458892822\n",
      "Epoch 24/50, Classification Loss: 0.21710827946662903, Adversary Loss: 0.5536671280860901\n",
      "Epoch 25/50, Classification Loss: 0.2876702845096588, Adversary Loss: 0.593445360660553\n",
      "Epoch 26/50, Classification Loss: 0.3467074930667877, Adversary Loss: 0.6378958225250244\n",
      "Epoch 27/50, Classification Loss: 0.2800329923629761, Adversary Loss: 0.6096704602241516\n",
      "Epoch 28/50, Classification Loss: 0.23118023574352264, Adversary Loss: 0.5824545621871948\n",
      "Epoch 29/50, Classification Loss: 0.22439159452915192, Adversary Loss: 0.6126025319099426\n",
      "Epoch 30/50, Classification Loss: 0.1906317174434662, Adversary Loss: 0.6130915880203247\n",
      "Epoch 31/50, Classification Loss: 0.2545246183872223, Adversary Loss: 0.5922975540161133\n",
      "Epoch 32/50, Classification Loss: 0.22949007153511047, Adversary Loss: 0.6201574206352234\n",
      "Epoch 33/50, Classification Loss: 0.2904690206050873, Adversary Loss: 0.5970935821533203\n",
      "Epoch 34/50, Classification Loss: 0.21914714574813843, Adversary Loss: 0.6199926733970642\n",
      "Epoch 35/50, Classification Loss: 0.19312909245491028, Adversary Loss: 0.5864880084991455\n",
      "Epoch 36/50, Classification Loss: 0.3282870352268219, Adversary Loss: 0.5883879661560059\n",
      "Epoch 37/50, Classification Loss: 0.2868996262550354, Adversary Loss: 0.6396299600601196\n",
      "Epoch 38/50, Classification Loss: 0.1913602501153946, Adversary Loss: 0.5808702111244202\n",
      "Epoch 39/50, Classification Loss: 0.23698782920837402, Adversary Loss: 0.5762530565261841\n",
      "Epoch 40/50, Classification Loss: 0.25398874282836914, Adversary Loss: 0.6200920939445496\n",
      "Epoch 41/50, Classification Loss: 0.17691951990127563, Adversary Loss: 0.6628867387771606\n",
      "Epoch 42/50, Classification Loss: 0.1643807291984558, Adversary Loss: 0.6486925482749939\n",
      "Epoch 43/50, Classification Loss: 0.2928508520126343, Adversary Loss: 0.5792038440704346\n",
      "Epoch 44/50, Classification Loss: 0.1736467033624649, Adversary Loss: 0.624782383441925\n",
      "Epoch 45/50, Classification Loss: 0.22273486852645874, Adversary Loss: 0.6125943064689636\n",
      "Epoch 46/50, Classification Loss: 0.23800857365131378, Adversary Loss: 0.5807373523712158\n",
      "Epoch 47/50, Classification Loss: 0.2216176986694336, Adversary Loss: 0.5804793834686279\n",
      "Epoch 48/50, Classification Loss: 0.16511352360248566, Adversary Loss: 0.6268982887268066\n",
      "Epoch 49/50, Classification Loss: 0.2205103039741516, Adversary Loss: 0.6401817202568054\n",
      "Epoch 50/50, Classification Loss: 0.19955307245254517, Adversary Loss: 0.5673919320106506\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step\n",
      "Model has been saved in ONNX format at ./german/german_debiased_onnx/GC-5.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 21:43:35.058670: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:43:35.058754: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-10 21:43:35.091426: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-10 21:43:35.091558: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    }
   ],
   "source": [
    "# Adversary model definition\n",
    "def build_adversary_model(input_shape):\n",
    "    adversary_input = layers.Input(shape=input_shape)\n",
    "    x = layers.Dense(64, activation='relu')(adversary_input)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    adversary_output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    adversary_model = models.Model(inputs=adversary_input, outputs=adversary_output)\n",
    "    adversary_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return adversary_model\n",
    "\n",
    "# Load and preprocess the data\n",
    "X_train, X_test, y_train, y_test, protected_train, protected_test = load_german()\n",
    "\n",
    "# Standardize the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Directory paths\n",
    "input_directory = './german/german_keras'\n",
    "output_directory = './german/german_debiased_onnx'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "metrics_filename = './model_metrics/german_model_metrics.csv'\n",
    "\n",
    "# Iterate over all .keras files in the input directory to convert to ONNX file\n",
    "for file in os.listdir(input_directory):\n",
    "    if file.endswith('.keras'):\n",
    "        # Full path to the current model file\n",
    "        input_path = os.path.join(input_directory, file)\n",
    "        output_path = os.path.join(output_directory, file.replace('.keras', '.onnx'))\n",
    "\n",
    "        try:\n",
    "            # Load the model\n",
    "            print(f\"Loading model from {input_path}\")\n",
    "            classifier_model = load_model(input_path)\n",
    "\n",
    "            # Ensure the model is compiled with the correct optimizer and metrics\n",
    "            classifier_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Print metrics for plain model\n",
    "            y_test_pred_plain = classifier_model.predict(X_test).argmax(axis=1)\n",
    "            y_test_true = y_test.argmax(axis=1)\n",
    "\n",
    "            plain_classification_accuracy = classification_accuracy(y_test_true, y_test_pred_plain)\n",
    "            plain_balanced_accuracy = balanced_accuracy(y_test_true, y_test_pred_plain)\n",
    "            plain_disparate_impact = disparate_impact(y_test_true, y_test_pred_plain, protected_test)\n",
    "            plain_equal_opportunity_difference = equal_opportunity_difference(y_test_true, y_test_pred_plain, protected_test)\n",
    "            plain_average_odds_difference = average_odds_difference(y_test_true, y_test_pred_plain, protected_test)\n",
    "\n",
    "            save_metrics_to_csv(metrics_filename, file, 'Plain Model', plain_classification_accuracy, plain_balanced_accuracy, plain_disparate_impact, plain_equal_opportunity_difference, plain_average_odds_difference)\n",
    "            \n",
    "            # Build and compile the adversary model\n",
    "            adversary_model = build_adversary_model(classifier_model.output_shape[1:])\n",
    "\n",
    "            # Training parameters\n",
    "            num_epochs = 50\n",
    "            batch_size = 128\n",
    "            learning_rate = 0.001\n",
    "            adversary_loss_weight = 0.7\n",
    "\n",
    "            # Optimizers\n",
    "            classifier_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "            adversary_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "            # Loss functions\n",
    "            classification_loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "            adversary_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "            # Training loop\n",
    "            for epoch in range(num_epochs):\n",
    "                # Shuffle the training data\n",
    "                indices = np.arange(X_train.shape[0])\n",
    "                np.random.shuffle(indices)\n",
    "                \n",
    "                # Mini-batch training\n",
    "                for start in range(0, X_train.shape[0], batch_size):\n",
    "                    end = min(start + batch_size, X_train.shape[0])\n",
    "                    batch_indices = indices[start:end]\n",
    "                    \n",
    "                    X_batch = X_train[batch_indices]\n",
    "                    y_batch = y_train[batch_indices]\n",
    "                    protected_batch = protected_train[batch_indices].reshape(-1, 1)\n",
    "                    \n",
    "                    with tf.GradientTape() as classifier_tape, tf.GradientTape() as adversary_tape:\n",
    "                        # Forward pass through the classifier\n",
    "                        classifier_predictions = classifier_model(X_batch, training=True)\n",
    "                        \n",
    "                        # Forward pass through the adversary\n",
    "                        adversary_predictions = adversary_model(classifier_predictions, training=True)\n",
    "                        \n",
    "                        # Compute losses\n",
    "                        classification_loss = classification_loss_fn(y_batch, classifier_predictions)\n",
    "                        adversary_loss = adversary_loss_fn(protected_batch, adversary_predictions)\n",
    "                        total_loss = classification_loss - adversary_loss_weight * adversary_loss\n",
    "                    \n",
    "                    # Compute gradients and update classifier weights\n",
    "                    classifier_gradients = classifier_tape.gradient(total_loss, classifier_model.trainable_variables)\n",
    "                    classifier_optimizer.apply_gradients(zip(classifier_gradients, classifier_model.trainable_variables))\n",
    "                    \n",
    "                    with tf.GradientTape() as adversary_tape:\n",
    "                        # Forward pass through the classifier\n",
    "                        classifier_predictions = classifier_model(X_batch, training=True)\n",
    "                        \n",
    "                        # Forward pass through the adversary\n",
    "                        adversary_predictions = adversary_model(classifier_predictions, training=True)\n",
    "                        \n",
    "                        # Compute adversary loss\n",
    "                        adversary_loss = adversary_loss_fn(protected_batch, adversary_predictions)\n",
    "                    \n",
    "                    # Compute gradients and update adversary weights\n",
    "                    adversary_gradients = adversary_tape.gradient(adversary_loss, adversary_model.trainable_variables)\n",
    "                    adversary_optimizer.apply_gradients(zip(adversary_gradients, adversary_model.trainable_variables))\n",
    "                \n",
    "                print(f\"Epoch {epoch + 1}/{num_epochs}, Classification Loss: {classification_loss.numpy()}, Adversary Loss: {adversary_loss.numpy()}\")\n",
    "            \n",
    "            # Predictions for debiased model\n",
    "            y_test_pred_debiased = classifier_model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "            debiased_classification_accuracy = classification_accuracy(y_test_true, y_test_pred_debiased)\n",
    "            debiased_balanced_accuracy = balanced_accuracy(y_test_true, y_test_pred_debiased)\n",
    "            debiased_disparate_impact = disparate_impact(y_test_true, y_test_pred_debiased, protected_test)\n",
    "            debiased_equal_opportunity_difference = equal_opportunity_difference(y_test_true, y_test_pred_debiased, protected_test)\n",
    "            debiased_average_odds_difference = average_odds_difference(y_test_true, y_test_pred_debiased, protected_test)\n",
    "\n",
    "            save_metrics_to_csv(metrics_filename, file, 'Debiased Model', debiased_classification_accuracy, debiased_balanced_accuracy, debiased_disparate_impact, debiased_equal_opportunity_difference, debiased_average_odds_difference)\n",
    "            \n",
    "            # Save the debiased model as ONNX\n",
    "            input_shape = (20,)  # Adjust the input shape based on your model's expected input\n",
    "            save_model_onnx(classifier_model, input_shape, output_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert {file}. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
